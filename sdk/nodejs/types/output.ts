// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import { input as inputs, output as outputs } from "../types";

export interface AlbBackendGroupGrpcBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig?: outputs.AlbBackendGroupGrpcBackendLoadBalancingConfig;
    /**
     * Name of the backend.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port?: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls?: outputs.AlbBackendGroupGrpcBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight?: number;
}

export interface AlbBackendGroupGrpcBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort?: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold?: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent?: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface AlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck {
    /**
     * Service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName?: string;
}

export interface AlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck {
    /**
     * "Host" HTTP header value.
     */
    host?: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface AlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck {
    /**
     * Text to search in reply.
     */
    receive?: string;
    /**
     * Message to send. If empty, it's a connect-only health check.
     */
    send?: string;
}

export interface AlbBackendGroupGrpcBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent?: number;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold?: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality?: boolean;
}

export interface AlbBackendGroupGrpcBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - (Optional) Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - (Optional) PEM-encoded trusted CA certificate chain.
     */
    sni?: string;
    validationContext?: outputs.AlbBackendGroupGrpcBackendTlsValidationContext;
}

export interface AlbBackendGroupGrpcBackendTlsValidationContext {
    trustedCaBytes?: string;
    trustedCaId?: string;
}

export interface AlbBackendGroupHttpBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheck;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig?: outputs.AlbBackendGroupHttpBackendLoadBalancingConfig;
    /**
     * Name of the backend.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port?: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls?: outputs.AlbBackendGroupHttpBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight?: number;
}

export interface AlbBackendGroupHttpBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort?: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold?: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent?: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface AlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck {
    /**
     * Service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName?: string;
}

export interface AlbBackendGroupHttpBackendHealthcheckHttpHealthcheck {
    /**
     * "Host" HTTP header value.
     */
    host?: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface AlbBackendGroupHttpBackendHealthcheckStreamHealthcheck {
    /**
     * Text to search in reply.
     */
    receive?: string;
    /**
     * Message to send. If empty, it's a connect-only health check.
     */
    send?: string;
}

export interface AlbBackendGroupHttpBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent?: number;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold?: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality?: boolean;
}

export interface AlbBackendGroupHttpBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - (Optional) Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - (Optional) PEM-encoded trusted CA certificate chain.
     */
    sni?: string;
    validationContext?: outputs.AlbBackendGroupHttpBackendTlsValidationContext;
}

export interface AlbBackendGroupHttpBackendTlsValidationContext {
    trustedCaBytes?: string;
    trustedCaId?: string;
}

export interface AlbBackendGroupStreamBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig?: outputs.AlbBackendGroupStreamBackendLoadBalancingConfig;
    /**
     * Name of the backend.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port?: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls?: outputs.AlbBackendGroupStreamBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight?: number;
}

export interface AlbBackendGroupStreamBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort?: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold?: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent?: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface AlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck {
    /**
     * Service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName?: string;
}

export interface AlbBackendGroupStreamBackendHealthcheckHttpHealthcheck {
    /**
     * "Host" HTTP header value.
     */
    host?: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface AlbBackendGroupStreamBackendHealthcheckStreamHealthcheck {
    /**
     * Text to search in reply.
     */
    receive?: string;
    /**
     * Message to send. If empty, it's a connect-only health check.
     */
    send?: string;
}

export interface AlbBackendGroupStreamBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent?: number;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold?: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality?: boolean;
}

export interface AlbBackendGroupStreamBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - (Optional) Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - (Optional) PEM-encoded trusted CA certificate chain.
     */
    sni?: string;
    validationContext?: outputs.AlbBackendGroupStreamBackendTlsValidationContext;
}

export interface AlbBackendGroupStreamBackendTlsValidationContext {
    trustedCaBytes?: string;
    trustedCaId?: string;
}

export interface AlbLoadBalancerAllocationPolicy {
    /**
     * Unique set of locations. The structure is documented below.
     */
    locations: outputs.AlbLoadBalancerAllocationPolicyLocation[];
}

export interface AlbLoadBalancerAllocationPolicyLocation {
    /**
     * If set, will disable all L7 instances in the zone for request handling.
     */
    disableTraffic?: boolean;
    /**
     * Provided by the client or computed automatically.
     */
    subnetId: string;
    /**
     * ID of the zone that location is located at.
     */
    zoneId: string;
}

export interface AlbLoadBalancerListener {
    /**
     * Network endpoints (addresses and ports) of the listener. The structure is documented below.
     */
    endpoints?: outputs.AlbLoadBalancerListenerEndpoint[];
    /**
     * HTTP listener resource. The structure is documented below.
     */
    http?: outputs.AlbLoadBalancerListenerHttp;
    /**
     * name of SNI match.
     */
    name: string;
    /**
     * Stream listener resource. The structure is documented below.
     */
    stream?: outputs.AlbLoadBalancerListenerStream;
    /**
     * TLS listener resource. The structure is documented below.
     */
    tls?: outputs.AlbLoadBalancerListenerTls;
}

export interface AlbLoadBalancerListenerEndpoint {
    /**
     * Provided by the client or computed automatically.
     */
    addresses: outputs.AlbLoadBalancerListenerEndpointAddress[];
    /**
     * One or more ports to listen on.
     */
    ports: number[];
}

export interface AlbLoadBalancerListenerEndpointAddress {
    /**
     * External IPv4 address. The structure is documented below.
     */
    externalIpv4Address?: outputs.AlbLoadBalancerListenerEndpointAddressExternalIpv4Address;
    /**
     * External IPv6 address. The structure is documented below.
     */
    externalIpv6Address?: outputs.AlbLoadBalancerListenerEndpointAddressExternalIpv6Address;
    /**
     * Internal IPv4 address. The structure is documented below.
     */
    internalIpv4Address?: outputs.AlbLoadBalancerListenerEndpointAddressInternalIpv4Address;
}

export interface AlbLoadBalancerListenerEndpointAddressExternalIpv4Address {
    /**
     * Provided by the client or computed automatically.
     */
    address: string;
}

export interface AlbLoadBalancerListenerEndpointAddressExternalIpv6Address {
    /**
     * Provided by the client or computed automatically.
     */
    address: string;
}

export interface AlbLoadBalancerListenerEndpointAddressInternalIpv4Address {
    /**
     * Provided by the client or computed automatically.
     */
    address: string;
    /**
     * Provided by the client or computed automatically.
     */
    subnetId: string;
}

export interface AlbLoadBalancerListenerHttp {
    /**
     * HTTP handler that sets plaintext HTTP router. The structure is documented below.
     */
    handler?: outputs.AlbLoadBalancerListenerHttpHandler;
    /**
     * Shortcut for adding http > https redirects. The structure is documented below.
     */
    redirects?: outputs.AlbLoadBalancerListenerHttpRedirects;
}

export interface AlbLoadBalancerListenerHttpHandler {
    /**
     * If set, will enable only HTTP1 protocol with HTTP1.0 support.
     */
    allowHttp10?: boolean;
    /**
     * If set, will enable HTTP2 protocol for the handler. The structure is documented below.
     */
    http2Options?: outputs.AlbLoadBalancerListenerHttpHandlerHttp2Options;
    /**
     * HTTP router id.
     */
    httpRouterId?: string;
}

export interface AlbLoadBalancerListenerHttpHandlerHttp2Options {
    /**
     * Maximum number of concurrent streams.
     */
    maxConcurrentStreams?: number;
}

export interface AlbLoadBalancerListenerHttpRedirects {
    httpToHttps?: boolean;
}

export interface AlbLoadBalancerListenerStream {
    /**
     * HTTP handler that sets plaintext HTTP router. The structure is documented below.
     */
    handler?: outputs.AlbLoadBalancerListenerStreamHandler;
}

export interface AlbLoadBalancerListenerStreamHandler {
    /**
     * Backend group id.
     */
    backendGroupId?: string;
}

export interface AlbLoadBalancerListenerTls {
    /**
     * TLS handler resource. The structure is documented below.
     */
    defaultHandler: outputs.AlbLoadBalancerListenerTlsDefaultHandler;
    /**
     * SNI match resource. The structure is documented below.
     */
    sniHandlers?: outputs.AlbLoadBalancerListenerTlsSniHandler[];
}

export interface AlbLoadBalancerListenerTlsDefaultHandler {
    /**
     * Certificate IDs in the Certificate Manager. Multiple TLS certificates can be associated
     * with the same context to allow both RSA and ECDSA certificates. Only the first certificate of each type will be used.
     */
    certificateIds: string[];
    /**
     * HTTP handler resource. The structure is documented below.
     */
    httpHandler?: outputs.AlbLoadBalancerListenerTlsDefaultHandlerHttpHandler;
    /**
     * Stream handler resource. The structure is documented below.
     */
    streamHandler?: outputs.AlbLoadBalancerListenerTlsDefaultHandlerStreamHandler;
}

export interface AlbLoadBalancerListenerTlsDefaultHandlerHttpHandler {
    /**
     * If set, will enable only HTTP1 protocol with HTTP1.0 support.
     */
    allowHttp10?: boolean;
    /**
     * If set, will enable HTTP2 protocol for the handler. The structure is documented below.
     */
    http2Options?: outputs.AlbLoadBalancerListenerTlsDefaultHandlerHttpHandlerHttp2Options;
    /**
     * HTTP router id.
     */
    httpRouterId?: string;
}

export interface AlbLoadBalancerListenerTlsDefaultHandlerHttpHandlerHttp2Options {
    /**
     * Maximum number of concurrent streams.
     */
    maxConcurrentStreams?: number;
}

export interface AlbLoadBalancerListenerTlsDefaultHandlerStreamHandler {
    /**
     * Backend group id.
     */
    backendGroupId?: string;
}

export interface AlbLoadBalancerListenerTlsSniHandler {
    /**
     * HTTP handler that sets plaintext HTTP router. The structure is documented below.
     */
    handler: outputs.AlbLoadBalancerListenerTlsSniHandlerHandler;
    /**
     * name of SNI match.
     */
    name: string;
    /**
     * A set of server names.
     */
    serverNames: string[];
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandler {
    /**
     * Certificate IDs in the Certificate Manager. Multiple TLS certificates can be associated
     * with the same context to allow both RSA and ECDSA certificates. Only the first certificate of each type will be used.
     */
    certificateIds: string[];
    /**
     * HTTP handler resource. The structure is documented below.
     */
    httpHandler?: outputs.AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandler;
    /**
     * Stream handler resource. The structure is documented below.
     */
    streamHandler?: outputs.AlbLoadBalancerListenerTlsSniHandlerHandlerStreamHandler;
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandler {
    /**
     * If set, will enable only HTTP1 protocol with HTTP1.0 support.
     */
    allowHttp10?: boolean;
    /**
     * If set, will enable HTTP2 protocol for the handler. The structure is documented below.
     */
    http2Options?: outputs.AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandlerHttp2Options;
    /**
     * HTTP router id.
     */
    httpRouterId?: string;
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandlerHttp2Options {
    /**
     * Maximum number of concurrent streams.
     */
    maxConcurrentStreams?: number;
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandlerStreamHandler {
    /**
     * Backend group id.
     */
    backendGroupId?: string;
}

export interface AlbTargetGroupTarget {
    /**
     * IP address of the target.
     */
    ipAddress: string;
    privateIpv4Address?: boolean;
    /**
     * ID of the subnet that targets are connected to.
     * All targets in the target group must be connected to the same subnet within a single availability zone.
     */
    subnetId?: string;
}

export interface AlbVirtualHostModifyRequestHeader {
    /**
     * Append string to the header value.
     */
    append?: string;
    /**
     * name of the route.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove?: boolean;
    /**
     * New value for a header. Header values support the following 
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace?: string;
}

export interface AlbVirtualHostModifyResponseHeader {
    /**
     * Append string to the header value.
     */
    append?: string;
    /**
     * name of the route.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove?: boolean;
    /**
     * New value for a header. Header values support the following 
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace?: string;
}

export interface AlbVirtualHostRoute {
    /**
     * GRPC route resource. The structure is documented below.
     */
    grpcRoute?: outputs.AlbVirtualHostRouteGrpcRoute;
    /**
     * HTTP route resource. The structure is documented below.
     */
    httpRoute?: outputs.AlbVirtualHostRouteHttpRoute;
    /**
     * name of the route.
     */
    name?: string;
}

export interface AlbVirtualHostRouteGrpcRoute {
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    grpcMatches?: outputs.AlbVirtualHostRouteGrpcRouteGrpcMatch[];
    /**
     * GRPC route action resource. The structure is documented below.
     */
    grpcRouteAction?: outputs.AlbVirtualHostRouteGrpcRouteGrpcRouteAction;
    /**
     * GRPC status response action resource. The structure is documented below.
     */
    grpcStatusResponseAction?: outputs.AlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcMatch {
    /**
     * If not set, all services/methods are assumed. The structure is documented below.
     */
    fqmn?: outputs.AlbVirtualHostRouteGrpcRouteGrpcMatchFqmn;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcMatchFqmn {
    /**
     * Match exactly.
     */
    exact?: string;
    /**
     * Match prefix.
     */
    prefix?: string;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite?: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite?: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the
     * route. It is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout
     * to the maximum time the stream is allowed to be alive. If not specified, there is no
     * per-route idle timeout.
     */
    idleTimeout?: string;
    /**
     * Lower timeout may be specified by the client (using grpc-timeout header). If not set, default is 
     * 60 seconds.
     */
    maxTimeout?: string;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction {
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, 
     * permission_denied, unauthenticated, unimplemented, internal, unavailable.
     */
    status?: string;
}

export interface AlbVirtualHostRouteHttpRoute {
    /**
     * Direct response action resource. The structure is documented below.
     */
    directResponseAction?: outputs.AlbVirtualHostRouteHttpRouteDirectResponseAction;
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    httpMatches?: outputs.AlbVirtualHostRouteHttpRouteHttpMatch[];
    /**
     * HTTP route action resource. The structure is documented below.
     */
    httpRouteAction?: outputs.AlbVirtualHostRouteHttpRouteHttpRouteAction;
    /**
     * Redirect action resource. The structure is documented below.
     */
    redirectAction?: outputs.AlbVirtualHostRouteHttpRouteRedirectAction;
}

export interface AlbVirtualHostRouteHttpRouteDirectResponseAction {
    /**
     * Response body text.
     */
    body?: string;
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, 
     * permission_denied, unauthenticated, unimplemented, internal, unavailable.
     */
    status?: number;
}

export interface AlbVirtualHostRouteHttpRouteHttpMatch {
    /**
     * List of methods(strings).
     */
    httpMethods?: string[];
    /**
     * If not set, '/' is assumed. The structure is documented below.
     */
    path?: outputs.AlbVirtualHostRouteHttpRouteHttpMatchPath;
}

export interface AlbVirtualHostRouteHttpRouteHttpMatchPath {
    /**
     * Match exactly.
     */
    exact?: string;
    /**
     * Match prefix.
     */
    prefix?: string;
}

export interface AlbVirtualHostRouteHttpRouteHttpRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite?: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite?: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the
     * route. It is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout
     * to the maximum time the stream is allowed to be alive. If not specified, there is no
     * per-route idle timeout.
     */
    idleTimeout?: string;
    /**
     * If not empty, matched path prefix will be replaced by this value.
     */
    prefixRewrite?: string;
    /**
     * Specifies the request timeout (overall time request processing is allowed to take) for the 
     * route. If not set, default is 60 seconds.
     */
    timeout?: string;
    /**
     * List of upgrade types. Only specified upgrade types will be allowed. For example, 
     * "websocket".
     */
    upgradeTypes?: string[];
}

export interface AlbVirtualHostRouteHttpRouteRedirectAction {
    removeQuery?: boolean;
    /**
     * Replaces hostname.
     */
    replaceHost?: string;
    /**
     * Replace path.
     */
    replacePath?: string;
    /**
     * Replaces port.
     */
    replacePort?: number;
    /**
     * Replace only matched prefix. Example:<br/> match:{ prefix_match: "/some" } <br/> 
     * redirect: { replace_prefix: "/other" } <br/> will redirect "/something" to "/otherthing".
     */
    replacePrefix?: string;
    /**
     * Replaces scheme. If the original scheme is `http` or `https`, will also remove the 
     * 80 or 443 port, if present.
     */
    replaceScheme?: string;
    /**
     * The HTTP status code to use in the redirect response. Supported values are: 
     * moved_permanently, found, see_other, temporary_redirect, permanent_redirect.
     */
    responseCode?: string;
}

export interface CdnOriginGroupOrigin {
    backup?: boolean;
    enabled?: boolean;
    originGroupId: number;
    source: string;
}

export interface CdnResourceOptions {
    /**
     * HTTP methods for your CDN content. By default the following methods are allowed: GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS. In case some methods are not allowed to the user, they will get the 405 (Method Not Allowed) response. If the method is not supported, the user gets the 501 (Not Implemented) response.
     */
    allowedHttpMethods: string[];
    /**
     * set up a cache period for the end-users browser. Content will be cached due to origin settings. If there are no cache settings on your origin, the content will not be cached. The list of HTTP response codes that can be cached in browsers: 200, 201, 204, 206, 301, 302, 303, 304, 307, 308. Other response codes will not be cached. The default value is 4 days.
     */
    browserCacheSettings: number;
    /**
     * list HTTP headers that must be included in responses to clients.
     */
    cacheHttpHeaders: string[];
    /**
     * parameter that lets browsers get access to selected resources from a domain different to a domain from which the request is received.
     */
    cors: string[];
    /**
     * custom value for the Host header. Your server must be able to process requests with the chosen header.
     */
    customHostHeader: string;
    /**
     * wildcard additional CNAME. If a resource has a wildcard additional CNAME, you can use your own certificate for content delivery via HTTPS. Read-only.
     */
    customServerName: string;
    /**
     * setup a cache status.
     */
    disableCache: boolean;
    /**
     * disabling proxy force ranges.
     */
    disableProxyForceRanges: boolean;
    /**
     * content will be cached according to origin cache settings. The value applies for a response with codes 200, 201, 204, 206, 301, 302, 303, 304, 307, 308 if an origin server does not have caching HTTP headers. Responses with other codes will not be cached.
     */
    edgeCacheSettings: number;
    /**
     * option helps you to reduce the bandwidth between origin and CDN servers. Also, content delivery speed becomes higher because of reducing the time for compressing files in a CDN.
     */
    fetchedCompressed: boolean;
    /**
     * choose the Forward Host header option if is important to send in the request to the Origin the same Host header as was sent in the request to CDN server.
     */
    forwardHostHeader: boolean;
    /**
     * GZip compression at CDN servers reduces file size by 70% and can be as high as 90%.
     */
    gzipOn: boolean;
    /**
     * set for ignoring cookie.
     */
    ignoreCookie: boolean;
    /**
     * files with different query parameters are cached as objects with the same key regardless of the parameter value. selected by default.
     */
    ignoreQueryParams: boolean;
    /**
     * allows caching for GET, HEAD and POST requests.
     */
    proxyCacheMethodsSet: boolean;
    /**
     * files with the specified query parameters are cached as objects with the same key, files with other parameters are cached as objects with different keys.
     */
    queryParamsBlacklists: string[];
    /**
     * files with the specified query parameters are cached as objects with different keys, files with other parameters are cached as objects with the same key.
     */
    queryParamsWhitelists: string[];
    /**
     * set up a redirect from HTTPS to HTTP.
     */
    redirectHttpToHttps: boolean;
    /**
     * set up a redirect from HTTP to HTTPS.
     */
    redirectHttpsToHttp: boolean;
    /**
     * files larger than 10 MB will be requested and cached in parts (no larger than 10 MB each part). It reduces time to first byte. The origin must support HTTP Range requests.
     */
    slice: boolean;
    /**
     * set up custom headers that CDN servers send in requests to origins.
     */
    staticRequestHeaders: string[];
    staticResponseHeaders: {[key: string]: string};
}

export interface CdnResourceSslCertificate {
    certificateManagerId?: string;
    status: string;
    type: string;
}

export interface ComputeDiskDiskPlacementPolicy {
    /**
     * Specifies Disk Placement Group id.
     */
    diskPlacementGroupId: string;
}

export interface ComputeInstanceBootDisk {
    /**
     * Whether the disk is auto-deleted when the instance
     * is deleted. The default value is false.
     */
    autoDelete?: boolean;
    /**
     * Name that can be used to access an attached disk
     * under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Parameters for a new disk that will be created
     * alongside the new instance. Either `initializeParams` or `diskId` must be set. The structure is documented below.
     */
    initializeParams: outputs.ComputeInstanceBootDiskInitializeParams;
    /**
     * Type of access to the disk resource. By default, a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface ComputeInstanceBootDiskInitializeParams {
    blockSize: number;
    /**
     * Description of the boot disk.
     */
    description: string;
    /**
     * A disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * Name of the boot disk.
     */
    name: string;
    /**
     * Size of the disk in GB.
     */
    size: number;
    /**
     * A snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Disk type.
     */
    type?: string;
}

export interface ComputeInstanceGroupAllocationPolicy {
    /**
     * A list of availability zones.
     */
    zones: string[];
}

export interface ComputeInstanceGroupApplicationLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration?: number;
    /**
     * The status message of the instance.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription?: string;
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels?: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName?: string;
}

export interface ComputeInstanceGroupDeployPolicy {
    /**
     * The maximum number of instances that can be created at the same time.
     */
    maxCreating?: number;
    /**
     * The maximum number of instances that can be deleted at the same time.
     */
    maxDeleting?: number;
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size
     * during the update process.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline (stopped or deleted) at the same time
     * during the update process.
     */
    maxUnavailable: number;
    /**
     * The amount of time in seconds to allow for an instance to start.
     * Instance will be considered up and running (and start receiving traffic) only after the startupDuration
     * has elapsed and all health checks are passed.
     */
    startupDuration?: number;
    /**
     * Affects the lifecycle of the instance during deployment. If set to `proactive` (default), Instance Groups
     * can forcefully stop a running instance. If `opportunistic`, Instance Groups does not stop a running instance. Instead,
     * it will wait until the instance stops itself or becomes unhealthy.
     */
    strategy: string;
}

export interface ComputeInstanceGroupHealthCheck {
    /**
     * The number of successful health checks before the managed instance is declared healthy.
     */
    healthyThreshold?: number;
    /**
     * HTTP check options. The structure is documented below.
     */
    httpOptions?: outputs.ComputeInstanceGroupHealthCheckHttpOption[];
    /**
     * The interval to wait between health checks in seconds.
     */
    interval?: number;
    /**
     * TCP check options. The structure is documented below.
     */
    tcpOptions: outputs.ComputeInstanceGroupHealthCheckTcpOptions;
    /**
     * The length of time to wait for a response before the health check times out in seconds.
     */
    timeout?: number;
    /**
     * The number of failed health checks before the managed instance is declared unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface ComputeInstanceGroupHealthCheckHttpOption {
    /**
     * The URL path used for health check requests.
     */
    path: string;
    /**
     * The port used for TCP health checks.
     */
    port: number;
}

export interface ComputeInstanceGroupHealthCheckTcpOptions {
    /**
     * The port used for TCP health checks.
     */
    port: number;
}

export interface ComputeInstanceGroupInstance {
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * The ID of the instance.
     */
    instanceId: string;
    /**
     * Name template of the instance.  
     * In order to be unique it must contain at least one of instance unique placeholders:
     * {instance.short_id}
     * {instance.index}
     * combination of {instance.zone_id} and {instance.index_in_zone}
     * Example: my-instance-{instance.index}
     * If not set, default is used: {instance_group.id}-{instance.short_id}
     * It may also contain another placeholders, see metadata doc for full list.
     */
    name: string;
    /**
     * Network specifications for the instance. This can be used multiple times for adding multiple interfaces. The structure is documented below.
     */
    networkInterfaces: outputs.ComputeInstanceGroupInstanceNetworkInterface[];
    /**
     * The status of the instance.
     */
    status: string;
    statusChangedAt: string;
    /**
     * The status message of the instance.
     */
    statusMessage: string;
    /**
     * The ID of the availability zone where the instance resides.
     */
    zoneId: string;
}

export interface ComputeInstanceGroupInstanceNetworkInterface {
    /**
     * The index of the network interface as generated by the server.
     */
    index: number;
    /**
     * Manual set static IP address.
     */
    ipAddress: string;
    /**
     * True if IPv4 address allocated for the network interface.
     */
    ipv4: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * The MAC address assigned to the network interface.
     */
    macAddress: string;
    /**
     * Flag for using NAT.
     */
    nat: boolean;
    /**
     * A public address that can be used to access the internet over NAT. Use `variables` to set.
     */
    natIpAddress: string;
    /**
     * The IP version for the public address.
     */
    natIpVersion: string;
    /**
     * The ID of the subnet to attach this interface to. The subnet must reside in the same zone where this instance was created.
     */
    subnetId: string;
}

export interface ComputeInstanceGroupInstanceTemplate {
    /**
     * Boot disk specifications for the instance. The structure is documented below.
     */
    bootDisk: outputs.ComputeInstanceGroupInstanceTemplateBootDisk;
    /**
     * A description of the boot disk.
     */
    description?: string;
    /**
     * Hostname template for the instance.   
     * This field is used to generate the FQDN value of instance.
     * The hostname must be unique within the network and region.
     * If not specified, the hostname will be equal to id of the instance
     * and FQDN will be `<id>.auto.internal`. Otherwise FQDN will be `<hostname>.<region_id>.internal`.
     * In order to be unique it must contain at least on of instance unique placeholders:
     * {instance.short_id}
     * {instance.index}
     * combination of {instance.zone_id} and {instance.index_in_zone}
     * Example: my-instance-{instance.index}
     * If not set, `name` value will be used
     * It may also contain another placeholders, see metadata doc for full list.
     */
    hostname?: string;
    /**
     * A map of labels of metric.
     */
    labels: {[key: string]: string};
    /**
     * A set of metadata key/value pairs to make available from within the instance.
     */
    metadata: {[key: string]: string};
    /**
     * Name template of the instance.  
     * In order to be unique it must contain at least one of instance unique placeholders:
     * {instance.short_id}
     * {instance.index}
     * combination of {instance.zone_id} and {instance.index_in_zone}
     * Example: my-instance-{instance.index}
     * If not set, default is used: {instance_group.id}-{instance.short_id}
     * It may also contain another placeholders, see metadata doc for full list.
     */
    name?: string;
    /**
     * Network specifications for the instance. This can be used multiple times for adding multiple interfaces. The structure is documented below.
     */
    networkInterfaces: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterface[];
    /**
     * Network acceleration type for instance. The structure is documented below.
     */
    networkSettings?: outputs.ComputeInstanceGroupInstanceTemplateNetworkSetting[];
    /**
     * The placement policy configuration. The structure is documented below.
     */
    placementPolicy?: outputs.ComputeInstanceGroupInstanceTemplatePlacementPolicy;
    /**
     * The ID of the hardware platform configuration for the instance. The default is 'standard-v1'.
     */
    platformId?: string;
    /**
     * Compute resource specifications for the instance. The structure is documented below.
     */
    resources: outputs.ComputeInstanceGroupInstanceTemplateResources;
    /**
     * The scheduling policy configuration. The structure is documented below.
     */
    schedulingPolicy: outputs.ComputeInstanceGroupInstanceTemplateSchedulingPolicy;
    /**
     * A list of disks to attach to the instance. The structure is documented below.
     */
    secondaryDisks?: outputs.ComputeInstanceGroupInstanceTemplateSecondaryDisk[];
    /**
     * The ID of the service account authorized for this instance.
     */
    serviceAccountId?: string;
}

export interface ComputeInstanceGroupInstanceTemplateBootDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId?: string;
    /**
     * Parameters for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams?: outputs.ComputeInstanceGroupInstanceTemplateBootDiskInitializeParams;
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode?: string;
}

export interface ComputeInstanceGroupInstanceTemplateBootDiskInitializeParams {
    /**
     * A description of the boot disk.
     */
    description?: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * The number of instances in the instance group.
     */
    size: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type?: string;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterface {
    /**
     * List of dns records.  The structure is documented below.
     */
    dnsRecords?: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord[];
    /**
     * Manual set static IP address.
     */
    ipAddress: string;
    /**
     * True if IPv4 address allocated for the network interface.
     */
    ipv4?: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * List of ipv6 dns records.  The structure is documented below.
     */
    ipv6DnsRecords?: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord[];
    /**
     * Flag for using NAT.
     */
    nat: boolean;
    /**
     * List of nat dns records.  The structure is documented below.
     */
    natDnsRecords?: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord[];
    /**
     * A public address that can be used to access the internet over NAT. Use `variables` to set.
     */
    natIpAddress?: string;
    /**
     * The ID of the network.
     */
    networkId?: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds?: string[];
    /**
     * The ID of the subnets to attach this interface to.
     */
    subnetIds?: string[];
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord {
    /**
     * DNS zone id (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl?: number;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone id (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl?: number;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone id (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl?: number;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkSetting {
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type?: string;
}

export interface ComputeInstanceGroupInstanceTemplatePlacementPolicy {
    /**
     * Specifies the id of the Placement Group to assign to the instances.
     */
    placementGroupId: string;
}

export interface ComputeInstanceGroupInstanceTemplateResources {
    /**
     * If provided, specifies baseline core performance as a percent.
     */
    coreFraction?: number;
    /**
     * The number of CPU cores for the instance.
     */
    cores: number;
    gpus?: number;
    /**
     * The memory size in GB.
     */
    memory: number;
}

export interface ComputeInstanceGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible?: boolean;
}

export interface ComputeInstanceGroupInstanceTemplateSecondaryDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName?: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId?: string;
    /**
     * Parameters for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams?: outputs.ComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParams;
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode?: string;
}

export interface ComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParams {
    /**
     * A description of the boot disk.
     */
    description?: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId?: string;
    /**
     * The number of instances in the instance group.
     */
    size?: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId?: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type?: string;
}

export interface ComputeInstanceGroupLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration?: number;
    /**
     * The status message of the instance.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription?: string;
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels?: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName?: string;
}

export interface ComputeInstanceGroupScalePolicy {
    /**
     * The auto scaling policy of the instance group. The structure is documented below.
     */
    autoScale?: outputs.ComputeInstanceGroupScalePolicyAutoScale;
    /**
     * The fixed scaling policy of the instance group. The structure is documented below.
     */
    fixedScale?: outputs.ComputeInstanceGroupScalePolicyFixedScale;
    /**
     * The test auto scaling policy of the instance group. Use it to test how the auto scale works. The structure is documented below.
     */
    testAutoScale?: outputs.ComputeInstanceGroupScalePolicyTestAutoScale;
}

export interface ComputeInstanceGroupScalePolicyAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget?: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules?: outputs.ComputeInstanceGroupScalePolicyAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize?: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize?: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface ComputeInstanceGroupScalePolicyAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId?: string;
    /**
     * A map of labels of metric.
     */
    labels?: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service?: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface ComputeInstanceGroupScalePolicyFixedScale {
    /**
     * The number of instances in the instance group.
     */
    size: number;
}

export interface ComputeInstanceGroupScalePolicyTestAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget?: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules?: outputs.ComputeInstanceGroupScalePolicyTestAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize?: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize?: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface ComputeInstanceGroupScalePolicyTestAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId?: string;
    /**
     * A map of labels of metric.
     */
    labels?: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service?: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface ComputeInstanceNetworkInterface {
    /**
     * List of configurations for creating ipv4 DNS records. The structure is documented below.
     */
    dnsRecords?: outputs.ComputeInstanceNetworkInterfaceDnsRecord[];
    index: number;
    /**
     * The private IP address to assign to the instance. If
     * empty, the address will be automatically assigned from the specified subnet.
     */
    ipAddress: string;
    /**
     * Allocate an IPv4 address for the interface. The default value is `true`.
     */
    ipv4?: boolean;
    /**
     * If true, allocate an IPv6 address for the interface.
     * The address will be automatically assigned from the specified subnet.
     */
    ipv6: boolean;
    /**
     * The private IPv6 address to assign to the instance.
     */
    ipv6Address: string;
    /**
     * List of configurations for creating ipv6 DNS records. The structure is documented below.
     */
    ipv6DnsRecords?: outputs.ComputeInstanceNetworkInterfaceIpv6DnsRecord[];
    macAddress: string;
    /**
     * Provide a public address, for instance, to access the internet over NAT.
     */
    nat: boolean;
    /**
     * List of configurations for creating ipv4 NAT DNS records. The structure is documented below.
     */
    natDnsRecords?: outputs.ComputeInstanceNetworkInterfaceNatDnsRecord[];
    /**
     * Provide a public address, for instance, to access the internet over NAT. Address should be already reserved in web UI.
     */
    natIpAddress: string;
    natIpVersion: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * ID of the subnet to attach this
     * interface to. The subnet must exist in the same zone where this instance will be
     * created.
     */
    subnetId: string;
}

export interface ComputeInstanceNetworkInterfaceDnsRecord {
    /**
     * DNS zone ID (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN (must have a dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl?: number;
}

export interface ComputeInstanceNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone ID (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN (must have a dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl?: number;
}

export interface ComputeInstanceNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone ID (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN (must have a dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl?: number;
}

export interface ComputeInstancePlacementPolicy {
    /**
     * Specifies the id of the Placement Group to assign to the instance.
     */
    placementGroupId: string;
}

export interface ComputeInstanceResources {
    /**
     * If provided, specifies baseline performance for a core as a percent.
     */
    coreFraction?: number;
    /**
     * CPU cores for the instance.
     */
    cores: number;
    gpus?: number;
    /**
     * Memory size in GB.
     */
    memory: number;
}

export interface ComputeInstanceSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible?: boolean;
}

export interface ComputeInstanceSecondaryDisk {
    /**
     * Whether the disk is auto-deleted when the instance
     * is deleted. The default value is false.
     */
    autoDelete?: boolean;
    /**
     * Name that can be used to access an attached disk
     * under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Type of access to the disk resource. By default, a disk is attached in `READ_WRITE` mode.
     */
    mode?: string;
}

export interface DataprocClusterClusterConfig {
    /**
     * Data Proc specific options. The structure is documented below.
     */
    hadoop?: outputs.DataprocClusterClusterConfigHadoop;
    /**
     * Configuration of the Data Proc subcluster. The structure is documented below.
     */
    subclusterSpecs: outputs.DataprocClusterClusterConfigSubclusterSpec[];
    /**
     * Version of Data Proc image.
     */
    versionId: string;
}

export interface DataprocClusterClusterConfigHadoop {
    /**
     * A set of key/value pairs that are used to configure cluster services.
     */
    properties?: {[key: string]: string};
    /**
     * List of services to run on Data Proc cluster.
     */
    services?: string[];
    /**
     * List of SSH public keys to put to the hosts of the cluster. For information on how to connect to the cluster, see [the official documentation](https://cloud.yandex.com/docs/data-proc/operations/connect).
     */
    sshPublicKeys?: string[];
}

export interface DataprocClusterClusterConfigSubclusterSpec {
    /**
     * Autoscaling configuration for compute subclusters.
     */
    autoscalingConfig?: outputs.DataprocClusterClusterConfigSubclusterSpecAutoscalingConfig;
    /**
     * Number of hosts within Data Proc subcluster.
     */
    hostsCount: number;
    /**
     * (Computed) ID of a new Data Proc cluster.
     */
    id: string;
    /**
     * Name of the Data Proc subcluster.
     */
    name: string;
    /**
     * Resources allocated to each host of the Data Proc subcluster. The structure is documented below.
     */
    resources: outputs.DataprocClusterClusterConfigSubclusterSpecResources;
    /**
     * Role of the subcluster in the Data Proc cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which hosts of the subcluster belong. Subnets of all the subclusters must belong to the same VPC network.
     */
    subnetId: string;
}

export interface DataprocClusterClusterConfigSubclusterSpecAutoscalingConfig {
    /**
     * Defines an autoscaling rule based on the average CPU utilization of the instance group. If not set default autoscaling metric will be used.
     */
    cpuUtilizationTarget?: number;
    /**
     * Timeout to gracefully decommission nodes during downscaling. In seconds.
     */
    decommissionTimeout?: number;
    /**
     * Maximum number of nodes in autoscaling subclusters.
     */
    maxHostsCount: number;
    /**
     * Time in seconds allotted for averaging metrics.
     */
    measurementDuration?: number;
    /**
     * Bool flag -- whether to use preemptible compute instances. Preemptible instances are stopped at least once every 24 hours, and can be stopped at any time if their resources are needed by Compute. For more information, see [Preemptible Virtual Machines](https://cloud.yandex.com/docs/compute/concepts/preemptible-vm).
     */
    preemptible?: boolean;
    /**
     * Minimum amount of time in seconds allotted for monitoring before Instance Groups can reduce the number of instances in the group. During this time, the group size doesn't decrease, even if the new metric values indicate that it should.
     */
    stabilizationDuration?: number;
    /**
     * The warmup time of the instance in seconds. During this time, traffic is sent to the instance, but instance metrics are not collected.
     */
    warmupDuration?: number;
}

export interface DataprocClusterClusterConfigSubclusterSpecResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of a host. One of `network-hdd` (default) or `network-ssd`.
     */
    diskTypeId?: string;
    /**
     * The ID of the preset for computational resources available to a host. All available presets are listed in the [documentation](https://cloud.yandex.com/docs/data-proc/concepts/instance-types).
     */
    resourcePresetId: string;
}

export interface DatatransferEndpointSettings {
    /**
     * Settings specific to the MySQL source endpoint.
     */
    mysqlSource?: outputs.DatatransferEndpointSettingsMysqlSource;
    /**
     * Settings specific to the MySQL target endpoint.
     */
    mysqlTarget?: outputs.DatatransferEndpointSettingsMysqlTarget;
    /**
     * Settings specific to the PostgreSQL source endpoint.
     */
    postgresSource?: outputs.DatatransferEndpointSettingsPostgresSource;
    /**
     * Settings specific to the PostgreSQL target endpoint.
     */
    postgresTarget?: outputs.DatatransferEndpointSettingsPostgresTarget;
}

export interface DatatransferEndpointSettingsMysqlSource {
    /**
     * Connection settings. The structure is documented below.
     */
    connection?: outputs.DatatransferEndpointSettingsMysqlSourceConnection;
    /**
     * Name of the database to transfer.
     */
    database?: string;
    /**
     * Opposite of `includeTableRegex`. The tables matching the specified regular expressions will not be transferred.
     */
    excludeTablesRegexes: string[];
    /**
     * List of regular expressions of table names which should be transferred. A table name is formatted as schemaname.tablename. For example, a single regular expression may look like `^mydb.employees$`.
     */
    includeTablesRegexes: string[];
    /**
     * Defines which database schema objects should be transferred, e.g. views, functions, etc.
     */
    objectTransferSettings: outputs.DatatransferEndpointSettingsMysqlSourceObjectTransferSettings;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password?: outputs.DatatransferEndpointSettingsMysqlSourcePassword;
    /**
     * Timezone to use for parsing timestamps for saving source timezones. Accepts values from IANA timezone database. Default: local timezone.
     */
    timezone: string;
    /**
     * User for the database access.
     */
    user?: string;
}

export interface DatatransferEndpointSettingsMysqlSourceConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise MySQL server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremise;
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremise {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
    /**
     * List of host names of the PostgreSQL server. Exactly one host is expected currently.
     */
    hosts?: string[];
    /**
     * Port for the database connection.
     */
    port?: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId?: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
}

export interface DatatransferEndpointSettingsMysqlSourceObjectTransferSettings {
    routine?: string;
    trigger?: string;
    view?: string;
}

export interface DatatransferEndpointSettingsMysqlSourcePassword {
    raw?: string;
}

export interface DatatransferEndpointSettingsMysqlTarget {
    /**
     * Connection settings. The structure is documented below.
     */
    connection?: outputs.DatatransferEndpointSettingsMysqlTargetConnection;
    /**
     * Name of the database to transfer.
     */
    database?: string;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password?: outputs.DatatransferEndpointSettingsMysqlTargetPassword;
    /**
     * Name of the database schema in which auxiliary tables needed for the transfer will be created. Empty `serviceSchema` implies schema "public".
     */
    serviceSchema?: string;
    /**
     * When true, disables foreign key checks. See [foreignKeyChecks](https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_foreign_key_checks). False by default.
     */
    skipConstraintChecks?: boolean;
    /**
     * [sqlMode](https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html) to use when interacting with the server. Defaults to "NO_AUTO_VALUE_ON_ZERO,NO_DIR_IN_CREATE,NO_ENGINE_SUBSTITUTION".
     */
    sqlMode?: string;
    /**
     * Timezone to use for parsing timestamps for saving source timezones. Accepts values from IANA timezone database. Default: local timezone.
     */
    timezone?: string;
    /**
     * User for the database access.
     */
    user?: string;
}

export interface DatatransferEndpointSettingsMysqlTargetConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise MySQL server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremise;
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremise {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
    /**
     * List of host names of the PostgreSQL server. Exactly one host is expected currently.
     */
    hosts?: string[];
    /**
     * Port for the database connection.
     */
    port?: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId?: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
}

export interface DatatransferEndpointSettingsMysqlTargetPassword {
    raw?: string;
}

export interface DatatransferEndpointSettingsPostgresSource {
    collapseInheritTable?: boolean;
    /**
     * Connection settings. The structure is documented below.
     */
    connection?: outputs.DatatransferEndpointSettingsPostgresSourceConnection;
    /**
     * Name of the database to transfer.
     */
    database?: string;
    /**
     * List of tables which will not be transfered, formatted as `schemaname.tablename`.
     */
    excludeTables?: string[];
    /**
     * List of tables to transfer, formatted as `schemaname.tablename`. If omitted or an empty list is specified, all tables will be transferred.
     */
    includeTables?: string[];
    /**
     * Defines which database schema objects should be transferred, e.g. views, functions, etc.
     */
    objectTransferSettings: outputs.DatatransferEndpointSettingsPostgresSourceObjectTransferSettings;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password?: outputs.DatatransferEndpointSettingsPostgresSourcePassword;
    /**
     * Name of the database schema in which auxiliary tables needed for the transfer will be created. Empty `serviceSchema` implies schema "public".
     */
    serviceSchema: string;
    /**
     * Maximum WAL size held by the replication slot, in gigabytes. Exceeding this limit will result in a replication failure and deletion of the replication slot. Unlimited by default.
     */
    slotGigabyteLagLimit: number;
    /**
     * User for the database access.
     */
    user?: string;
}

export interface DatatransferEndpointSettingsPostgresSourceConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise MySQL server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremise;
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremise {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
    /**
     * List of host names of the PostgreSQL server. Exactly one host is expected currently.
     */
    hosts?: string[];
    /**
     * Port for the database connection.
     */
    port?: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId?: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
}

export interface DatatransferEndpointSettingsPostgresSourceObjectTransferSettings {
    cast?: string;
    collation?: string;
    constraint?: string;
    defaultValues?: string;
    fkConstraint?: string;
    function?: string;
    index?: string;
    policy?: string;
    primaryKey?: string;
    rule?: string;
    sequence?: string;
    sequenceOwnedBy?: string;
    table?: string;
    trigger?: string;
    type?: string;
    view?: string;
}

export interface DatatransferEndpointSettingsPostgresSourcePassword {
    raw?: string;
}

export interface DatatransferEndpointSettingsPostgresTarget {
    /**
     * Connection settings. The structure is documented below.
     */
    connection?: outputs.DatatransferEndpointSettingsPostgresTargetConnection;
    /**
     * Name of the database to transfer.
     */
    database?: string;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password?: outputs.DatatransferEndpointSettingsPostgresTargetPassword;
    /**
     * User for the database access.
     */
    user?: string;
}

export interface DatatransferEndpointSettingsPostgresTargetConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise MySQL server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremise;
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremise {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
    /**
     * List of host names of the PostgreSQL server. Exactly one host is expected currently.
     */
    hosts?: string[];
    /**
     * Port for the database connection.
     */
    port?: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId?: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate?: string;
}

export interface DatatransferEndpointSettingsPostgresTargetPassword {
    raw?: string;
}

export interface FunctionContent {
    zipFilename: string;
}

export interface FunctionPackage {
    bucketName: string;
    objectName: string;
    sha256?: string;
}

export interface FunctionScalingPolicyPolicy {
    tag: string;
    zoneInstancesLimit?: number;
    zoneRequestsLimit?: number;
}

export interface FunctionTriggerDlq {
    queueId: string;
    serviceAccountId: string;
}

export interface FunctionTriggerFunction {
    id: string;
    retryAttempts?: string;
    retryInterval?: string;
    serviceAccountId?: string;
    tag?: string;
}

export interface FunctionTriggerIot {
    deviceId?: string;
    registryId: string;
    topic?: string;
}

export interface FunctionTriggerLogGroup {
    batchCutoff: string;
    batchSize?: string;
    logGroupIds: string[];
}

export interface FunctionTriggerLogging {
    batchCutoff: string;
    batchSize?: string;
    groupId: string;
    levels: string[];
    resourceIds: string[];
    resourceTypes: string[];
}

export interface FunctionTriggerMessageQueue {
    batchCutoff: string;
    batchSize?: string;
    queueId: string;
    serviceAccountId: string;
    visibilityTimeout?: string;
}

export interface FunctionTriggerObjectStorage {
    bucketId: string;
    create?: boolean;
    delete?: boolean;
    prefix?: string;
    suffix?: string;
    update?: boolean;
}

export interface FunctionTriggerTimer {
    cronExpression: string;
}

export interface GetAlbBackendGroupGrpcBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig: outputs.GetAlbBackendGroupGrpcBackendLoadBalancingConfig;
    /**
     * - Name of the Backend Group.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls: outputs.GetAlbBackendGroupGrpcBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight: number;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck {
    /**
     * Optional service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName: string;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck {
    /**
     * Optional "Host" HTTP header value.
     */
    host: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck {
    /**
     * Optional text to search in reply.
     */
    receive: string;
    /**
     * Optional message to send. If empty, it's a connect-only health check.
     */
    send: string;
}

export interface GetAlbBackendGroupGrpcBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent: number;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality: boolean;
}

export interface GetAlbBackendGroupGrpcBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - PEM-encoded trusted CA certificate chain.
     */
    sni: string;
    validationContext: outputs.GetAlbBackendGroupGrpcBackendTlsValidationContext;
}

export interface GetAlbBackendGroupGrpcBackendTlsValidationContext {
    trustedCaBytes: string;
    trustedCaId: string;
}

export interface GetAlbBackendGroupHttpBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheck;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig: outputs.GetAlbBackendGroupHttpBackendLoadBalancingConfig;
    /**
     * - Name of the Backend Group.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls: outputs.GetAlbBackendGroupHttpBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight: number;
}

export interface GetAlbBackendGroupHttpBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetAlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck {
    /**
     * Optional service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName: string;
}

export interface GetAlbBackendGroupHttpBackendHealthcheckHttpHealthcheck {
    /**
     * Optional "Host" HTTP header value.
     */
    host: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface GetAlbBackendGroupHttpBackendHealthcheckStreamHealthcheck {
    /**
     * Optional text to search in reply.
     */
    receive: string;
    /**
     * Optional message to send. If empty, it's a connect-only health check.
     */
    send: string;
}

export interface GetAlbBackendGroupHttpBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent: number;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality: boolean;
}

export interface GetAlbBackendGroupHttpBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - PEM-encoded trusted CA certificate chain.
     */
    sni: string;
    validationContext: outputs.GetAlbBackendGroupHttpBackendTlsValidationContext;
}

export interface GetAlbBackendGroupHttpBackendTlsValidationContext {
    trustedCaBytes: string;
    trustedCaId: string;
}

export interface GetAlbBackendGroupStreamBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig: outputs.GetAlbBackendGroupStreamBackendLoadBalancingConfig;
    /**
     * - Name of the Backend Group.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls: outputs.GetAlbBackendGroupStreamBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight: number;
}

export interface GetAlbBackendGroupStreamBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetAlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck {
    /**
     * Optional service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName: string;
}

export interface GetAlbBackendGroupStreamBackendHealthcheckHttpHealthcheck {
    /**
     * Optional "Host" HTTP header value.
     */
    host: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface GetAlbBackendGroupStreamBackendHealthcheckStreamHealthcheck {
    /**
     * Optional text to search in reply.
     */
    receive: string;
    /**
     * Optional message to send. If empty, it's a connect-only health check.
     */
    send: string;
}

export interface GetAlbBackendGroupStreamBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent: number;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality: boolean;
}

export interface GetAlbBackendGroupStreamBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - PEM-encoded trusted CA certificate chain.
     */
    sni: string;
    validationContext: outputs.GetAlbBackendGroupStreamBackendTlsValidationContext;
}

export interface GetAlbBackendGroupStreamBackendTlsValidationContext {
    trustedCaBytes: string;
    trustedCaId: string;
}

export interface GetAlbLoadBalancerAllocationPolicy {
    locations: outputs.GetAlbLoadBalancerAllocationPolicyLocation[];
}

export interface GetAlbLoadBalancerAllocationPolicyLocation {
    disableTraffic: boolean;
    subnetId: string;
    zoneId: string;
}

export interface GetAlbLoadBalancerListener {
    endpoints: outputs.GetAlbLoadBalancerListenerEndpoint[];
    https?: outputs.GetAlbLoadBalancerListenerHttp[];
    name: string;
    stream?: outputs.GetAlbLoadBalancerListenerStream;
    tls?: outputs.GetAlbLoadBalancerListenerTl[];
}

export interface GetAlbLoadBalancerListenerEndpoint {
    addresses: outputs.GetAlbLoadBalancerListenerEndpointAddress[];
    ports: number[];
}

export interface GetAlbLoadBalancerListenerEndpointAddress {
    externalIpv4Addresses: outputs.GetAlbLoadBalancerListenerEndpointAddressExternalIpv4Address[];
    externalIpv6Addresses: outputs.GetAlbLoadBalancerListenerEndpointAddressExternalIpv6Address[];
    internalIpv4Addresses: outputs.GetAlbLoadBalancerListenerEndpointAddressInternalIpv4Address[];
}

export interface GetAlbLoadBalancerListenerEndpointAddressExternalIpv4Address {
    address: string;
}

export interface GetAlbLoadBalancerListenerEndpointAddressExternalIpv6Address {
    address: string;
}

export interface GetAlbLoadBalancerListenerEndpointAddressInternalIpv4Address {
    address: string;
    subnetId: string;
}

export interface GetAlbLoadBalancerListenerHttp {
    handlers?: outputs.GetAlbLoadBalancerListenerHttpHandler[];
    redirects?: outputs.GetAlbLoadBalancerListenerHttpRedirect[];
}

export interface GetAlbLoadBalancerListenerHttpHandler {
    allowHttp10?: boolean;
    http2Options: outputs.GetAlbLoadBalancerListenerHttpHandlerHttp2Option[];
    httpRouterId: string;
}

export interface GetAlbLoadBalancerListenerHttpHandlerHttp2Option {
    maxConcurrentStreams: number;
}

export interface GetAlbLoadBalancerListenerHttpRedirect {
    httpToHttps: boolean;
}

export interface GetAlbLoadBalancerListenerStream {
    handlers?: outputs.GetAlbLoadBalancerListenerStreamHandler[];
}

export interface GetAlbLoadBalancerListenerStreamHandler {
    backendGroupId: string;
}

export interface GetAlbLoadBalancerListenerTl {
    defaultHandlers: outputs.GetAlbLoadBalancerListenerTlDefaultHandler[];
    sniHandlers: outputs.GetAlbLoadBalancerListenerTlSniHandler[];
}

export interface GetAlbLoadBalancerListenerTlDefaultHandler {
    certificateIds: string[];
    httpHandlers?: outputs.GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandler[];
    streamHandlers?: outputs.GetAlbLoadBalancerListenerTlDefaultHandlerStreamHandler[];
}

export interface GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandler {
    allowHttp10?: boolean;
    http2Options: outputs.GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandlerHttp2Option[];
    httpRouterId: string;
}

export interface GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandlerHttp2Option {
    maxConcurrentStreams: number;
}

export interface GetAlbLoadBalancerListenerTlDefaultHandlerStreamHandler {
    backendGroupId: string;
}

export interface GetAlbLoadBalancerListenerTlSniHandler {
    handlers: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandler[];
    name: string;
    serverNames: string[];
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandler {
    certificateIds: string[];
    httpHandlers?: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandler[];
    streamHandlers?: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandlerStreamHandler[];
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandler {
    allowHttp10?: boolean;
    http2Options: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandlerHttp2Option[];
    httpRouterId: string;
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandlerHttp2Option {
    maxConcurrentStreams: number;
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandlerStreamHandler {
    backendGroupId: string;
}

export interface GetAlbTargetGroupTarget {
    ipAddress: string;
    privateIpv4Address?: boolean;
    subnetId?: string;
}

export interface GetAlbVirtualHostModifyRequestHeader {
    /**
     * Append string to the header value.
     */
    append: string;
    /**
     * Name of the Virtual Host.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove: boolean;
    /**
     * New value for a header. Header values support the following
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace: string;
}

export interface GetAlbVirtualHostModifyResponseHeader {
    /**
     * Append string to the header value.
     */
    append: string;
    /**
     * Name of the Virtual Host.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove: boolean;
    /**
     * New value for a header. Header values support the following
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace: string;
}

export interface GetAlbVirtualHostRoute {
    /**
     * GRPC route resource. The structure is documented below.
     */
    grpcRoutes: outputs.GetAlbVirtualHostRouteGrpcRoute[];
    /**
     * HTTP route resource. The structure is documented below.
     */
    httpRoutes: outputs.GetAlbVirtualHostRouteHttpRoute[];
    /**
     * Name of the Virtual Host.
     */
    name: string;
}

export interface GetAlbVirtualHostRouteGrpcRoute {
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    grpcMatches: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcMatch[];
    /**
     * GRPC route action resource. The structure is documented below.
     */
    grpcRouteActions: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcRouteAction[];
    /**
     * (Required) GRPC status response action resource. The structure is documented below.
     */
    grpcStatusResponseActions: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction[];
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcMatch {
    /**
     * If not set, all services/methods are assumed. The structure is documented below.
     */
    fqmns: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcMatchFqmn[];
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcMatchFqmn {
    exact: string;
    prefix: string;
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the route. It
     * is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout to the maximum
     * time the stream is allowed to be alive. If not specified, there is no per-route idle timeout.
     */
    idleTimeout: string;
    /**
     * Lower timeout may be specified by the client (using grpc-timeout header). If not set, default is 60
     * seconds.
     */
    maxTimeout: string;
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction {
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, permission_denied,
     * unauthenticated, unimplemented, internal, unavailable.
     */
    status: string;
}

export interface GetAlbVirtualHostRouteHttpRoute {
    /**
     * (Required) Direct response action resource. The structure is documented below.
     */
    directResponseActions: outputs.GetAlbVirtualHostRouteHttpRouteDirectResponseAction[];
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    httpMatches: outputs.GetAlbVirtualHostRouteHttpRouteHttpMatch[];
    /**
     * HTTP route action resource. The structure is documented below.
     */
    httpRouteActions: outputs.GetAlbVirtualHostRouteHttpRouteHttpRouteAction[];
    /**
     * Redirect action resource. The structure is documented below.
     */
    redirectActions: outputs.GetAlbVirtualHostRouteHttpRouteRedirectAction[];
}

export interface GetAlbVirtualHostRouteHttpRouteDirectResponseAction {
    /**
     * Response body text.
     */
    body: string;
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, permission_denied,
     * unauthenticated, unimplemented, internal, unavailable.
     */
    status: number;
}

export interface GetAlbVirtualHostRouteHttpRouteHttpMatch {
    /**
     * List of methods(strings).
     */
    httpMethods: string[];
    /**
     * If not set, '/' is assumed. The structure is documented below.
     */
    paths: outputs.GetAlbVirtualHostRouteHttpRouteHttpMatchPath[];
}

export interface GetAlbVirtualHostRouteHttpRouteHttpMatchPath {
    exact: string;
    prefix: string;
}

export interface GetAlbVirtualHostRouteHttpRouteHttpRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the route. It
     * is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout to the maximum
     * time the stream is allowed to be alive. If not specified, there is no per-route idle timeout.
     */
    idleTimeout: string;
    /**
     * If not empty, matched path prefix will be replaced by this value.
     */
    prefixRewrite: string;
    /**
     * Specifies the request timeout (overall time request processing is allowed to take) for the route. If not
     * set, default is 60 seconds.
     */
    timeout: string;
    /**
     * List of upgrade types. Only specified upgrade types will be allowed. For example,
     * "websocket".
     */
    upgradeTypes: string[];
}

export interface GetAlbVirtualHostRouteHttpRouteRedirectAction {
    removeQuery: boolean;
    /**
     * Replaces hostname.
     */
    replaceHost: string;
    /**
     * Replace path.
     */
    replacePath: string;
    /**
     * Replaces port.
     */
    replacePort: number;
    /**
     * Replace only matched prefix. Example:<br/> match:{ prefix_match: "/some" } <br/>
     * redirect: { replace_prefix: "/other" } <br/> will redirect "/something" to "/otherthing".
     */
    replacePrefix: string;
    /**
     * Replaces scheme. If the original scheme is `http` or `https`, will also remove the 80 or 443 port,
     * if present.
     */
    replaceScheme: string;
    /**
     * The HTTP status code to use in the redirect response. Supported values are:
     * moved_permanently, found, see_other, temporary_redirect, permanent_redirect.
     */
    responseCode: string;
}

export interface GetCdnOriginGroupOrigin {
    backup?: boolean;
    enabled?: boolean;
    /**
     * The ID of a specific origin group.
     */
    originGroupId: number;
    source: string;
}

export interface GetCdnResourceOptions {
    /**
     * HTTP methods for your CDN content. By default the following methods are allowed: GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS. In case some methods are not allowed to the user, they will get the 405 (Method Not Allowed) response. If the method is not supported, the user gets the 501 (Not Implemented) response.
     */
    allowedHttpMethods: string[];
    /**
     * set up a cache period for the end-users browser. Content will be cached due to origin settings. If there are no cache settings on your origin, the content will not be cached. The list of HTTP response codes that can be cached in browsers: 200, 201, 204, 206, 301, 302, 303, 304, 307, 308. Other response codes will not be cached. The default value is 4 days.
     */
    browserCacheSettings: number;
    /**
     * list HTTP headers that must be included in responses to clients.
     */
    cacheHttpHeaders: string[];
    /**
     * parameter that lets browsers get access to selected resources from a domain different to a domain from which the request is received.
     */
    cors: string[];
    /**
     * custom value for the Host header. Your server must be able to process requests with the chosen header.
     */
    customHostHeader: string;
    /**
     * wildcard additional CNAME. If a resource has a wildcard additional CNAME, you can use your own certificate for content delivery via HTTPS. Read-only.
     */
    customServerName: string;
    /**
     * setup a cache status.
     */
    disableCache: boolean;
    /**
     * disabling proxy force ranges.
     */
    disableProxyForceRanges: boolean;
    /**
     * content will be cached according to origin cache settings. The value applies for a response with codes 200, 201, 204, 206, 301, 302, 303, 304, 307, 308 if an origin server does not have caching HTTP headers. Responses with other codes will not be cached.
     */
    edgeCacheSettings: number;
    /**
     * option helps you to reduce the bandwidth between origin and CDN servers. Also, content delivery speed becomes higher because of reducing the time for compressing files in a CDN.
     */
    fetchedCompressed: boolean;
    /**
     * choose the Forward Host header option if is important to send in the request to the Origin the same Host header as was sent in the request to CDN server.
     */
    forwardHostHeader: boolean;
    /**
     * GZip compression at CDN servers reduces file size by 70% and can be as high as 90%.
     */
    gzipOn: boolean;
    /**
     * set for ignoring cookie.
     */
    ignoreCookie: boolean;
    /**
     * files with different query parameters are cached as objects with the same key regardless of the parameter value. selected by default.
     */
    ignoreQueryParams: boolean;
    /**
     * allows caching for GET, HEAD and POST requests.
     */
    proxyCacheMethodsSet: boolean;
    /**
     * files with the specified query parameters are cached as objects with the same key, files with other parameters are cached as objects with different keys.
     */
    queryParamsBlacklists: string[];
    /**
     * files with the specified query parameters are cached as objects with different keys, files with other parameters are cached as objects with the same key.
     */
    queryParamsWhitelists: string[];
    /**
     * set up a redirect from HTTPS to HTTP.
     */
    redirectHttpToHttps: boolean;
    /**
     * set up a redirect from HTTP to HTTPS.
     */
    redirectHttpsToHttp: boolean;
    /**
     * files larger than 10 MB will be requested and cached in parts (no larger than 10 MB each part). It reduces time to first byte. The origin must support HTTP Range requests.
     */
    slice: boolean;
    /**
     * set up custom headers that CDN servers send in requests to origins.
     */
    staticRequestHeaders: string[];
    staticResponseHeaders: {[key: string]: string};
}

export interface GetCdnResourceSslCertificate {
    certificateManagerId?: string;
    status: string;
    type: string;
}

export interface GetComputeDiskDiskPlacementPolicy {
    diskPlacementGroupId: string;
}

export interface GetComputeInstanceBootDisk {
    /**
     * Specifies whether the disk is auto-deleted when the instance is deleted.
     */
    autoDelete: boolean;
    /**
     * This value can be used to reference the device from within the instance for mounting, resizing, and so on.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Parameters used for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams: outputs.GetComputeInstanceBootDiskInitializeParam[];
    /**
     * Access to the Disk resource. By default, a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeInstanceBootDiskInitializeParam {
    /**
     * The block size of the disk in bytes.
     */
    blockSize: number;
    /**
     * Description of the boot disk.
     */
    description: string;
    /**
     * A disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * Name of the instance.
     */
    name: string;
    /**
     * Size of the disk in GB.
     */
    size: number;
    /**
     * A snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Disk type.
     */
    type: string;
}

export interface GetComputeInstanceGroupAllocationPolicy {
    /**
     * A list of availability zones.
     */
    zones: string[];
}

export interface GetComputeInstanceGroupApplicationBalancerState {
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
}

export interface GetComputeInstanceGroupApplicationLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration: number;
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName: string;
}

export interface GetComputeInstanceGroupDeployPolicy {
    /**
     * The maximum number of instances that can be created at the same time.
     */
    maxCreating: number;
    /**
     * The maximum number of instances that can be deleted at the same time.
     */
    maxDeleting: number;
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size during the update process.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline (stopped or deleted) at the same time
     * during the update process.
     */
    maxUnavailable: number;
    /**
     * The amount of time in seconds to allow for an instance to start.
     */
    startupDuration: number;
    /**
     * Affects the lifecycle of the instance during deployment. If set to `proactive` (default), Instance Groups
     * can forcefully stop a running instance. If `opportunistic`, Instance Groups does not stop a running instance. Instead,
     * it will wait until the instance stops itself or becomes unhealthy.
     */
    strategy: string;
}

export interface GetComputeInstanceGroupHealthCheck {
    /**
     * The number of successful health checks before the managed instance is declared healthy.
     */
    healthyThreshold: number;
    /**
     * HTTP check options. The structure is documented below.
     */
    httpOptions: outputs.GetComputeInstanceGroupHealthCheckHttpOption[];
    /**
     * The interval between health checks in seconds.
     */
    interval: number;
    /**
     * TCP check options. The structure is documented below.
     */
    tcpOptions: outputs.GetComputeInstanceGroupHealthCheckTcpOption[];
    /**
     * Timeout for the managed instance to return a response for the health check in seconds.
     */
    timeout: number;
    /**
     * The number of failed health checks before the managed instance is declared unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetComputeInstanceGroupHealthCheckHttpOption {
    /**
     * The URL path used for health check requests.
     */
    path: string;
    /**
     * The port to use for TCP health checks.
     */
    port: number;
}

export interface GetComputeInstanceGroupHealthCheckTcpOption {
    /**
     * The port to use for TCP health checks.
     */
    port: number;
}

export interface GetComputeInstanceGroupInstance {
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * The ID of the instance.
     */
    instanceId: string;
    /**
     * The name of the managed instance.
     */
    name: string;
    /**
     * An array with the network interfaces attached to the managed instance. The structure is documented below.
     * * `statusChangedAt` -The timestamp when the status of the managed instance was last changed.
     */
    networkInterfaces: outputs.GetComputeInstanceGroupInstanceNetworkInterface[];
    /**
     * The status of the instance.
     */
    status: string;
    statusChangedAt: string;
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * The ID of the availability zone where the instance resides.
     */
    zoneId: string;
}

export interface GetComputeInstanceGroupInstanceNetworkInterface {
    /**
     * The index of the network interface as generated by the server.
     */
    index: number;
    /**
     * The private IP address to assign to the instance. If empty, the address is automatically assigned from the specified subnet.
     */
    ipAddress: string;
    /**
     * Is IPv4 address assigned.
     */
    ipv4: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * The MAC address assigned to the network interface.
     */
    macAddress: string;
    /**
     * The instance's public address for accessing the internet over NAT.
     */
    nat: boolean;
    /**
     * The public IP address of the instance.
     */
    natIpAddress: string;
    /**
     * The IP version for the public address.
     */
    natIpVersion: string;
    /**
     * The ID of the subnet to attach this interface to. The subnet must reside in the same zone where this instance was created.
     */
    subnetId: string;
}

export interface GetComputeInstanceGroupInstanceTemplate {
    /**
     * The specifications for boot disk that will be attached to the instance. The structure is documented below.
     */
    bootDisks: outputs.GetComputeInstanceGroupInstanceTemplateBootDisk[];
    /**
     * A description of the boot disk.
     */
    description: string;
    /**
     * Hostname temaplate for the instance.
     */
    hostname: string;
    /**
     * A map of labels applied to this instance.
     * * `resources.0.memory` - The memory size allocated to the instance.
     * * `resources.0.cores` - Number of CPU cores allocated to the instance.
     * * `resources.0.core_fraction` - Baseline core performance as a percent.
     * * `resources.0.gpus` - Number of GPU cores allocated to the instance.
     */
    labels: {[key: string]: string};
    /**
     * The set of metadata `key:value` pairs assigned to this instance template. This includes custom metadata and predefined keys.
     */
    metadata: {[key: string]: string};
    /**
     * The name of the managed instance.
     */
    name: string;
    /**
     * An array with the network interfaces attached to the managed instance. The structure is documented below.
     * * `statusChangedAt` -The timestamp when the status of the managed instance was last changed.
     */
    networkInterfaces: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterface[];
    /**
     * Network acceleration settings. The structure is documented below.
     */
    networkSettings: outputs.GetComputeInstanceGroupInstanceTemplateNetworkSetting[];
    placementPolicy?: outputs.GetComputeInstanceGroupInstanceTemplatePlacementPolicy;
    /**
     * The ID of the hardware platform configuration for the instance.
     */
    platformId: string;
    resources: outputs.GetComputeInstanceGroupInstanceTemplateResource[];
    /**
     * The scheduling policy for the instance. The structure is documented below.
     */
    schedulingPolicies: outputs.GetComputeInstanceGroupInstanceTemplateSchedulingPolicy[];
    /**
     * An array with the secondary disks that will be attached to the instance. The structure is documented below.
     */
    secondaryDisks: outputs.GetComputeInstanceGroupInstanceTemplateSecondaryDisk[];
    /**
     * The service account ID for the instance.
     */
    serviceAccountId: string;
}

export interface GetComputeInstanceGroupInstanceTemplateBootDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId: string;
    /**
     * The parameters used for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams: outputs.GetComputeInstanceGroupInstanceTemplateBootDiskInitializeParam[];
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeInstanceGroupInstanceTemplateBootDiskInitializeParam {
    /**
     * A description of the boot disk.
     */
    description: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * The size of the disk in GB.
     */
    size: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type: string;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterface {
    /**
     * List of dns records.  The structure is documented below.
     */
    dnsRecords: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord[];
    /**
     * The private IP address to assign to the instance. If empty, the address is automatically assigned from the specified subnet.
     */
    ipAddress: string;
    /**
     * Is IPv4 address assigned.
     */
    ipv4: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * List of ipv6 dns records.  The structure is documented below.
     */
    ipv6DnsRecords: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord[];
    /**
     * The instance's public address for accessing the internet over NAT.
     */
    nat: boolean;
    /**
     * List of nat dns records.  The structure is documented below.
     */
    natDnsRecords: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord[];
    /**
     * The public IP address of the instance.
     */
    natIpAddress: string;
    /**
     * The ID of the network.
     */
    networkId: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * The IDs of the subnets.
     */
    subnetIds: string[];
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord {
    /**
     * DNS zone id (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl: number;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone id (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl: number;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone id (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl: number;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkSetting {
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type: string;
}

export interface GetComputeInstanceGroupInstanceTemplatePlacementPolicy {
    placementGroupId: string;
}

export interface GetComputeInstanceGroupInstanceTemplateResource {
    coreFraction: number;
    cores: number;
    gpus: number;
    memory: number;
}

export interface GetComputeInstanceGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible: boolean;
}

export interface GetComputeInstanceGroupInstanceTemplateSecondaryDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId: string;
    /**
     * The parameters used for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams: outputs.GetComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParam[];
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParam {
    /**
     * A description of the boot disk.
     */
    description: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * The size of the disk in GB.
     */
    size: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type: string;
}

export interface GetComputeInstanceGroupLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration: number;
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName: string;
}

export interface GetComputeInstanceGroupLoadBalancerState {
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
}

export interface GetComputeInstanceGroupScalePolicy {
    /**
     * The auto scaling policy of the instance group. The structure is documented below.
     */
    autoScales: outputs.GetComputeInstanceGroupScalePolicyAutoScale[];
    /**
     * The fixed scaling policy of the instance group. The structure is documented below.
     */
    fixedScales: outputs.GetComputeInstanceGroupScalePolicyFixedScale[];
    /**
     * The test auto scaling policy of the instance group. Use it to test how the auto scale works. The structure is documented below.
     */
    testAutoScales: outputs.GetComputeInstanceGroupScalePolicyTestAutoScale[];
}

export interface GetComputeInstanceGroupScalePolicyAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules: outputs.GetComputeInstanceGroupScalePolicyAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface GetComputeInstanceGroupScalePolicyAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId: string;
    /**
     * A map of labels applied to this instance.
     * * `resources.0.memory` - The memory size allocated to the instance.
     * * `resources.0.cores` - Number of CPU cores allocated to the instance.
     * * `resources.0.core_fraction` - Baseline core performance as a percent.
     * * `resources.0.gpus` - Number of GPU cores allocated to the instance.
     */
    labels: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface GetComputeInstanceGroupScalePolicyFixedScale {
    /**
     * The size of the disk in GB.
     */
    size: number;
}

export interface GetComputeInstanceGroupScalePolicyTestAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules: outputs.GetComputeInstanceGroupScalePolicyTestAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface GetComputeInstanceGroupScalePolicyTestAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId: string;
    /**
     * A map of labels applied to this instance.
     * * `resources.0.memory` - The memory size allocated to the instance.
     * * `resources.0.cores` - Number of CPU cores allocated to the instance.
     * * `resources.0.core_fraction` - Baseline core performance as a percent.
     * * `resources.0.gpus` - Number of GPU cores allocated to the instance.
     */
    labels: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface GetComputeInstanceNetworkInterface {
    /**
     * List of configurations for creating ipv4 DNS records. The structure is documented below.
     */
    dnsRecords: outputs.GetComputeInstanceNetworkInterfaceDnsRecord[];
    /**
     * The index of the network interface, generated by the server.
     */
    index: number;
    /**
     * The assignd private IP address to the network interface.
     */
    ipAddress: string;
    /**
     * Show if IPv4 address is assigned to the network interface.
     */
    ipv4: boolean;
    ipv6: boolean;
    ipv6Address: string;
    /**
     * List of configurations for creating ipv6 DNS records. The structure is documented below.
     */
    ipv6DnsRecords: outputs.GetComputeInstanceNetworkInterfaceIpv6DnsRecord[];
    /**
     * MAC address that is assigned to the network interface.
     */
    macAddress: string;
    /**
     * Assigned for the instance's public address that is used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * List of configurations for creating ipv4 NAT DNS records. The structure is documented below.
     */
    natDnsRecords: outputs.GetComputeInstanceNetworkInterfaceNatDnsRecord[];
    /**
     * Public IP address of the instance.
     */
    natIpAddress: string;
    /**
     * IP version for the public address.
     */
    natIpVersion: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * ID of the subnet to attach this interface to. The subnet must reside in the same zone where this instance was created.
     */
    subnetId: string;
}

export interface GetComputeInstanceNetworkInterfaceDnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a TR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl: number;
}

export interface GetComputeInstanceNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a TR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl: number;
}

export interface GetComputeInstanceNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a TR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl: number;
}

export interface GetComputeInstancePlacementPolicy {
    placementGroupId: string;
}

export interface GetComputeInstanceResource {
    coreFraction: number;
    cores: number;
    gpus: number;
    memory: number;
}

export interface GetComputeInstanceSchedulingPolicy {
    /**
     * (Optional) Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible?: boolean;
}

export interface GetComputeInstanceSecondaryDisk {
    /**
     * Specifies whether the disk is auto-deleted when the instance is deleted.
     */
    autoDelete: boolean;
    /**
     * This value can be used to reference the device from within the instance for mounting, resizing, and so on.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Access to the Disk resource. By default, a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetDataprocClusterClusterConfig {
    /**
     * Data Proc specific options. The structure is documented below.
     */
    hadoops: outputs.GetDataprocClusterClusterConfigHadoop[];
    /**
     * Configuration of the Data Proc subcluster. The structure is documented below.
     */
    subclusterSpecs: outputs.GetDataprocClusterClusterConfigSubclusterSpec[];
    /**
     * Version of Data Proc image.
     */
    versionId: string;
}

export interface GetDataprocClusterClusterConfigHadoop {
    /**
     * A set of key/value pairs used to configure cluster services.
     */
    properties: {[key: string]: string};
    /**
     * List of services launched on Data Proc cluster.
     */
    services: string[];
    /**
     * List of SSH public keys distributed to the hosts of the cluster.
     */
    sshPublicKeys: string[];
}

export interface GetDataprocClusterClusterConfigSubclusterSpec {
    /**
     * Optional autoscaling configuration for compute subclusters.
     */
    autoscalingConfigs: outputs.GetDataprocClusterClusterConfigSubclusterSpecAutoscalingConfig[];
    /**
     * Number of hosts within Data Proc subcluster.
     */
    hostsCount: number;
    /**
     * ID of the Data Proc subcluster.
     */
    id: string;
    /**
     * The name of the Data Proc cluster.
     */
    name: string;
    /**
     * Resources allocated to each host of the Data Proc subcluster. The structure is documented below.
     */
    resources: outputs.GetDataprocClusterClusterConfigSubclusterSpecResource[];
    /**
     * Role of the subcluster in the Data Proc cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which hosts of the subcluster belong.
     */
    subnetId: string;
}

export interface GetDataprocClusterClusterConfigSubclusterSpecAutoscalingConfig {
    /**
     * Defines an autoscaling rule based on the average CPU utilization of the instance group. If not set default autoscaling metric will be used.
     */
    cpuUtilizationTarget: number;
    /**
     * Timeout to gracefully decommission nodes during downscaling. In seconds.
     */
    decommissionTimeout: number;
    /**
     * Maximum number of nodes in autoscaling subclusters.
     */
    maxHostsCount: number;
    /**
     * Time in seconds allotted for averaging metrics.
     */
    measurementDuration: number;
    /**
     * Bool flag -- whether to use preemptible compute instances. Preemptible instances are stopped at least once every 24 hours, and can be stopped at any time if their resources are needed by Compute. For more information, see [Preemptible Virtual Machines](https://cloud.yandex.com/docs/compute/concepts/preemptible-vm).
     */
    preemptible: boolean;
    /**
     * Minimum amount of time in seconds allotted for monitoring before Instance Groups can reduce the number of instances in the group. During this time, the group size doesn't decrease, even if the new metric values indicate that it should.
     */
    stabilizationDuration: number;
    /**
     * The warmup time of the instance in seconds. During this time, traffic is sent to the instance, but instance metrics are not collected.
     */
    warmupDuration: number;
}

export interface GetDataprocClusterClusterConfigSubclusterSpecResource {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of a host.
     */
    diskTypeId: string;
    /**
     * The ID of the preset for computational resources available to a host. All available presets are listed in the [documentation](https://cloud.yandex.com/docs/data-proc/concepts/instance-types).
     */
    resourcePresetId: string;
}

export interface GetFunctionScalingPolicyPolicy {
    tag: string;
    zoneInstancesLimit?: number;
    zoneRequestsLimit?: number;
}

export interface GetFunctionTriggerDlq {
    queueId: string;
    serviceAccountId: string;
}

export interface GetFunctionTriggerFunction {
    id: string;
    retryAttempts: string;
    retryInterval: string;
    serviceAccountId: string;
    tag: string;
}

export interface GetFunctionTriggerIot {
    deviceId: string;
    registryId: string;
    topic: string;
}

export interface GetFunctionTriggerLogGroup {
    batchCutoff: string;
    batchSize: string;
    logGroupIds: string[];
}

export interface GetFunctionTriggerLogging {
    batchCutoff: string;
    batchSize: string;
    groupId: string;
    levels: string[];
    resourceIds: string[];
    resourceTypes: string[];
}

export interface GetFunctionTriggerMessageQueue {
    batchCutoff: string;
    batchSize: string;
    queueId: string;
    serviceAccountId: string;
    visibilityTimeout: string;
}

export interface GetFunctionTriggerObjectStorage {
    bucketId: string;
    create: boolean;
    delete: boolean;
    prefix: string;
    suffix: string;
    update: boolean;
}

export interface GetFunctionTriggerTimer {
    cronExpression: string;
}

export interface GetIamPolicyBinding {
    /**
     * An array of identities that will be granted the privilege in the `role`.
     * Each entry can have one of the following values:
     * * **userAccount:{user_id}**: A unique user ID that represents a specific Yandex account.
     * * **serviceAccount:{service_account_id}**: A unique service account ID.
     */
    members: string[];
    /**
     * The role/permission that will be granted to the members.
     * See the [IAM Roles] documentation for a complete list of roles.
     */
    role: string;
}

export interface GetKubernetesClusterKmsProvider {
    /**
     * KMS key ID.
     */
    keyId: string;
}

export interface GetKubernetesClusterMaster {
    /**
     * PEM-encoded public certificate that is the root of trust for the Kubernetes cluster.
     */
    clusterCaCertificate: string;
    /**
     * An IPv4 external network address that is assigned to the master.
     */
    externalV4Address: string;
    /**
     * External endpoint that can be used to access Kubernetes cluster API from the internet (outside of the cloud).
     */
    externalV4Endpoint: string;
    /**
     * An IPv4 internal network address that is assigned to the master.
     */
    internalV4Address: string;
    /**
     * Internal endpoint that can be used to connect to the master from cloud networks.
     */
    internalV4Endpoint: string;
    /**
     * Maintenance policy for Kubernetes master. The structure is documented below.
     */
    maintenancePolicies: outputs.GetKubernetesClusterMasterMaintenancePolicy[];
    /**
     * Boolean flag. When `true`, Kubernetes master have visible ipv4 address.
     */
    publicIp: boolean;
    /**
     * Information about cluster regional master. The structure is documented below.
     */
    regionals: outputs.GetKubernetesClusterMasterRegional[];
    /**
     * A list of security groups IDs of the Kubernetes cluster.
     */
    securityGroupIds: string[];
    /**
     * Version of Kubernetes master.
     */
    version: string;
    /**
     * Information about cluster version. The structure is documented below.
     */
    versionInfos: outputs.GetKubernetesClusterMasterVersionInfo[];
    /**
     * Information about cluster zonal master. The structure is documented below.
     */
    zonals: outputs.GetKubernetesClusterMasterZonal[];
}

export interface GetKubernetesClusterMasterMaintenancePolicy {
    /**
     * Boolean flag that specifies if master can be upgraded automatically.
     */
    autoUpgrade: boolean;
    /**
     * Set of day intervals, when maintenance is allowed, when update for master is allowed.
     * When omitted, it defaults to any time.
     */
    maintenanceWindows: outputs.GetKubernetesClusterMasterMaintenancePolicyMaintenanceWindow[];
}

export interface GetKubernetesClusterMasterMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface GetKubernetesClusterMasterRegional {
    /**
     * ID of the availability region where the master compute instances resides.
     */
    region: string;
}

export interface GetKubernetesClusterMasterVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * True/false flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * True/false flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface GetKubernetesClusterMasterZonal {
    /**
     * ID of the availability zone where the master compute instance resides.
     */
    zone: string;
}

export interface GetKubernetesClusterNetworkImplementation {
    /**
     * Cilium network implementation configuration. No options exist.
     */
    cilias: outputs.GetKubernetesClusterNetworkImplementationCilia[];
}

export interface GetKubernetesClusterNetworkImplementationCilia {
    routingMode: string;
}

export interface GetKubernetesNodeGroupAllocationPolicy {
    /**
     * Repeated field, that specify subnets (zones), that will be used by node group compute instances. The structure is documented below.
     */
    locations: outputs.GetKubernetesNodeGroupAllocationPolicyLocation[];
}

export interface GetKubernetesNodeGroupAllocationPolicyLocation {
    /**
     * ID of the subnet, that will be used by one compute instance in node group.
     */
    subnetId: string;
    /**
     * ID of the availability zone where for one compute instance in node group.
     */
    zone: string;
}

export interface GetKubernetesNodeGroupDeployPolicy {
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size during the update.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline during update.
     */
    maxUnavailable: number;
}

export interface GetKubernetesNodeGroupInstanceTemplate {
    /**
     * The specifications for boot disks that will be attached to the instance. The structure is documented below.
     */
    bootDisks: outputs.GetKubernetesNodeGroupInstanceTemplateBootDisk[];
    /**
     * Container runtime configuration. The structure is documented below.
     * ---
     */
    containerRuntime: outputs.GetKubernetesNodeGroupInstanceTemplateContainerRuntime;
    /**
     * The set of metadata `key:value` pairs assigned to this instance template. This includes custom metadata and predefined keys.
     */
    metadata: {[key: string]: string};
    /**
     * A public address that can be used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * Type of network acceleration. Values: `standard`, `softwareAccelerated`.
     */
    networkAccelerationType: string;
    /**
     * An array with the network interfaces that will be attached to the instance. The structure is documented below.
     */
    networkInterfaces: outputs.GetKubernetesNodeGroupInstanceTemplateNetworkInterface[];
    /**
     * (Optional) The placement policy configuration. The structure is documented below.
     */
    placementPolicies?: outputs.GetKubernetesNodeGroupInstanceTemplatePlacementPolicy[];
    /**
     * The ID of the hardware platform configuration for the instance.
     */
    platformId: string;
    resources: outputs.GetKubernetesNodeGroupInstanceTemplateResource[];
    /**
     * The scheduling policy for the instances in node group. The structure is documented below.
     */
    schedulingPolicies: outputs.GetKubernetesNodeGroupInstanceTemplateSchedulingPolicy[];
}

export interface GetKubernetesNodeGroupInstanceTemplateBootDisk {
    /**
     * The number of instances in the node group.
     */
    size: number;
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface GetKubernetesNodeGroupInstanceTemplateContainerRuntime {
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface GetKubernetesNodeGroupInstanceTemplateNetworkInterface {
    /**
     * Indicates whether the IPv4 address has been assigned.
     */
    ipv4: boolean;
    /**
     * Indicates whether the IPv6 address has been assigned.
     */
    ipv6: boolean;
    /**
     * A public address that can be used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * The IDs of the subnets.
     */
    subnetIds: string[];
}

export interface GetKubernetesNodeGroupInstanceTemplatePlacementPolicy {
    /**
     * (Optional) Specifies the id of the Placement Group to assign to the instances.
     */
    placementGroupId: string;
}

export interface GetKubernetesNodeGroupInstanceTemplateResource {
    coreFraction: number;
    cores: number;
    gpus: number;
    memory: number;
}

export interface GetKubernetesNodeGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     * ---
     */
    preemptible: boolean;
}

export interface GetKubernetesNodeGroupMaintenancePolicy {
    /**
     * Boolean flag.
     */
    autoRepair: boolean;
    /**
     * Boolean flag.
     */
    autoUpgrade: boolean;
    /**
     * Set of day intervals, when maintenance is allowed for this node group.
     * When omitted, it defaults to any time.
     */
    maintenanceWindows: outputs.GetKubernetesNodeGroupMaintenancePolicyMaintenanceWindow[];
}

export interface GetKubernetesNodeGroupMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface GetKubernetesNodeGroupScalePolicy {
    /**
     * Scale policy for an autoscaled node group. The structure is documented below.
     */
    autoScales: outputs.GetKubernetesNodeGroupScalePolicyAutoScale[];
    /**
     * Scale policy for a fixed scale node group. The structure is documented below.
     */
    fixedScales: outputs.GetKubernetesNodeGroupScalePolicyFixedScale[];
}

export interface GetKubernetesNodeGroupScalePolicyAutoScale {
    /**
     * Initial number of instances in the node group.
     */
    initial: number;
    /**
     * Maximum number of instances in the node group.
     */
    max: number;
    /**
     * Minimum number of instances in the node group.
     */
    min: number;
}

export interface GetKubernetesNodeGroupScalePolicyFixedScale {
    /**
     * The number of instances in the node group.
     */
    size: number;
}

export interface GetKubernetesNodeGroupVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * True/false flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * True/false flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroup {
    healthchecks: outputs.GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheck[];
    /**
     * ID of the target group that attached to the network load balancer.
     * * `healthcheck.0.name` - Name of the health check.
     * * `healthcheck.0.interval` - The interval between health checks.
     * * `healthcheck.0.timeout` - Timeout for a target to return a response for the health check.
     * * `healthcheck.0.unhealthy_threshold` - Number of failed health checks before changing the status to `UNHEALTHY`.
     * * `healthcheck.0.healthy_threshold` - Number of successful health checks required in order to set the `HEALTHY` status for the target.
     * * `healthcheck.0.tcp_options.0.port` - Port to use for TCP health checks.
     * * `healthcheck.0.http_options.0.port` - Port to use for HTTP health checks.
     * * `healthcheck.0.http_options.0.path` - URL path to use for HTTP health checks.
     */
    targetGroupId: string;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheck {
    healthyThreshold: number;
    httpOptions: outputs.GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOption[];
    interval: number;
    /**
     * - Name of the network load balancer.
     */
    name: string;
    tcpOptions: outputs.GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOption[];
    timeout: number;
    unhealthyThreshold: number;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOption {
    path: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOption {
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface GetLbNetworkLoadBalancerListener {
    externalAddressSpecs: outputs.GetLbNetworkLoadBalancerListenerExternalAddressSpec[];
    internalAddressSpecs: outputs.GetLbNetworkLoadBalancerListenerInternalAddressSpec[];
    /**
     * - Name of the network load balancer.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * Protocol for incoming traffic.
     */
    protocol: string;
    /**
     * Port of a target. 
     * * `external_address_spec.0.address` - External IP address of a listener.
     * * `external_address_spec.0.ip_version` - IP version of the external addresses.
     * * `internal_address_spec.0.subnet_id` - Subnet ID to which the internal IP address belongs
     * * `internal_address_spec.0.address` - Internal IP address of a listener.
     * * `internal_address_spec.0.ip_version` - IP version of the internal addresses.
     */
    targetPort: number;
}

export interface GetLbNetworkLoadBalancerListenerExternalAddressSpec {
    address: string;
    ipVersion: string;
}

export interface GetLbNetworkLoadBalancerListenerInternalAddressSpec {
    address: string;
    ipVersion: string;
    subnetId: string;
}

export interface GetLbTargetGroupTarget {
    address: string;
    subnetId: string;
}

export interface GetMdbClickhouseClusterAccess {
    /**
     * Allow access for Web SQL.
     */
    dataLens: boolean;
    /**
     * Allow access for Yandex.Metrika.
     */
    metrika: boolean;
    /**
     * Allow access for Serverless.
     */
    serverless: boolean;
    /**
     * Allow access for DataLens.
     */
    webSql: boolean;
}

export interface GetMdbClickhouseClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours: number;
    /**
     * The minute at which backup will be started.
     */
    minutes: number;
}

export interface GetMdbClickhouseClusterClickhouse {
    /**
     * Main ClickHouse cluster configuration. The structure is documented below.
     */
    config: outputs.GetMdbClickhouseClusterClickhouseConfig;
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbClickhouseClusterClickhouseResource[];
}

export interface GetMdbClickhouseClusterClickhouseConfig {
    backgroundPoolSize?: number;
    backgroundSchedulePoolSize?: number;
    /**
     * Data compression configuration. The structure is documented below.
     */
    compressions?: outputs.GetMdbClickhouseClusterClickhouseConfigCompression[];
    geobaseUri?: string;
    /**
     * Graphite rollup configuration. The structure is documented below.
     */
    graphiteRollups?: outputs.GetMdbClickhouseClusterClickhouseConfigGraphiteRollup[];
    /**
     * Kafka topic connection configuration. The structure is documented below.
     */
    kafkaTopics?: outputs.GetMdbClickhouseClusterClickhouseConfigKafkaTopic[];
    /**
     * Kafka connection configuration. The structure is documented below.
     */
    kafkas: outputs.GetMdbClickhouseClusterClickhouseConfigKafka[];
    keepAliveTimeout?: number;
    logLevel?: string;
    markCacheSize?: number;
    maxConcurrentQueries?: number;
    maxConnections?: number;
    maxPartitionSizeToDrop?: number;
    maxTableSizeToDrop?: number;
    /**
     * MergeTree engine configuration. The structure is documented below.
     */
    mergeTree: outputs.GetMdbClickhouseClusterClickhouseConfigMergeTree;
    metricLogEnabled?: boolean;
    metricLogRetentionSize?: number;
    metricLogRetentionTime?: number;
    partLogRetentionSize?: number;
    partLogRetentionTime?: number;
    queryLogRetentionSize?: number;
    queryLogRetentionTime?: number;
    queryThreadLogEnabled?: boolean;
    queryThreadLogRetentionSize?: number;
    queryThreadLogRetentionTime?: number;
    /**
     * RabbitMQ connection configuration. The structure is documented below.
     */
    rabbitmq: outputs.GetMdbClickhouseClusterClickhouseConfigRabbitmq;
    textLogEnabled?: boolean;
    textLogLevel?: string;
    textLogRetentionSize?: number;
    textLogRetentionTime?: number;
    timezone?: string;
    traceLogEnabled?: boolean;
    traceLogRetentionSize?: number;
    traceLogRetentionTime?: number;
    uncompressedCacheSize?: number;
}

export interface GetMdbClickhouseClusterClickhouseConfigCompression {
    /**
     * Method: Compression method. Two methods are available: LZ4 and zstd.
     */
    method: string;
    /**
     * Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
     */
    minPartSize: number;
    /**
     * Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
     */
    minPartSizeRatio: number;
}

export interface GetMdbClickhouseClusterClickhouseConfigGraphiteRollup {
    /**
     * The name of the ClickHouse cluster.
     */
    name: string;
    /**
     * Set of thinning rules.
     */
    patterns?: outputs.GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPattern[];
}

export interface GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPattern {
    /**
     * Aggregation function name.
     */
    function: string;
    /**
     * Regular expression that the metric name must match.
     */
    regexp?: string;
    /**
     * Retain parameters.
     */
    retentions?: outputs.GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention[];
}

export interface GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention {
    /**
     * Minimum data age in seconds.
     */
    age: number;
    /**
     * Accuracy of determining the age of the data in seconds.
     */
    precision: number;
}

export interface GetMdbClickhouseClusterClickhouseConfigKafka {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism?: string;
    /**
     * User password on kafka server.
     */
    saslPassword?: string;
    /**
     * Username on kafka server.
     */
    saslUsername?: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol?: string;
}

export interface GetMdbClickhouseClusterClickhouseConfigKafkaTopic {
    /**
     * The name of the ClickHouse cluster.
     */
    name: string;
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings?: outputs.GetMdbClickhouseClusterClickhouseConfigKafkaTopicSettings;
}

export interface GetMdbClickhouseClusterClickhouseConfigKafkaTopicSettings {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism?: string;
    /**
     * User password on kafka server.
     */
    saslPassword?: string;
    /**
     * Username on kafka server.
     */
    saslUsername?: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol?: string;
}

export interface GetMdbClickhouseClusterClickhouseConfigMergeTree {
    /**
     * Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
     */
    maxBytesToMergeAtMinSpaceInPool?: number;
    /**
     * Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
     */
    maxReplicatedMergesInQueue?: number;
    /**
     * Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
     */
    numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge?: number;
    /**
     * Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
     */
    partsToDelayInsert?: number;
    /**
     * Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
     */
    partsToThrowInsert?: number;
    /**
     * Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
     */
    replicatedDeduplicationWindow?: number;
    /**
     * Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
     */
    replicatedDeduplicationWindowSeconds?: number;
}

export interface GetMdbClickhouseClusterClickhouseConfigRabbitmq {
    /**
     * RabbitMQ user password.
     */
    password?: string;
    /**
     * RabbitMQ username.
     */
    username?: string;
}

export interface GetMdbClickhouseClusterClickhouseResource {
    /**
     * Volume of the storage available to a ClickHouse or ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ClickHouse or ZooKeeper hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbClickhouseClusterCloudStorage {
    /**
     * (Required) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
     */
    enabled: boolean;
}

export interface GetMdbClickhouseClusterDatabase {
    /**
     * The name of the ClickHouse cluster.
     */
    name: string;
}

export interface GetMdbClickhouseClusterFormatSchema {
    /**
     * The name of the ClickHouse cluster.
     */
    name: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri: string;
}

export interface GetMdbClickhouseClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation.
     */
    assignPublicIp: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * The availability zone where the ClickHouse host will be created.
     */
    zone: string;
}

export interface GetMdbClickhouseClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface GetMdbClickhouseClusterMlModel {
    /**
     * The name of the ClickHouse cluster.
     */
    name: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri: string;
}

export interface GetMdbClickhouseClusterShardGroup {
    /**
     * Description of the shard group.
     */
    description: string;
    /**
     * The name of the ClickHouse cluster.
     */
    name: string;
    /**
     * List of shards names that belong to the shard group.
     */
    shardNames: string[];
}

export interface GetMdbClickhouseClusterUser {
    /**
     * The name of the ClickHouse cluster.
     */
    name: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbClickhouseClusterUserPermission[];
    /**
     * Set of user quotas. The structure is documented below.
     */
    quotas: outputs.GetMdbClickhouseClusterUserQuota[];
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings: outputs.GetMdbClickhouseClusterUserSettings;
}

export interface GetMdbClickhouseClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
}

export interface GetMdbClickhouseClusterUserQuota {
    /**
     * The number of queries that threw exception.
     */
    errors: number;
    /**
     * The total query execution time, in milliseconds (wall time).
     */
    executionTime: number;
    /**
     * Duration of interval for quota in milliseconds.
     */
    intervalDuration: number;
    /**
     * The total number of queries.
     */
    queries: number;
    /**
     * The total number of source rows read from tables for running the query, on all remote servers.
     */
    readRows: number;
    /**
     * The total number of rows given as the result.
     */
    resultRows: number;
}

export interface GetMdbClickhouseClusterUserSettings {
    /**
     * Include CORS headers in HTTP responces.
     */
    addHttpCorsHeader: boolean;
    /**
     * Allows or denies DDL queries.
     */
    allowDdl: boolean;
    /**
     * Enable compilation of queries.
     */
    compile: boolean;
    /**
     * Turn on expression compilation.
     */
    compileExpressions: boolean;
    /**
     * Connect timeout in milliseconds on the socket used for communicating with the client.
     */
    connectTimeout: number;
    /**
     * Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT ) construction.
     */
    countDistinctImplementation: string;
    /**
     * Sets behaviour on overflow when using DISTINCT. Possible values:
     */
    distinctOverflowMode: string;
    /**
     * Determine the behavior of distributed subqueries.
     */
    distributedAggregationMemoryEfficient: boolean;
    /**
     * Timeout for DDL queries, in milliseconds.
     */
    distributedDdlTaskTimeout: number;
    /**
     * Changes the behaviour of distributed subqueries.
     */
    distributedProductMode: string;
    /**
     * Allows to retunr empty result.
     */
    emptyResultForAggregationByEmptySet: boolean;
    /**
     * Enables or disables data compression in the response to an HTTP request.
     */
    enableHttpCompression: boolean;
    /**
     * Forces a query to an out-of-date replica if updated data is not available.
     */
    fallbackToStaleReplicasForDistributedQueries: boolean;
    /**
     * Disables query execution if the index cant be used by date.
     */
    forceIndexByDate: boolean;
    /**
     * Disables query execution if indexing by the primary key is not possible.
     */
    forcePrimaryKey: boolean;
    /**
     * Sets behaviour on overflow while GROUP BY operation. Possible values:
     */
    groupByOverflowMode: string;
    /**
     * Sets the threshold of the number of keys, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThreshold: number;
    /**
     * Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThresholdBytes: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpConnectionTimeout: number;
    /**
     * Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
     */
    httpHeadersProgressInterval: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpReceiveTimeout: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpSendTimeout: number;
    /**
     * When performing INSERT queries, replace omitted input column values with default values of the respective columns.
     */
    inputFormatDefaultsForOmittedFields: boolean;
    /**
     * Enables or disables the full SQL parser if the fast stream parser cant parse the data.
     */
    inputFormatValuesInterpretExpressions: boolean;
    /**
     * Enables the quorum writes.
     */
    insertQuorum: number;
    /**
     * Write to a quorum timeout in milliseconds.
     */
    insertQuorumTimeout: number;
    /**
     * Sets behaviour on overflow in JOIN. Possible values:
     */
    joinOverflowMode: string;
    /**
     * Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
     */
    joinUseNulls: boolean;
    /**
     * Require aliases for subselects and table functions in FROM that more than one table is present.
     */
    joinedSubqueryRequiresAlias: boolean;
    /**
     * Allows or restricts using the LowCardinality data type with the Native format.
     */
    lowCardinalityAllowInNativeFormat: boolean;
    /**
     * Maximum abstract syntax tree depth.
     */
    maxAstDepth: number;
    /**
     * Maximum abstract syntax tree elements.
     */
    maxAstElements: number;
    /**
     * A recommendation for what size of the block (in a count of rows) to load from tables.
     */
    maxBlockSize: number;
    /**
     * Limit in bytes for using memoru for GROUP BY before using swap on disk.
     */
    maxBytesBeforeExternalGroupBy: number;
    /**
     * This setting is equivalent of the maxBytesBeforeExternalGroupBy setting, except for it is for sort operation (ORDER BY), not aggregation.
     */
    maxBytesBeforeExternalSort: number;
    /**
     * Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
     */
    maxBytesInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in bytes.
     */
    maxBytesInJoin: number;
    /**
     * Limit on the number of bytes in the set resulting from the execution of the IN section.
     */
    maxBytesInSet: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
     */
    maxBytesToRead: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
     */
    maxBytesToSort: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxBytesToTransfer: number;
    /**
     * Limits the maximum number of columns that can be read from a table in a single query.
     */
    maxColumnsToRead: number;
    /**
     * Limits the maximum query execution time in milliseconds.
     */
    maxExecutionTime: number;
    /**
     * Maximum abstract syntax tree depth after after expansion of aliases.
     */
    maxExpandedAstElements: number;
    /**
     * The size of blocks (in a count of rows) to form for insertion into a table.
     */
    maxInsertBlockSize: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing queries on a single server.
     */
    maxMemoryUsage: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
     */
    maxMemoryUsageForUser: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidth: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidthForUser: number;
    /**
     * The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
     */
    maxQuerySize: number;
    /**
     * Disables lagging replicas for distributed queries.
     */
    maxReplicaDelayForDistributedQueries: number;
    /**
     * Limits the number of bytes in the result.
     */
    maxResultBytes: number;
    /**
     * Limits the number of rows in the result.
     */
    maxResultRows: number;
    /**
     * Limits the maximum number of different rows when using DISTINCT.
     */
    maxRowsInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in rows.
     */
    maxRowsInJoin: number;
    /**
     * Limit on the number of rows in the set resulting from the execution of the IN section.
     */
    maxRowsInSet: number;
    /**
     * Limits the maximum number of unique keys received from aggregation function.
     */
    maxRowsToGroupBy: number;
    /**
     * Limits the maximum number of rows that can be read from a table when running a query.
     */
    maxRowsToRead: number;
    /**
     * Limits the maximum number of rows that can be read from a table for sorting.
     */
    maxRowsToSort: number;
    /**
     * Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxRowsToTransfer: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
     */
    maxTemporaryColumns: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
     */
    maxTemporaryNonConstColumns: number;
    /**
     * The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
     */
    maxThreads: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxBytesToUseCache bytes in one query, it doesnt use the cache of uncompressed blocks.
     */
    mergeTreeMaxBytesToUseCache: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxRowsToUseCache rows in one query, it doesnt use the cache of uncompressed blocks.
     */
    mergeTreeMaxRowsToUseCache: number;
    /**
     * If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
     */
    mergeTreeMinBytesForConcurrentRead: number;
    /**
     * If the number of rows to be read from a file of a MergeTree table exceeds mergeTreeMinRowsForConcurrentRead then ClickHouse tries to perform a concurrent reading from this file on several threads.
     */
    mergeTreeMinRowsForConcurrentRead: number;
    /**
     * The minimum data volume required for using direct I/O access to the storage disk.
     */
    minBytesToUseDirectIo: number;
    /**
     * How many times to potentially use a compiled chunk of code before running compilation.
     */
    minCountToCompile: number;
    /**
     * A query waits for expression compilation process to complete prior to continuing execution.
     */
    minCountToCompileExpression: number;
    /**
     * Minimal execution speed in rows per second.
     */
    minExecutionSpeed: number;
    /**
     * Minimal execution speed in bytes per second.
     */
    minExecutionSpeedBytes: number;
    /**
     * Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeBytes: number;
    /**
     * Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeRows: number;
    /**
     * If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
     */
    outputFormatJsonQuote64bitIntegers: boolean;
    /**
     * Enables +nan, -nan, +inf, -inf outputs in JSON output format.
     */
    outputFormatJsonQuoteDenormals: boolean;
    /**
     * Query priority.
     */
    priority: number;
    /**
     * Quota accounting mode.
     */
    quotaMode: string;
    /**
     * Sets behaviour on overflow while read. Possible values:
     */
    readOverflowMode: string;
    /**
     * Restricts permissions for reading data, write data and change settings queries.
     */
    readonly: number;
    /**
     * Receive timeout in milliseconds on the socket used for communicating with the client.
     */
    receiveTimeout: number;
    /**
     * For ALTER ... ATTACH|DETACH|DROP queries, you can use the replicationAlterPartitionsSync setting to set up waiting.
     */
    replicationAlterPartitionsSync: number;
    /**
     * Sets behaviour on overflow in result. Possible values:
     */
    resultOverflowMode: string;
    /**
     * Enables or disables sequential consistency for SELECT queries.
     */
    selectSequentialConsistency: boolean;
    /**
     * Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
     */
    sendProgressInHttpHeaders: boolean;
    /**
     * Send timeout in milliseconds on the socket used for communicating with the client.
     */
    sendTimeout: number;
    /**
     * Sets behaviour on overflow in the set resulting. Possible values:
     */
    setOverflowMode: string;
    /**
     * Enables or disables silently skipping of unavailable shards.
     */
    skipUnavailableShards: boolean;
    /**
     * Sets behaviour on overflow while sort. Possible values:
     */
    sortOverflowMode: string;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    timeoutOverflowMode: string;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    transferOverflowMode: string;
    /**
     * Enables equality of NULL values for IN operator.
     */
    transformNullIn: boolean;
    /**
     * Whether to use a cache of uncompressed blocks.
     */
    useUncompressedCache: boolean;
}

export interface GetMdbClickhouseClusterZookeeper {
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbClickhouseClusterZookeeperResource[];
}

export interface GetMdbClickhouseClusterZookeeperResource {
    /**
     * Volume of the storage available to a ClickHouse or ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ClickHouse or ZooKeeper hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbElasticSearchClusterConfig {
    adminPassword: string;
    /**
     * Configuration for Elasticsearch data nodes subcluster. The structure is documented below.
     */
    dataNodes: outputs.GetMdbElasticSearchClusterConfigDataNode[];
    /**
     * Edition of Elasticsearch. For more information, see [the official documentation](https://cloud.yandex.com/en-ru/docs/managed-elasticsearch/concepts/es-editions).
     */
    edition: string;
    /**
     * Configuration for Elasticsearch master nodes subcluster. The structure is documented below.
     */
    masterNode: outputs.GetMdbElasticSearchClusterConfigMasterNode;
    /**
     * A set of requested Elasticsearch plugins.
     */
    plugins: string[];
    /**
     * Version of Elasticsearch.
     */
    version: string;
}

export interface GetMdbElasticSearchClusterConfigDataNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbElasticSearchClusterConfigDataNodeResource[];
}

export interface GetMdbElasticSearchClusterConfigDataNodeResource {
    /**
     * Volume of the storage available to a Elasticsearch host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbElasticSearchClusterConfigMasterNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbElasticSearchClusterConfigMasterNodeResource[];
}

export interface GetMdbElasticSearchClusterConfigMasterNodeResource {
    /**
     * Volume of the storage available to a Elasticsearch host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbElasticSearchClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation.
     */
    assignPublicIp: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the Elasticsearch cluster.
     */
    name: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of a maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour need to be specified with the weekly window.
     */
    type: string;
    /**
     * The availability zone where the Elasticsearch host will be created.
     */
    zone: string;
}

export interface GetMdbElasticSearchClusterMaintenanceWindow {
    /**
     * Day of the week for a maintenance window if the window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day: string;
    /**
     * Hour of the day in UTC time zone (1-24) for a maintenance window if the window type is weekly.
     */
    hour: number;
    /**
     * Type of a maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour need to be specified with the weekly window.
     */
    type: string;
}

export interface GetMdbGreenplumClusterAccess {
    dataLens: boolean;
    webSql: boolean;
}

export interface GetMdbGreenplumClusterBackupWindowStart {
    hours: number;
    minutes: number;
}

export interface GetMdbGreenplumClusterMasterHost {
    assignPublicIp: boolean;
    fqdn: string;
}

export interface GetMdbGreenplumClusterMasterSubcluster {
    resources: outputs.GetMdbGreenplumClusterMasterSubclusterResource[];
}

export interface GetMdbGreenplumClusterMasterSubclusterResource {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbGreenplumClusterSegmentHost {
    fqdn: string;
}

export interface GetMdbGreenplumClusterSegmentSubcluster {
    resources: outputs.GetMdbGreenplumClusterSegmentSubclusterResource[];
}

export interface GetMdbGreenplumClusterSegmentSubclusterResource {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbKafkaClusterConfig {
    /**
     * The flag that defines whether a public IP address is assigned to the node.
     */
    assignPublicIp?: boolean;
    /**
     * (Optional) Count of brokers per availability zone.
     */
    brokersCount?: number;
    /**
     * (Optional) Configuration of the Kafka subcluster. The structure is documented below.
     */
    kafka: outputs.GetMdbKafkaClusterConfigKafka;
    /**
     * (Optional) Enables managed schema registry on cluster. Can be either `true` or `false`.
     */
    schemaRegistry?: boolean;
    /**
     * (Optional) Allows to use Kafka AdminAPI to manage topics. Can be either `true` or `false`.
     */
    unmanagedTopics?: boolean;
    /**
     * (Required) Version of the Kafka server software.
     */
    version: string;
    /**
     * (Optional) List of availability zones.
     */
    zones: string[];
    /**
     * (Optional) Configuration of the ZooKeeper subcluster. The structure is documented below.
     */
    zookeeper: outputs.GetMdbKafkaClusterConfigZookeeper;
}

export interface GetMdbKafkaClusterConfigKafka {
    /**
     * (Optional) User-defined settings for the Kafka cluster. The structure is documented below.
     */
    kafkaConfig?: outputs.GetMdbKafkaClusterConfigKafkaKafkaConfig;
    /**
     * (Optional) Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbKafkaClusterConfigKafkaResources;
}

export interface GetMdbKafkaClusterConfigKafkaKafkaConfig {
    autoCreateTopicsEnable?: boolean;
    compressionType?: string;
    defaultReplicationFactor?: string;
    logFlushIntervalMessages?: string;
    logFlushIntervalMs?: string;
    logFlushSchedulerIntervalMs?: string;
    logPreallocate?: boolean;
    logRetentionBytes?: string;
    logRetentionHours?: string;
    logRetentionMinutes?: string;
    logRetentionMs?: string;
    logSegmentBytes?: string;
    numPartitions?: string;
    socketReceiveBufferBytes?: string;
    socketSendBufferBytes?: string;
}

export interface GetMdbKafkaClusterConfigKafkaResources {
    /**
     * (Optional) Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * (Optional) Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbKafkaClusterConfigZookeeper {
    /**
     * (Optional) Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbKafkaClusterConfigZookeeperResources;
}

export interface GetMdbKafkaClusterConfigZookeeperResources {
    /**
     * (Optional) Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * (Optional) Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbKafkaClusterHost {
    /**
     * The flag that defines whether a public IP address is assigned to the node.
     */
    assignPublicIp: boolean;
    /**
     * Health of the host.
     */
    health: string;
    /**
     * The name of the Kafka cluster.
     */
    name: string;
    /**
     * Role of the host in the cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which the host belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Kafka host was created.
     */
    zoneId: string;
}

export interface GetMdbKafkaClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Value is one of: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day: string;
    /**
     * Hour of the day in UTC (in `HH` format). Value is between 1 and 24.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`.
     */
    type: string;
}

export interface GetMdbKafkaClusterTopic {
    /**
     * The ID of the Kafka cluster.
     */
    clusterId: string;
    /**
     * The name of the Kafka cluster.
     */
    name: string;
    /**
     * (Required) The number of the topic's partitions.
     */
    partitions: number;
    /**
     * (Required) Amount of data copies (replicas) for the topic in the cluster.
     */
    replicationFactor: number;
    /**
     * (Required) User-defined settings for the topic. The structure is documented below.
     */
    topicConfig?: outputs.GetMdbKafkaClusterTopicTopicConfig;
}

export interface GetMdbKafkaClusterTopicTopicConfig {
    cleanupPolicy?: string;
    compressionType?: string;
    deleteRetentionMs?: string;
    fileDeleteDelayMs?: string;
    flushMessages?: string;
    flushMs?: string;
    maxMessageBytes?: string;
    minCompactionLagMs?: string;
    minInsyncReplicas?: string;
    preallocate?: boolean;
    retentionBytes?: string;
    retentionMs?: string;
    segmentBytes?: string;
}

export interface GetMdbKafkaClusterUser {
    /**
     * The name of the Kafka cluster.
     */
    name: string;
    /**
     * (Required) The password of the user.
     */
    password: string;
    /**
     * (Optional) Set of permissions granted to the user. The structure is documented below.
     */
    permissions?: outputs.GetMdbKafkaClusterUserPermission[];
}

export interface GetMdbKafkaClusterUserPermission {
    /**
     * Role of the host in the cluster.
     */
    role: string;
    /**
     * (Required) The name of the topic that the permission grants access to.
     */
    topicName: string;
}

export interface GetMdbKafkaTopicTopicConfig {
    cleanupPolicy: string;
    compressionType: string;
    deleteRetentionMs: string;
    fileDeleteDelayMs: string;
    flushMessages: string;
    flushMs: string;
    maxMessageBytes: string;
    minCompactionLagMs: string;
    minInsyncReplicas: string;
    preallocate: boolean;
    retentionBytes: string;
    retentionMs: string;
    segmentBytes: string;
}

export interface GetMdbMongodbClusterClusterConfig {
    /**
     * Access policy to MongoDB cluster. The structure is documented below.
     */
    accesses: outputs.GetMdbMongodbClusterClusterConfigAccess[];
    /**
     * Time to start the daily backup, in the UTC timezone. The structure is documented below.
     */
    backupWindowStarts: outputs.GetMdbMongodbClusterClusterConfigBackupWindowStart[];
    /**
     * Feature compatibility version of MongoDB.
     */
    featureCompatibilityVersion: string;
    /**
     * Version of MongoDB (either 5.0, 4.4, 4.2, 4.0 or 3.6).
     */
    version: string;
}

export interface GetMdbMongodbClusterClusterConfigAccess {
    /**
     * Shows whether cluster has access to data lens.
     */
    dataLens: boolean;
}

export interface GetMdbMongodbClusterClusterConfigBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface GetMdbMongodbClusterDatabase {
    /**
     * The name of the MongoDB cluster.
     */
    name: string;
}

export interface GetMdbMongodbClusterHost {
    /**
     * Has assigned public IP.
     */
    assignPublicIp: boolean;
    /**
     * The health of the host.
     */
    health: string;
    /**
     * The name of the MongoDB cluster.
     */
    name: string;
    /**
     * The role of the cluster (either PRIMARY or SECONDARY).
     */
    role: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * The availability zone where the MongoDB host will be created.
     */
    zoneId: string;
}

export interface GetMdbMongodbClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface GetMdbMongodbClusterResource {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * The ID of the storage type. For more information, see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/storage)
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbMongodbClusterUser {
    /**
     * The name of the MongoDB cluster.
     */
    name: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbMongodbClusterUserPermission[];
}

export interface GetMdbMongodbClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * (Optional) List of strings. The roles of the user in this database. For more information see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/users-and-roles).
     */
    roles?: string[];
}

export interface GetMdbMysqlClusterAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens: boolean;
    /**
     * Allows access for [SQL queries in the management console](https://cloud.yandex.com/docs/managed-mysql/operations/web-sql-query).
     */
    webSql: boolean;
}

export interface GetMdbMysqlClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface GetMdbMysqlClusterDatabase {
    /**
     * The name of the MySQL cluster.
     */
    name: string;
}

export interface GetMdbMysqlClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Host replication source (fqdn), case when replicationSource is empty then host in HA group.
     */
    replicationSource: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the MySQL host will be created.
     */
    zone: string;
}

export interface GetMdbMysqlClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Value is one of: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day: string;
    /**
     * Hour of the day in UTC (in `HH` format). Value is between 1 and 24.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`.
     */
    type: string;
}

export interface GetMdbMysqlClusterResource {
    /**
     * Volume of the storage available to a MySQL host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage for MySQL hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbMysqlClusterUser {
    /**
     * Authentication plugin. Allowed values: `MYSQL_NATIVE_PASSWORD`, `CACHING_SHA2_PASSWORD`, `SHA256_PASSWORD`
     */
    authenticationPlugin: string;
    /**
     * User's connection limits. The structure is documented below.
     */
    connectionLimits: outputs.GetMdbMysqlClusterUserConnectionLimit[];
    /**
     * List user's global permissions. Allowed values: `REPLICATION_CLIENT`, `REPLICATION_SLAVE`, `PROCESS` or empty list.
     */
    globalPermissions: string[];
    /**
     * The name of the MySQL cluster.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbMysqlClusterUserPermission[];
}

export interface GetMdbMysqlClusterUserConnectionLimit {
    /**
     * Max connections per hour.
     */
    maxConnectionsPerHour: number;
    /**
     * Max questions per hour.
     */
    maxQuestionsPerHour: number;
    /**
     * Max updates per hour.
     */
    maxUpdatesPerHour: number;
    /**
     * Max user connections.
     */
    maxUserConnections: number;
}

export interface GetMdbMysqlClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `ALL`,`ALTER`,`ALTER_ROUTINE`,`CREATE`,`CREATE_ROUTINE`,`CREATE_TEMPORARY_TABLES`,
     * `CREATE_VIEW`,`DELETE`,`DROP`,`EVENT`,`EXECUTE`,`INDEX`,`INSERT`,`LOCK_TABLES`,`SELECT`,`SHOW_VIEW`,`TRIGGER`,`UPDATE`.
     */
    roles?: string[];
}

export interface GetMdbPostgresqlClusterConfig {
    /**
     * Access policy to the PostgreSQL cluster. The structure is documented below.
     */
    accesses: outputs.GetMdbPostgresqlClusterConfigAccess[];
    /**
     * Configuration setting which enables/disables autofailover in cluster.
     */
    autofailover: boolean;
    /**
     * The period in days during which backups are stored.
     */
    backupRetainPeriodDays: number;
    /**
     * Time to start the daily backup, in the UTC timezone. The structure is documented below.
     */
    backupWindowStarts: outputs.GetMdbPostgresqlClusterConfigBackupWindowStart[];
    /**
     * Cluster performance diagnostics settings. The structure is documented below. [YC Documentation](https://cloud.yandex.com/docs/managed-postgresql/grpc/cluster_service#PerformanceDiagnostics)
     */
    performanceDiagnostics: outputs.GetMdbPostgresqlClusterConfigPerformanceDiagnostic[];
    /**
     * Configuration of the connection pooler. The structure is documented below.
     */
    poolerConfigs: outputs.GetMdbPostgresqlClusterConfigPoolerConfig[];
    /**
     * PostgreSQL cluster config.
     */
    postgresqlConfig: {[key: string]: string};
    /**
     * Resources allocated to hosts of the PostgreSQL cluster. The structure is documented below.
     */
    resources: outputs.GetMdbPostgresqlClusterConfigResource[];
    /**
     * Version of the extension.
     */
    version: string;
}

export interface GetMdbPostgresqlClusterConfigAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens: boolean;
    /**
     * Allows access for [SQL queries in the management console](https://cloud.yandex.com/docs/managed-postgresql/operations/web-sql-query)
     */
    webSql: boolean;
}

export interface GetMdbPostgresqlClusterConfigBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours: number;
    /**
     * The minute at which backup will be started.
     */
    minutes: number;
}

export interface GetMdbPostgresqlClusterConfigPerformanceDiagnostic {
    /**
     * Flag, when true, performance diagnostics is enabled
     */
    enabled: boolean;
    /**
     * Interval (in seconds) for pgStatActivity sampling Acceptable values are 1 to 86400, inclusive.
     */
    sessionsSamplingInterval: number;
    /**
     * Interval (in seconds) for pgStatStatements sampling Acceptable values are 1 to 86400, inclusive.
     */
    statementsSamplingInterval: number;
}

export interface GetMdbPostgresqlClusterConfigPoolerConfig {
    /**
     * Value for `poolDiscard` [parameter in Odyssey](https://github.com/yandex/odyssey/blob/master/documentation/configuration.md#pool_discard-yesno).
     */
    poolDiscard: boolean;
    /**
     * Mode that the connection pooler is working in. See descriptions of all modes in the [documentation for Odyssey](https://github.com/yandex/odyssey/blob/master/documentation/configuration.md#pool-string.
     */
    poolingMode: string;
}

export interface GetMdbPostgresqlClusterConfigResource {
    /**
     * Volume of the storage available to a PostgreSQL host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage for PostgreSQL hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbPostgresqlClusterDatabase {
    /**
     * Set of database extensions. The structure is documented below
     */
    extensions: outputs.GetMdbPostgresqlClusterDatabaseExtension[];
    /**
     * POSIX locale for string sorting order. Forbidden to change in an existing database.
     */
    lcCollate: string;
    /**
     * POSIX locale for character classification. Forbidden to change in an existing database.
     */
    lcType: string;
    /**
     * The name of the PostgreSQL cluster.
     */
    name: string;
    /**
     * Name of the user assigned as the owner of the database.
     */
    owner: string;
}

export interface GetMdbPostgresqlClusterDatabaseExtension {
    /**
     * The name of the PostgreSQL cluster.
     */
    name: string;
    /**
     * Version of the extension.
     */
    version: string;
}

export interface GetMdbPostgresqlClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment.
     */
    assignPublicIp: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Host priority in HA group.
     */
    priority: number;
    /**
     * Host replication source (fqdn), case when replicationSource is empty then host in HA group.
     */
    replicationSource: string;
    /**
     * Role of the host in the cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the PostgreSQL host will be created.
     */
    zone: string;
}

export interface GetMdbPostgresqlClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Value is one of: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day: string;
    /**
     * Hour of the day in UTC (in `HH` format). Value is between 1 and 24.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`.
     */
    type: string;
}

export interface GetMdbPostgresqlClusterUser {
    /**
     * The maximum number of connections per user.
     */
    connLimit?: number;
    /**
     * List of the user's grants.
     */
    grants: string[];
    /**
     * User's ability to login.
     */
    login?: boolean;
    /**
     * The name of the PostgreSQL cluster.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbPostgresqlClusterUserPermission[];
    /**
     * Map of user settings.
     */
    settings: {[key: string]: string};
}

export interface GetMdbPostgresqlClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
}

export interface GetMdbRedisClusterConfig {
    /**
     * Number of databases (changing requires redis-server restart).
     */
    databases: number;
    /**
     * Redis key eviction policy for a dataset that reaches maximum memory.
     */
    maxmemoryPolicy: string;
    /**
     * Select the events that Redis will notify among a set of classes.
     */
    notifyKeyspaceEvents: string;
    /**
     * Log slow queries below this number in microseconds.
     */
    slowlogLogSlowerThan: number;
    /**
     * Slow queries log length.
     */
    slowlogMaxLen: number;
    /**
     * Close the connection after a client is idle for N seconds.
     */
    timeout: number;
    /**
     * Version of Redis (5.0, 6.0 or 6.2).
     */
    version: string;
}

export interface GetMdbRedisClusterHost {
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Redis host will be created.
     */
    zone: string;
}

export interface GetMdbRedisClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface GetMdbRedisClusterResource {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of a host.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbSqlserverClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours: number;
    /**
     * The minute at which backup will be started.
     */
    minutes: number;
}

export interface GetMdbSqlserverClusterDatabase {
    /**
     * The name of the SQLServer cluster.
     */
    name: string;
}

export interface GetMdbSqlserverClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment
     */
    assignPublicIp: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the SQLServer host will be created.
     */
    zone: string;
}

export interface GetMdbSqlserverClusterResource {
    /**
     * Volume of the storage available to a SQLServer host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage for SQLServer hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbSqlserverClusterUser {
    /**
     * The name of the SQLServer cluster.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbSqlserverClusterUserPermission[];
}

export interface GetMdbSqlserverClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `OWNER`, `SECURITYADMIN`, `ACCESSADMIN`, `BACKUPOPERATOR`, `DDLADMIN`, `DATAWRITER`, `DATAREADER`, `DENYDATAWRITER`, `DENYDATAREADER`.
     */
    roles: string[];
}

export interface GetServerlessContainerImage {
    args: string[];
    commands: string[];
    digest: string;
    environment: {[key: string]: string};
    /**
     * Invoke URL of the Yandex Cloud Serverless Container
     */
    url: string;
    workDir: string;
}

export interface GetVpcAddressExternalIpv4Address {
    /**
     * IP address.
     */
    address: string;
    /**
     * DDOS protection provider.
     */
    ddosProtectionProvider: string;
    /**
     * Outgoing smtp capability.
     */
    outgoingSmtpCapability: string;
    /**
     * Zone for allocating address.
     */
    zoneId: string;
}

export interface GetVpcRouteTableStaticRoute {
    /**
     * Route prefix in CIDR notation.
     */
    destinationPrefix: string;
    /**
     * Address of the next hop.
     */
    nextHopAddress: string;
}

export interface GetVpcSecurityGroupEgress {
    /**
     * Description of the rule.
     */
    description: string;
    /**
     * Minimum port number.
     */
    fromPort: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this rule.
     */
    labels: {[key: string]: string};
    /**
     * Port number (if applied to a single port).
     */
    port: number;
    /**
     * Special-purpose targets. `selfSecurityGroup` refers to this particular security group. `loadbalancerHealthchecks` represents [loadbalancer health check nodes](https://cloud.yandex.com/docs/network-load-balancer/concepts/health-check).
     */
    predefinedTarget: string;
    /**
     * One of `ANY`, `TCP`, `UDP`, `ICMP`, `IPV6_ICMP`.
     */
    protocol: string;
    /**
     * Security Group ID.
     */
    securityGroupId: string;
    /**
     * Maximum port number.
     */
    toPort: number;
    /**
     * The blocks of  IPv4 addresses for this rule.
     */
    v4CidrBlocks: string[];
    /**
     * The blocks of  IPv6 addresses for this rule.
     */
    v6CidrBlocks: string[];
}

export interface GetVpcSecurityGroupIngress {
    /**
     * Description of the rule.
     */
    description: string;
    /**
     * Minimum port number.
     */
    fromPort: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this rule.
     */
    labels: {[key: string]: string};
    /**
     * Port number (if applied to a single port).
     */
    port: number;
    /**
     * Special-purpose targets. `selfSecurityGroup` refers to this particular security group. `loadbalancerHealthchecks` represents [loadbalancer health check nodes](https://cloud.yandex.com/docs/network-load-balancer/concepts/health-check).
     */
    predefinedTarget: string;
    /**
     * One of `ANY`, `TCP`, `UDP`, `ICMP`, `IPV6_ICMP`.
     */
    protocol: string;
    /**
     * Security Group ID.
     */
    securityGroupId: string;
    /**
     * Maximum port number.
     */
    toPort: number;
    /**
     * The blocks of  IPv4 addresses for this rule.
     */
    v4CidrBlocks: string[];
    /**
     * The blocks of  IPv6 addresses for this rule.
     */
    v6CidrBlocks: string[];
}

export interface GetVpcSubnetDhcpOption {
    /**
     * Domain name.
     */
    domainName: string;
    /**
     * Domain name server IP addresses.
     */
    domainNameServers: string[];
    /**
     * NTP server IP addresses.
     */
    ntpServers: string[];
}

export interface GetYdbDatabaseDedicatedLocation {
    /**
     * Region of the Yandex Database cluster.
     * The structure is documented below.
     */
    regions: outputs.GetYdbDatabaseDedicatedLocationRegion[];
    zones: outputs.GetYdbDatabaseDedicatedLocationZone[];
}

export interface GetYdbDatabaseDedicatedLocationRegion {
    /**
     * Region ID of the Yandex Database cluster.
     */
    id: string;
}

export interface GetYdbDatabaseDedicatedLocationZone {
    /**
     * Region ID of the Yandex Database cluster.
     */
    id: string;
}

export interface GetYdbDatabaseDedicatedScalePolicy {
    /**
     * Fixed scaling policy of the Yandex Database cluster.
     * The structure is documented below.
     */
    fixedScales: outputs.GetYdbDatabaseDedicatedScalePolicyFixedScale[];
}

export interface GetYdbDatabaseDedicatedScalePolicyFixedScale {
    /**
     * Number of instances in the Yandex Database cluster.
     */
    size: number;
}

export interface GetYdbDatabaseDedicatedStorageConfig {
    /**
     * Amount of storage groups of selected type in the Yandex Database cluster.
     */
    groupCount: number;
    /**
     * Storage type ID of the Yandex Database cluster.
     */
    storageTypeId: string;
}

export interface KubernetesClusterKmsProvider {
    /**
     * KMS key ID.
     */
    keyId?: string;
}

export interface KubernetesClusterMaster {
    /**
     * (Computed) PEM-encoded public certificate that is the root of trust for the Kubernetes cluster.
     */
    clusterCaCertificate: string;
    /**
     * (Computed) An IPv4 external network address that is assigned to the master.
     */
    externalV4Address: string;
    /**
     * (Computed) External endpoint that can be used to access Kubernetes cluster API from the internet (outside of the cloud).
     */
    externalV4Endpoint: string;
    /**
     * (Computed) An IPv4 internal network address that is assigned to the master.
     */
    internalV4Address: string;
    /**
     * (Computed) Internal endpoint that can be used to connect to the master from cloud networks.
     */
    internalV4Endpoint: string;
    /**
     * (Optional) (Computed) Maintenance policy for Kubernetes master.
     * If policy is omitted, automatic revision upgrades of the kubernetes master are enabled and could happen at any time.
     * Revision upgrades are performed only within the same minor version, e.g. 1.13.
     * Minor version upgrades (e.g. 1.13->1.14) should be performed manually. The structure is documented below.
     */
    maintenancePolicy: outputs.KubernetesClusterMasterMaintenancePolicy;
    /**
     * (Optional) (Computed) Boolean flag. When `true`, Kubernetes master will have visible ipv4 address.
     */
    publicIp: boolean;
    /**
     * (Optional) Initialize parameters for Regional Master (highly available master). The structure is documented below.
     */
    regional: outputs.KubernetesClusterMasterRegional;
    /**
     * (Optional) List of security group IDs to which the Kubernetes cluster belongs.
     */
    securityGroupIds?: string[];
    /**
     * (Optional) (Computed) Version of Kubernetes that will be used for master.
     */
    version: string;
    /**
     * (Computed) Information about cluster version. The structure is documented below.
     */
    versionInfos: outputs.KubernetesClusterMasterVersionInfo[];
    /**
     * (Optional) Initialize parameters for Zonal Master (single node master). The structure is documented below.
     */
    zonal: outputs.KubernetesClusterMasterZonal;
}

export interface KubernetesClusterMasterMaintenancePolicy {
    /**
     * (Required) Boolean flag that specifies if master can be upgraded automatically. When omitted, default value is TRUE.
     */
    autoUpgrade: boolean;
    /**
     * (Optional) (Computed) This structure specifies maintenance window, when update for master is allowed. When omitted, it defaults to any time.
     * To specify time of day interval, for all days, one element should be provided, with two fields set, `startTime` and `duration`.
     * Please see `zonalClusterResourceName` config example.
     */
    maintenanceWindows?: outputs.KubernetesClusterMasterMaintenancePolicyMaintenanceWindow[];
}

export interface KubernetesClusterMasterMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface KubernetesClusterMasterRegional {
    /**
     * Array of locations, where master instances will be allocated. The structure is documented below.
     */
    locations: outputs.KubernetesClusterMasterRegionalLocation[];
    /**
     * (Required) Name of availability region (e.g. "ru-central1"), where master instances will be allocated.
     */
    region: string;
}

export interface KubernetesClusterMasterRegionalLocation {
    /**
     * (Optional) ID of the subnet.
     */
    subnetId?: string;
    /**
     * (Optional) ID of the availability zone.
     */
    zone?: string;
}

export interface KubernetesClusterMasterVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * Boolean flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * Boolean flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface KubernetesClusterMasterZonal {
    /**
     * (Optional) ID of the subnet.
     */
    subnetId?: string;
    /**
     * (Optional) ID of the availability zone.
     */
    zone: string;
}

export interface KubernetesClusterNetworkImplementation {
    /**
     * (Optional) Cilium network implementation configuration. No options exist.
     */
    cilium?: outputs.KubernetesClusterNetworkImplementationCilium;
}

export interface KubernetesClusterNetworkImplementationCilium {
}

export interface KubernetesNodeGroupAllocationPolicy {
    /**
     * Repeated field, that specify subnets (zones), that will be used by node group compute instances. The structure is documented below.
     */
    locations: outputs.KubernetesNodeGroupAllocationPolicyLocation[];
}

export interface KubernetesNodeGroupAllocationPolicyLocation {
    /**
     * ID of the subnet, that will be used by one compute instance in node group.
     *
     * @deprecated The 'subnet_id' field has been deprecated. Please use 'subnet_ids under network_interface' instead.
     */
    subnetId: string;
    /**
     * ID of the availability zone where for one compute instance in node group.
     */
    zone: string;
}

export interface KubernetesNodeGroupDeployPolicy {
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size during the update.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline during update.
     */
    maxUnavailable: number;
}

export interface KubernetesNodeGroupInstanceTemplate {
    /**
     * The specifications for boot disks that will be attached to the instance. The structure is documented below.
     */
    bootDisk: outputs.KubernetesNodeGroupInstanceTemplateBootDisk;
    /**
     * Container runtime configuration. The structure is documented below.
     * ---
     */
    containerRuntime: outputs.KubernetesNodeGroupInstanceTemplateContainerRuntime;
    /**
     * The set of metadata `key:value` pairs assigned to this instance template. This includes custom metadata and predefined keys.
     * * `resources.0.memory` - The memory size allocated to the instance.
     * * `resources.0.cores` - Number of CPU cores allocated to the instance.
     * * `resources.0.core_fraction` - Baseline core performance as a percent.
     * * `resources.0.gpus` - Number of GPU cores allocated to the instance.
     */
    metadata: {[key: string]: string};
    /**
     * A public address that can be used to access the internet over NAT.
     *
     * @deprecated The 'nat' field has been deprecated. Please use 'nat under network_interface' instead.
     */
    nat: boolean;
    /**
     * Type of network acceleration. Values: `standard`, `softwareAccelerated`.
     */
    networkAccelerationType: string;
    /**
     * An array with the network interfaces that will be attached to the instance. The structure is documented below.
     */
    networkInterfaces: outputs.KubernetesNodeGroupInstanceTemplateNetworkInterface[];
    /**
     * The placement policy configuration. The structure is documented below.
     */
    placementPolicy?: outputs.KubernetesNodeGroupInstanceTemplatePlacementPolicy;
    /**
     * The ID of the hardware platform configuration for the node group compute instances.
     */
    platformId: string;
    resources: outputs.KubernetesNodeGroupInstanceTemplateResources;
    /**
     * The scheduling policy for the instances in node group. The structure is documented below.
     */
    schedulingPolicy: outputs.KubernetesNodeGroupInstanceTemplateSchedulingPolicy;
}

export interface KubernetesNodeGroupInstanceTemplateBootDisk {
    /**
     * The number of instances in the node group.
     */
    size: number;
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface KubernetesNodeGroupInstanceTemplateContainerRuntime {
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface KubernetesNodeGroupInstanceTemplateNetworkInterface {
    /**
     * Allocate an IPv4 address for the interface. The default value is `true`.
     */
    ipv4?: boolean;
    /**
     * If true, allocate an IPv6 address for the interface. The address will be automatically assigned from the specified subnet.
     */
    ipv6: boolean;
    /**
     * A public address that can be used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds?: string[];
    /**
     * The IDs of the subnets.
     */
    subnetIds: string[];
}

export interface KubernetesNodeGroupInstanceTemplatePlacementPolicy {
    /**
     * Specifies the id of the Placement Group to assign to the instances.
     */
    placementGroupId: string;
}

export interface KubernetesNodeGroupInstanceTemplateResources {
    coreFraction: number;
    cores: number;
    gpus?: number;
    memory: number;
}

export interface KubernetesNodeGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     * ---
     */
    preemptible: boolean;
}

export interface KubernetesNodeGroupMaintenancePolicy {
    /**
     * Boolean flag that specifies if node group can be repaired automatically. When omitted, default value is TRUE.
     */
    autoRepair: boolean;
    /**
     * Boolean flag that specifies if node group can be upgraded automatically. When omitted, default value is TRUE.
     */
    autoUpgrade: boolean;
    /**
     * (Computed) Set of day intervals, when maintenance is allowed for this node group. When omitted, it defaults to any time.
     */
    maintenanceWindows?: outputs.KubernetesNodeGroupMaintenancePolicyMaintenanceWindow[];
}

export interface KubernetesNodeGroupMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface KubernetesNodeGroupScalePolicy {
    /**
     * Scale policy for an autoscaled node group. The structure is documented below.
     */
    autoScale?: outputs.KubernetesNodeGroupScalePolicyAutoScale;
    /**
     * Scale policy for a fixed scale node group. The structure is documented below.
     */
    fixedScale?: outputs.KubernetesNodeGroupScalePolicyFixedScale;
}

export interface KubernetesNodeGroupScalePolicyAutoScale {
    /**
     * Initial number of instances in the node group.
     */
    initial: number;
    /**
     * Maximum number of instances in the node group.
     */
    max: number;
    /**
     * Minimum number of instances in the node group.
     */
    min: number;
}

export interface KubernetesNodeGroupScalePolicyFixedScale {
    /**
     * The number of instances in the node group.
     */
    size: number;
}

export interface KubernetesNodeGroupVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * True/false flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * True/false flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface LbNetworkLoadBalancerAttachedTargetGroup {
    /**
     * A HealthCheck resource. The structure is documented below.
     */
    healthchecks: outputs.LbNetworkLoadBalancerAttachedTargetGroupHealthcheck[];
    /**
     * ID of the target group.
     */
    targetGroupId: string;
}

export interface LbNetworkLoadBalancerAttachedTargetGroupHealthcheck {
    /**
     * Number of successful health checks required in order to set the `HEALTHY` status for the target.
     */
    healthyThreshold?: number;
    /**
     * Options for HTTP health check. The structure is documented below.
     */
    httpOptions?: outputs.LbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOptions;
    /**
     * The interval between health checks. The default is 2 seconds.
     */
    interval?: number;
    /**
     * Name of the listener. The name must be unique for each listener on a single load balancer.
     */
    name: string;
    /**
     * Options for TCP health check. The structure is documented below.
     */
    tcpOptions?: outputs.LbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOptions;
    /**
     * Timeout for a target to return a response for the health check. The default is 1 second.
     */
    timeout?: number;
    /**
     * Number of failed health checks before changing the status to `UNHEALTHY`. The default is 2.
     */
    unhealthyThreshold?: number;
}

export interface LbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOptions {
    /**
     * URL path to set for health checking requests for every target in the target group. For example `/ping`. The default path is `/`.
     */
    path?: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface LbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOptions {
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface LbNetworkLoadBalancerListener {
    /**
     * External IP address specification. The structure is documented below.
     */
    externalAddressSpec?: outputs.LbNetworkLoadBalancerListenerExternalAddressSpec;
    /**
     * Internal IP address specification. The structure is documented below.
     */
    internalAddressSpec?: outputs.LbNetworkLoadBalancerListenerInternalAddressSpec;
    /**
     * Name of the listener. The name must be unique for each listener on a single load balancer.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * Protocol for incoming traffic. TCP or UDP and the default is TCP.
     */
    protocol: string;
    /**
     * Port of a target. The default is the same as listener's port.
     */
    targetPort: number;
}

export interface LbNetworkLoadBalancerListenerExternalAddressSpec {
    /**
     * Internal IP address for a listener. Must belong to the subnet that is referenced in subnet_id. IP address will be allocated if it wasn't been set.
     */
    address: string;
    /**
     * IP version of the internal addresses that the load balancer works with. Must be one of ipv4 or ipv6. The default is ipv4.
     */
    ipVersion?: string;
}

export interface LbNetworkLoadBalancerListenerInternalAddressSpec {
    /**
     * Internal IP address for a listener. Must belong to the subnet that is referenced in subnet_id. IP address will be allocated if it wasn't been set.
     */
    address: string;
    /**
     * IP version of the internal addresses that the load balancer works with. Must be one of ipv4 or ipv6. The default is ipv4.
     */
    ipVersion?: string;
    /**
     * ID of the subnet to which the internal IP address belongs.
     */
    subnetId: string;
}

export interface LbTargetGroupTarget {
    /**
     * IP address of the target.
     */
    address: string;
    /**
     * ID of the subnet that targets are connected to. 
     * All targets in the target group must be connected to the same subnet within a single availability zone.
     */
    subnetId: string;
}

export interface MdbClickhouseClusterAccess {
    /**
     * Allow access for DataLens. Can be either `true` or `false`.
     */
    dataLens?: boolean;
    /**
     * Allow access for Yandex.Metrika. Can be either `true` or `false`.
     */
    metrika?: boolean;
    /**
     * Allow access for Serverless. Can be either `true` or `false`.
     */
    serverless?: boolean;
    /**
     * Allow access for Web SQL. Can be either `true` or `false`.
     */
    webSql?: boolean;
}

export interface MdbClickhouseClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbClickhouseClusterClickhouse {
    /**
     * Main ClickHouse cluster configuration.
     */
    config: outputs.MdbClickhouseClusterClickhouseConfig;
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.MdbClickhouseClusterClickhouseResources;
}

export interface MdbClickhouseClusterClickhouseConfig {
    backgroundPoolSize: number;
    backgroundSchedulePoolSize: number;
    /**
     * Data compression configuration. The structure is documented below.
     */
    compressions?: outputs.MdbClickhouseClusterClickhouseConfigCompression[];
    geobaseUri: string;
    /**
     * Graphite rollup configuration. The structure is documented below.
     */
    graphiteRollups?: outputs.MdbClickhouseClusterClickhouseConfigGraphiteRollup[];
    /**
     * Kafka connection configuration. The structure is documented below.
     */
    kafka: outputs.MdbClickhouseClusterClickhouseConfigKafka;
    /**
     * Kafka topic connection configuration. The structure is documented below.
     */
    kafkaTopics?: outputs.MdbClickhouseClusterClickhouseConfigKafkaTopic[];
    keepAliveTimeout: number;
    logLevel: string;
    markCacheSize: number;
    maxConcurrentQueries: number;
    maxConnections: number;
    maxPartitionSizeToDrop: number;
    maxTableSizeToDrop: number;
    /**
     * MergeTree engine configuration. The structure is documented below.
     */
    mergeTree: outputs.MdbClickhouseClusterClickhouseConfigMergeTree;
    metricLogEnabled: boolean;
    metricLogRetentionSize: number;
    metricLogRetentionTime: number;
    partLogRetentionSize: number;
    partLogRetentionTime: number;
    queryLogRetentionSize: number;
    queryLogRetentionTime: number;
    queryThreadLogEnabled: boolean;
    queryThreadLogRetentionSize: number;
    queryThreadLogRetentionTime: number;
    /**
     * RabbitMQ connection configuration. The structure is documented below.
     */
    rabbitmq: outputs.MdbClickhouseClusterClickhouseConfigRabbitmq;
    textLogEnabled: boolean;
    textLogLevel: string;
    textLogRetentionSize: number;
    textLogRetentionTime: number;
    timezone: string;
    traceLogEnabled: boolean;
    traceLogRetentionSize: number;
    traceLogRetentionTime: number;
    uncompressedCacheSize: number;
}

export interface MdbClickhouseClusterClickhouseConfigCompression {
    /**
     * Method: Compression method. Two methods are available: LZ4 and zstd.
     */
    method: string;
    /**
     * Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
     */
    minPartSize: number;
    /**
     * Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
     */
    minPartSizeRatio: number;
}

export interface MdbClickhouseClusterClickhouseConfigGraphiteRollup {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Set of thinning rules.
     */
    patterns?: outputs.MdbClickhouseClusterClickhouseConfigGraphiteRollupPattern[];
}

export interface MdbClickhouseClusterClickhouseConfigGraphiteRollupPattern {
    /**
     * Aggregation function name.
     */
    function: string;
    /**
     * Regular expression that the metric name must match.
     */
    regexp: string;
    /**
     * Retain parameters.
     */
    retentions?: outputs.MdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention[];
}

export interface MdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention {
    /**
     * Minimum data age in seconds.
     */
    age: number;
    /**
     * Accuracy of determining the age of the data in seconds.
     */
    precision: number;
}

export interface MdbClickhouseClusterClickhouseConfigKafka {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism: string;
    /**
     * User password on kafka server.
     */
    saslPassword: string;
    /**
     * Username on kafka server.
     */
    saslUsername: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol: string;
}

export interface MdbClickhouseClusterClickhouseConfigKafkaTopic {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings?: outputs.MdbClickhouseClusterClickhouseConfigKafkaTopicSettings;
}

export interface MdbClickhouseClusterClickhouseConfigKafkaTopicSettings {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism?: string;
    /**
     * User password on kafka server.
     */
    saslPassword?: string;
    /**
     * Username on kafka server.
     */
    saslUsername?: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol?: string;
}

export interface MdbClickhouseClusterClickhouseConfigMergeTree {
    /**
     * Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
     */
    maxBytesToMergeAtMinSpaceInPool: number;
    /**
     * Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
     */
    maxReplicatedMergesInQueue: number;
    /**
     * Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
     */
    numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge: number;
    /**
     * Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
     */
    partsToDelayInsert: number;
    /**
     * Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
     */
    partsToThrowInsert: number;
    /**
     * Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
     */
    replicatedDeduplicationWindow: number;
    /**
     * Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
     */
    replicatedDeduplicationWindowSeconds: number;
}

export interface MdbClickhouseClusterClickhouseConfigRabbitmq {
    /**
     * RabbitMQ user password.
     */
    password: string;
    /**
     * RabbitMQ username.
     */
    username: string;
}

export interface MdbClickhouseClusterClickhouseResources {
    /**
     * Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbClickhouseClusterCloudStorage {
    /**
     * Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
     */
    enabled: boolean;
}

export interface MdbClickhouseClusterDatabase {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
}

export interface MdbClickhouseClusterFormatSchema {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri: string;
}

export interface MdbClickhouseClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Can be either `true` or `false`.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * The availability zone where the ClickHouse host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zone: string;
}

export interface MdbClickhouseClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbClickhouseClusterMlModel {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri: string;
}

export interface MdbClickhouseClusterShardGroup {
    /**
     * Description of the shard group.
     */
    description?: string;
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * List of shards names that belong to the shard group.
     */
    shardNames: string[];
}

export interface MdbClickhouseClusterUser {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * RabbitMQ user password.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.MdbClickhouseClusterUserPermission[];
    /**
     * Set of user quotas. The structure is documented below.
     */
    quotas: outputs.MdbClickhouseClusterUserQuota[];
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings: outputs.MdbClickhouseClusterUserSettings;
}

export interface MdbClickhouseClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
}

export interface MdbClickhouseClusterUserQuota {
    /**
     * The number of queries that threw exception.
     */
    errors: number;
    /**
     * The total query execution time, in milliseconds (wall time).
     */
    executionTime: number;
    /**
     * Duration of interval for quota in milliseconds.
     */
    intervalDuration: number;
    /**
     * The total number of queries.
     */
    queries: number;
    /**
     * The total number of source rows read from tables for running the query, on all remote servers.
     */
    readRows: number;
    /**
     * The total number of rows given as the result.
     */
    resultRows: number;
}

export interface MdbClickhouseClusterUserSettings {
    /**
     * Include CORS headers in HTTP responces.
     */
    addHttpCorsHeader: boolean;
    /**
     * Allows or denies DDL queries.
     */
    allowDdl: boolean;
    /**
     * Enable compilation of queries.
     */
    compile: boolean;
    /**
     * Turn on expression compilation.
     */
    compileExpressions: boolean;
    /**
     * Connect timeout in milliseconds on the socket used for communicating with the client.
     */
    connectTimeout: number;
    /**
     * Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT ) construction.
     */
    countDistinctImplementation: string;
    /**
     * Sets behaviour on overflow when using DISTINCT. Possible values:
     */
    distinctOverflowMode: string;
    /**
     * Determine the behavior of distributed subqueries.
     */
    distributedAggregationMemoryEfficient: boolean;
    /**
     * Timeout for DDL queries, in milliseconds.
     */
    distributedDdlTaskTimeout: number;
    /**
     * Changes the behaviour of distributed subqueries.
     */
    distributedProductMode: string;
    /**
     * Allows to retunr empty result.
     */
    emptyResultForAggregationByEmptySet: boolean;
    /**
     * Enables or disables data compression in the response to an HTTP request.
     */
    enableHttpCompression: boolean;
    /**
     * Forces a query to an out-of-date replica if updated data is not available.
     */
    fallbackToStaleReplicasForDistributedQueries: boolean;
    /**
     * Disables query execution if the index cant be used by date.
     */
    forceIndexByDate: boolean;
    /**
     * Disables query execution if indexing by the primary key is not possible.
     */
    forcePrimaryKey: boolean;
    /**
     * Sets behaviour on overflow while GROUP BY operation. Possible values:
     */
    groupByOverflowMode: string;
    /**
     * Sets the threshold of the number of keys, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThreshold: number;
    /**
     * Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThresholdBytes: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpConnectionTimeout: number;
    /**
     * Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
     */
    httpHeadersProgressInterval: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpReceiveTimeout: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpSendTimeout: number;
    /**
     * When performing INSERT queries, replace omitted input column values with default values of the respective columns.
     */
    inputFormatDefaultsForOmittedFields: boolean;
    /**
     * Enables or disables the full SQL parser if the fast stream parser cant parse the data.
     */
    inputFormatValuesInterpretExpressions: boolean;
    /**
     * Enables the quorum writes.
     */
    insertQuorum: number;
    /**
     * Write to a quorum timeout in milliseconds.
     */
    insertQuorumTimeout: number;
    /**
     * Sets behaviour on overflow in JOIN. Possible values:
     */
    joinOverflowMode: string;
    /**
     * Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
     */
    joinUseNulls: boolean;
    /**
     * Require aliases for subselects and table functions in FROM that more than one table is present.
     */
    joinedSubqueryRequiresAlias: boolean;
    /**
     * Allows or restricts using the LowCardinality data type with the Native format.
     */
    lowCardinalityAllowInNativeFormat: boolean;
    /**
     * Maximum abstract syntax tree depth.
     */
    maxAstDepth: number;
    /**
     * Maximum abstract syntax tree elements.
     */
    maxAstElements: number;
    /**
     * A recommendation for what size of the block (in a count of rows) to load from tables.
     */
    maxBlockSize: number;
    /**
     * Limit in bytes for using memoru for GROUP BY before using swap on disk.
     */
    maxBytesBeforeExternalGroupBy: number;
    /**
     * This setting is equivalent of the maxBytesBeforeExternalGroupBy setting, except for it is for sort operation (ORDER BY), not aggregation.
     */
    maxBytesBeforeExternalSort: number;
    /**
     * Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
     */
    maxBytesInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in bytes.
     */
    maxBytesInJoin: number;
    /**
     * Limit on the number of bytes in the set resulting from the execution of the IN section.
     */
    maxBytesInSet: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
     */
    maxBytesToRead: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
     */
    maxBytesToSort: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxBytesToTransfer: number;
    /**
     * Limits the maximum number of columns that can be read from a table in a single query.
     */
    maxColumnsToRead: number;
    /**
     * Limits the maximum query execution time in milliseconds.
     */
    maxExecutionTime: number;
    /**
     * Maximum abstract syntax tree depth after after expansion of aliases.
     */
    maxExpandedAstElements: number;
    /**
     * The size of blocks (in a count of rows) to form for insertion into a table.
     */
    maxInsertBlockSize: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing queries on a single server.
     */
    maxMemoryUsage: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
     */
    maxMemoryUsageForUser: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidth: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidthForUser: number;
    /**
     * The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
     */
    maxQuerySize: number;
    /**
     * Disables lagging replicas for distributed queries.
     */
    maxReplicaDelayForDistributedQueries: number;
    /**
     * Limits the number of bytes in the result.
     */
    maxResultBytes: number;
    /**
     * Limits the number of rows in the result.
     */
    maxResultRows: number;
    /**
     * Limits the maximum number of different rows when using DISTINCT.
     */
    maxRowsInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in rows.
     */
    maxRowsInJoin: number;
    /**
     * Limit on the number of rows in the set resulting from the execution of the IN section.
     */
    maxRowsInSet: number;
    /**
     * Limits the maximum number of unique keys received from aggregation function.
     */
    maxRowsToGroupBy: number;
    /**
     * Limits the maximum number of rows that can be read from a table when running a query.
     */
    maxRowsToRead: number;
    /**
     * Limits the maximum number of rows that can be read from a table for sorting.
     */
    maxRowsToSort: number;
    /**
     * Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxRowsToTransfer: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
     */
    maxTemporaryColumns: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
     */
    maxTemporaryNonConstColumns: number;
    /**
     * The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
     */
    maxThreads: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxBytesToUseCache bytes in one query, it doesnt use the cache of uncompressed blocks.
     */
    mergeTreeMaxBytesToUseCache: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxRowsToUseCache rows in one query, it doesnt use the cache of uncompressed blocks.
     */
    mergeTreeMaxRowsToUseCache: number;
    /**
     * If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
     */
    mergeTreeMinBytesForConcurrentRead: number;
    /**
     * If the number of rows to be read from a file of a MergeTree table exceeds mergeTreeMinRowsForConcurrentRead then ClickHouse tries to perform a concurrent reading from this file on several threads.
     */
    mergeTreeMinRowsForConcurrentRead: number;
    /**
     * The minimum data volume required for using direct I/O access to the storage disk.
     */
    minBytesToUseDirectIo: number;
    /**
     * How many times to potentially use a compiled chunk of code before running compilation.
     */
    minCountToCompile: number;
    /**
     * A query waits for expression compilation process to complete prior to continuing execution.
     */
    minCountToCompileExpression: number;
    /**
     * Minimal execution speed in rows per second.
     */
    minExecutionSpeed: number;
    /**
     * Minimal execution speed in bytes per second.
     */
    minExecutionSpeedBytes: number;
    /**
     * Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeBytes: number;
    /**
     * Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeRows: number;
    /**
     * If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
     */
    outputFormatJsonQuote64bitIntegers: boolean;
    /**
     * Enables +nan, -nan, +inf, -inf outputs in JSON output format.
     */
    outputFormatJsonQuoteDenormals: boolean;
    /**
     * Query priority.
     */
    priority: number;
    /**
     * Quota accounting mode.
     */
    quotaMode: string;
    /**
     * Sets behaviour on overflow while read. Possible values:
     */
    readOverflowMode: string;
    /**
     * Restricts permissions for reading data, write data and change settings queries.
     */
    readonly: number;
    /**
     * Receive timeout in milliseconds on the socket used for communicating with the client.
     */
    receiveTimeout: number;
    /**
     * For ALTER ... ATTACH|DETACH|DROP queries, you can use the replicationAlterPartitionsSync setting to set up waiting.
     */
    replicationAlterPartitionsSync: number;
    /**
     * Sets behaviour on overflow in result. Possible values:
     */
    resultOverflowMode: string;
    /**
     * Enables or disables sequential consistency for SELECT queries.
     */
    selectSequentialConsistency: boolean;
    /**
     * Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
     */
    sendProgressInHttpHeaders: boolean;
    /**
     * Send timeout in milliseconds on the socket used for communicating with the client.
     */
    sendTimeout: number;
    /**
     * Sets behaviour on overflow in the set resulting. Possible values:
     */
    setOverflowMode: string;
    /**
     * Enables or disables silently skipping of unavailable shards.
     */
    skipUnavailableShards: boolean;
    /**
     * Sets behaviour on overflow while sort. Possible values:
     */
    sortOverflowMode: string;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    timeoutOverflowMode: string;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    transferOverflowMode: string;
    /**
     * Enables equality of NULL values for IN operator.
     */
    transformNullIn: boolean;
    /**
     * Whether to use a cache of uncompressed blocks.
     */
    useUncompressedCache: boolean;
}

export interface MdbClickhouseClusterZookeeper {
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.MdbClickhouseClusterZookeeperResources;
}

export interface MdbClickhouseClusterZookeeperResources {
    /**
     * Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbElasticSearchClusterConfig {
    /**
     * Password for admin user of Elasticsearch.
     */
    adminPassword: string;
    /**
     * Configuration for Elasticsearch data nodes subcluster. The structure is documented below.
     */
    dataNode: outputs.MdbElasticSearchClusterConfigDataNode;
    /**
     * Edition of Elasticsearch. For more information, see [the official documentation](https://cloud.yandex.com/en-ru/docs/managed-elasticsearch/concepts/es-editions).
     */
    edition: string;
    /**
     * Configuration for Elasticsearch master nodes subcluster. The structure is documented below.
     */
    masterNode?: outputs.MdbElasticSearchClusterConfigMasterNode;
    /**
     * A set of Elasticsearch plugins to install.
     */
    plugins?: string[];
    /**
     * Version of Elasticsearch.
     */
    version: string;
}

export interface MdbElasticSearchClusterConfigDataNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.MdbElasticSearchClusterConfigDataNodeResources;
}

export interface MdbElasticSearchClusterConfigDataNodeResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbElasticSearchClusterConfigMasterNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.MdbElasticSearchClusterConfigMasterNodeResources;
}

export interface MdbElasticSearchClusterConfigMasterNodeResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbElasticSearchClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Can be either `true` or `false`.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * User defined host name.
     */
    name: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * The availability zone where the Elasticsearch host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zone: string;
}

export interface MdbElasticSearchClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbGreenplumClusterAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens?: boolean;
    /**
     * Allows access for SQL queries in the management console
     */
    webSql?: boolean;
}

export interface MdbGreenplumClusterBackupWindowStart {
    /**
     * The hour at which backup will be started (UTC).
     */
    hours?: number;
    /**
     * The minute at which backup will be started (UTC).
     */
    minutes?: number;
}

export interface MdbGreenplumClusterMasterHost {
    /**
     * Sets whether the master hosts should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment.
     */
    assignPublicIp: boolean;
    /**
     * (Computed) The fully qualified domain name of the host.
     */
    fqdn: string;
}

export interface MdbGreenplumClusterMasterSubcluster {
    /**
     * Resources allocated to hosts for segment subcluster of the Greenplum cluster. The structure is documented below.
     */
    resources: outputs.MdbGreenplumClusterMasterSubclusterResources;
}

export interface MdbGreenplumClusterMasterSubclusterResources {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbGreenplumClusterSegmentHost {
    /**
     * (Computed) The fully qualified domain name of the host.
     */
    fqdn: string;
}

export interface MdbGreenplumClusterSegmentSubcluster {
    /**
     * Resources allocated to hosts for segment subcluster of the Greenplum cluster. The structure is documented below.
     */
    resources: outputs.MdbGreenplumClusterSegmentSubclusterResources;
}

export interface MdbGreenplumClusterSegmentSubclusterResources {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbKafkaClusterConfig {
    /**
     * Determines whether each broker will be assigned a public IP address. The default is `false`.
     */
    assignPublicIp?: boolean;
    /**
     * Count of brokers per availability zone. The default is `1`.
     */
    brokersCount?: number;
    /**
     * Configuration of the Kafka subcluster. The structure is documented below.
     */
    kafka: outputs.MdbKafkaClusterConfigKafka;
    /**
     * Enables managed schema registry on cluster. The default is `false`.
     */
    schemaRegistry?: boolean;
    /**
     * Allows to use Kafka AdminAPI to manage topics. The default is `false`.
     */
    unmanagedTopics?: boolean;
    /**
     * Version of the Kafka server software.
     */
    version: string;
    /**
     * List of availability zones.
     */
    zones: string[];
    /**
     * Configuration of the ZooKeeper subcluster. The structure is documented below.
     */
    zookeeper: outputs.MdbKafkaClusterConfigZookeeper;
}

export interface MdbKafkaClusterConfigKafka {
    /**
     * User-defined settings for the Kafka cluster. The structure is documented below.
     */
    kafkaConfig?: outputs.MdbKafkaClusterConfigKafkaKafkaConfig;
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.MdbKafkaClusterConfigKafkaResources;
}

export interface MdbKafkaClusterConfigKafkaKafkaConfig {
    autoCreateTopicsEnable?: boolean;
    compressionType?: string;
    defaultReplicationFactor?: string;
    logFlushIntervalMessages?: string;
    logFlushIntervalMs?: string;
    logFlushSchedulerIntervalMs?: string;
    logPreallocate?: boolean;
    logRetentionBytes?: string;
    logRetentionHours?: string;
    logRetentionMinutes?: string;
    logRetentionMs?: string;
    logSegmentBytes?: string;
    numPartitions?: string;
    socketReceiveBufferBytes?: string;
    socketSendBufferBytes?: string;
}

export interface MdbKafkaClusterConfigKafkaResources {
    /**
     * Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbKafkaClusterConfigZookeeper {
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.MdbKafkaClusterConfigZookeeperResources;
}

export interface MdbKafkaClusterConfigZookeeperResources {
    /**
     * Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbKafkaClusterHost {
    /**
     * Determines whether each broker will be assigned a public IP address. The default is `false`.
     */
    assignPublicIp: boolean;
    /**
     * Health of the host.
     */
    health: string;
    /**
     * The name of the topic.
     */
    name: string;
    /**
     * The role type to grant to the topic.
     */
    role: string;
    /**
     * The ID of the subnet, to which the host belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Kafka host was created.
     */
    zoneId: string;
}

export interface MdbKafkaClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Allowed values: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day?: string;
    /**
     * Hour of the day in UTC (in `HH` format). Allowed value is between 1 and 24.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbKafkaClusterTopic {
    /**
     * The name of the topic.
     */
    name: string;
    /**
     * The number of the topic's partitions.
     */
    partitions: number;
    /**
     * Amount of data copies (replicas) for the topic in the cluster.
     */
    replicationFactor: number;
    /**
     * User-defined settings for the topic. The structure is documented below.
     */
    topicConfig?: outputs.MdbKafkaClusterTopicTopicConfig;
}

export interface MdbKafkaClusterTopicTopicConfig {
    cleanupPolicy?: string;
    compressionType?: string;
    deleteRetentionMs?: string;
    fileDeleteDelayMs?: string;
    flushMessages?: string;
    flushMs?: string;
    maxMessageBytes?: string;
    minCompactionLagMs?: string;
    minInsyncReplicas?: string;
    preallocate?: boolean;
    retentionBytes?: string;
    retentionMs?: string;
    segmentBytes?: string;
}

export interface MdbKafkaClusterUser {
    /**
     * The name of the topic.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions?: outputs.MdbKafkaClusterUserPermission[];
}

export interface MdbKafkaClusterUserPermission {
    /**
     * The role type to grant to the topic.
     */
    role: string;
    /**
     * The name of the topic that the permission grants access to.
     */
    topicName: string;
}

export interface MdbKafkaTopicTopicConfig {
    cleanupPolicy?: string;
    compressionType?: string;
    deleteRetentionMs?: string;
    fileDeleteDelayMs?: string;
    flushMessages?: string;
    flushMs?: string;
    maxMessageBytes?: string;
    minCompactionLagMs?: string;
    minInsyncReplicas?: string;
    preallocate?: boolean;
    retentionBytes?: string;
    retentionMs?: string;
    segmentBytes?: string;
}

export interface MdbMongodbClusterClusterConfig {
    /**
     * Shows whether cluster has access to data lens. The structure is documented below.
     */
    access: outputs.MdbMongodbClusterClusterConfigAccess;
    /**
     * Time to start the daily backup, in the UTC timezone. The structure is documented below.
     */
    backupWindowStart: outputs.MdbMongodbClusterClusterConfigBackupWindowStart;
    /**
     * Feature compatibility version of MongoDB. If not provided version is taken. Can be either `5.0`, `4.4`, `4.2` and `4.0`.
     */
    featureCompatibilityVersion: string;
    /**
     * Version of MongoDB (either 5.0, 4.4, 4.2 or 4.0).
     */
    version: string;
}

export interface MdbMongodbClusterClusterConfigAccess {
    /**
     * Allow access for DataLens.
     */
    dataLens: boolean;
}

export interface MdbMongodbClusterClusterConfigBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbMongodbClusterDatabase {
    /**
     * The fully qualified domain name of the host. Computed on server side.
     */
    name: string;
}

export interface MdbMongodbClusterHost {
    /**
     * -(Optional)  Should this host have assigned public IP assigned. Can be either `true` or `false`.
     */
    assignPublicIp: boolean;
    /**
     * The health of the host.
     */
    health: string;
    /**
     * The fully qualified domain name of the host. Computed on server side.
     */
    name: string;
    /**
     * The role of the cluster (either PRIMARY or SECONDARY).
     */
    role: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * The availability zone where the MongoDB host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zoneId: string;
}

export interface MdbMongodbClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbMongodbClusterResources {
    /**
     * Volume of the storage available to a MongoDB host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MongoDB hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMongodbClusterUser {
    /**
     * The fully qualified domain name of the host. Computed on server side.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.MdbMongodbClusterUserPermission[];
}

export interface MdbMongodbClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    roles?: string[];
}

export interface MdbMysqlClusterAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens?: boolean;
    /**
     * Allows access for [SQL queries in the management console](https://cloud.yandex.com/docs/managed-mysql/operations/web-sql-query).
     */
    webSql?: boolean;
}

export interface MdbMysqlClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbMysqlClusterDatabase {
    /**
     * Host state name. It should be set for all hosts or unset for all hosts. This field can be used by another host, to select which host will be its replication source. Please refer to `replicationSourceName` parameter.
     */
    name: string;
}

export interface MdbMysqlClusterHost {
    /**
     * Sets whether the host should get a public IP address. It can be changed on the fly only when `name` is set.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Host state name. It should be set for all hosts or unset for all hosts. This field can be used by another host, to select which host will be its replication source. Please refer to `replicationSourceName` parameter.
     */
    name?: string;
    /**
     * Host replication source (fqdn), when replicationSource is empty then host is in HA group.
     */
    replicationSource: string;
    /**
     * Host replication source name points to host's `name` from which this host should replicate. When not set then host in HA group. It works only when `name` is set.
     */
    replicationSourceName?: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the MySQL host will be created.
     */
    zone: string;
}

export interface MdbMysqlClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Allowed values: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day?: string;
    /**
     * Hour of the day in UTC (in `HH` format). Allowed value is between 0 and 23.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbMysqlClusterResources {
    /**
     * Volume of the storage available to a MySQL host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MySQL hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMysqlClusterRestore {
    /**
     * Backup ID. The cluster will be created from the specified backup. [How to get a list of MySQL backups](https://cloud.yandex.com/docs/managed-mysql/operations/cluster-backups).
     */
    backupId: string;
    /**
     * Timestamp of the moment to which the MySQL cluster should be restored. (Format: "2006-01-02T15:04:05" - UTC). When not set, current time is used.
     */
    time?: string;
}

export interface MdbMysqlClusterUser {
    /**
     * Authentication plugin. Allowed values: `MYSQL_NATIVE_PASSWORD`, `CACHING_SHA2_PASSWORD`, `SHA256_PASSWORD` (for version 5.7 `MYSQL_NATIVE_PASSWORD`, `SHA256_PASSWORD`)
     */
    authenticationPlugin: string;
    /**
     * User's connection limits. The structure is documented below.
     * If the attribute is not specified there will be no changes.
     */
    connectionLimits: outputs.MdbMysqlClusterUserConnectionLimits;
    /**
     * List user's global permissions     
     * Allowed permissions:  `REPLICATION_CLIENT`, `REPLICATION_SLAVE`, `PROCESS` for clear list use empty list.
     * If the attribute is not specified there will be no changes.
     */
    globalPermissions: string[];
    /**
     * Host state name. It should be set for all hosts or unset for all hosts. This field can be used by another host, to select which host will be its replication source. Please refer to `replicationSourceName` parameter.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.MdbMysqlClusterUserPermission[];
}

export interface MdbMysqlClusterUserConnectionLimits {
    /**
     * Max connections per hour.
     */
    maxConnectionsPerHour?: number;
    /**
     * Max questions per hour.
     */
    maxQuestionsPerHour?: number;
    /**
     * Max updates per hour.
     */
    maxUpdatesPerHour?: number;
    /**
     * Max user connections.
     */
    maxUserConnections?: number;
}

export interface MdbMysqlClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `ALL`,`ALTER`,`ALTER_ROUTINE`,`CREATE`,`CREATE_ROUTINE`,`CREATE_TEMPORARY_TABLES`,
     * `CREATE_VIEW`,`DELETE`,`DROP`,`EVENT`,`EXECUTE`,`INDEX`,`INSERT`,`LOCK_TABLES`,`SELECT`,`SHOW_VIEW`,`TRIGGER`,`UPDATE`.
     */
    roles?: string[];
}

export interface MdbRedisClusterConfig {
    /**
     * Number of databases (changing requires redis-server restart).
     */
    databases: number;
    /**
     * Redis key eviction policy for a dataset that reaches maximum memory.
     * Can be any of the listed in [the official RedisDB documentation](https://docs.redislabs.com/latest/rs/administering/database-operations/eviction-policy/).
     */
    maxmemoryPolicy: string;
    /**
     * Select the events that Redis will notify among a set of classes.
     */
    notifyKeyspaceEvents: string;
    /**
     * Password for the Redis cluster.
     */
    password: string;
    /**
     * Log slow queries below this number in microseconds.
     */
    slowlogLogSlowerThan: number;
    /**
     * Slow queries log length.
     */
    slowlogMaxLen: number;
    /**
     * Close the connection after a client is idle for N seconds.
     */
    timeout: number;
    /**
     * Version of Redis (5.0, 6.0 or 6.2).
     */
    version: string;
}

export interface MdbRedisClusterHost {
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Redis host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zone: string;
}

export interface MdbRedisClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbRedisClusterResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Redis hosts - environment default is used if missing.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbSqlServerClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbSqlServerClusterDatabase {
    /**
     * The name of the database.
     */
    name: string;
}

export interface MdbSqlServerClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the SQLServer host will be created.
     */
    zone: string;
}

export interface MdbSqlServerClusterResources {
    /**
     * Volume of the storage available to a SQLServer host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of SQLServer hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbSqlServerClusterUser {
    /**
     * The name of the database.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions?: outputs.MdbSqlServerClusterUserPermission[];
}

export interface MdbSqlServerClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `OWNER`, `SECURITYADMIN`, `ACCESSADMIN`, `BACKUPOPERATOR`, `DDLADMIN`, `DATAWRITER`, `DATAREADER`, `DENYDATAWRITER`, `DENYDATAREADER`.
     */
    roles?: string[];
}

export interface OrganizationmanagerSamlFederationSecuritySettings {
    /**
     * Enable encrypted assertions.
     */
    encryptedAssertions: boolean;
}

export interface ServerlessContainerImage {
    args?: string[];
    commands?: string[];
    digest: string;
    environment?: {[key: string]: string};
    /**
     * Invoke URL for the Yandex Cloud Serverless Container
     */
    url: string;
    workDir?: string;
}

export interface StorageBucketCorsRule {
    /**
     * Specifies which headers are allowed.
     */
    allowedHeaders?: string[];
    /**
     * Specifies which methods are allowed. Can be `GET`, `PUT`, `POST`, `DELETE` or `HEAD`.
     */
    allowedMethods: string[];
    /**
     * Specifies which origins are allowed.
     */
    allowedOrigins: string[];
    /**
     * Specifies expose header in the response.
     */
    exposeHeaders?: string[];
    /**
     * Specifies time in seconds that browser can cache the response for a preflight request.
     */
    maxAgeSeconds?: number;
}

export interface StorageBucketGrant {
    /**
     * Unique identifier for the rule. Must be less than or equal to 255 characters in length.
     */
    id?: string;
    permissions: string[];
    type: string;
    uri?: string;
}

export interface StorageBucketLifecycleRule {
    /**
     * Specifies the number of days after initiating a multipart upload when the multipart upload must be completed.
     */
    abortIncompleteMultipartUploadDays?: number;
    /**
     * Specifies lifecycle rule status.
     */
    enabled: boolean;
    /**
     * Specifies a period in the object's expire (documented below).
     */
    expiration?: outputs.StorageBucketLifecycleRuleExpiration;
    /**
     * Unique identifier for the rule. Must be less than or equal to 255 characters in length.
     */
    id: string;
    /**
     * Specifies when noncurrent object versions expire (documented below).
     */
    noncurrentVersionExpiration?: outputs.StorageBucketLifecycleRuleNoncurrentVersionExpiration;
    /**
     * Specifies when noncurrent object versions transitions (documented below).
     */
    noncurrentVersionTransitions?: outputs.StorageBucketLifecycleRuleNoncurrentVersionTransition[];
    /**
     * Object key prefix identifying one or more objects to which the rule applies.
     */
    prefix?: string;
    /**
     * Specifies a period in the object's transitions (documented below).
     */
    transitions?: outputs.StorageBucketLifecycleRuleTransition[];
}

export interface StorageBucketLifecycleRuleExpiration {
    /**
     * Specifies the date after which you want the corresponding action to take effect.
     */
    date?: string;
    /**
     * Specifies the number of days after object creation when the specific rule action takes effect.
     */
    days?: number;
    /**
     * On a versioned bucket (versioning-enabled or versioning-suspended bucket), you can add this element in the lifecycle configuration to direct Object Storage to delete expired object delete markers.
     */
    expiredObjectDeleteMarker?: boolean;
}

export interface StorageBucketLifecycleRuleNoncurrentVersionExpiration {
    /**
     * Specifies the number of days noncurrent object versions expire.
     */
    days?: number;
}

export interface StorageBucketLifecycleRuleNoncurrentVersionTransition {
    /**
     * Specifies the number of days noncurrent object versions transition.
     */
    days?: number;
    /**
     * Specifies the storage class to which you want the noncurrent object versions to transition. Can only be `COLD` or `STANDARD_IA`.
     */
    storageClass: string;
}

export interface StorageBucketLifecycleRuleTransition {
    /**
     * Specifies the date after which you want the corresponding action to take effect.
     */
    date?: string;
    /**
     * Specifies the number of days after object creation when the specific rule action takes effect.
     */
    days?: number;
    /**
     * Specifies the storage class to which you want the object to transition. Can only be `COLD` or `STANDARD_IA`.
     */
    storageClass: string;
}

export interface StorageBucketLogging {
    /**
     * The name of the bucket that will receive the log objects.
     */
    targetBucket: string;
    /**
     * To specify a key prefix for log objects.
     */
    targetPrefix?: string;
}

export interface StorageBucketServerSideEncryptionConfiguration {
    /**
     * A single object for server-side encryption by default configuration. (documented below)
     */
    rule: outputs.StorageBucketServerSideEncryptionConfigurationRule;
}

export interface StorageBucketServerSideEncryptionConfigurationRule {
    /**
     * A single object for setting server-side encryption by default. (documented below)
     */
    applyServerSideEncryptionByDefault: outputs.StorageBucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefault;
}

export interface StorageBucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefault {
    /**
     * The KMS master key ID used for the SSE-KMS encryption.
     */
    kmsMasterKeyId: string;
    /**
     * The server-side encryption algorithm to use. Single valid value is `aws:kms`
     */
    sseAlgorithm: string;
}

export interface StorageBucketVersioning {
    /**
     * Enable versioning. Once you version-enable a bucket, it can never return to an unversioned state. You can, however, suspend versioning on that bucket.
     */
    enabled?: boolean;
}

export interface StorageBucketWebsite {
    /**
     * An absolute path to the document to return in case of a 4XX error.
     */
    errorDocument?: string;
    /**
     * Storage returns this index document when requests are made to the root domain or any of the subfolders.
     */
    indexDocument?: string;
    /**
     * A hostname to redirect all website requests for this bucket to. Hostname can optionally be prefixed with a protocol (`http://` or `https://`) to use when redirecting requests. The default is the protocol that is used in the original request.
     */
    redirectAllRequestsTo?: string;
    /**
     * A json array containing [routing rules](https://cloud.yandex.com/docs/storage/s3/api-ref/hosting/upload#request-scheme) describing redirect behavior and when redirects are applied.
     */
    routingRules?: string;
}

export interface VpcAddressExternalIpv4Address {
    /**
     * - Desired IP.
     */
    address: string;
    /**
     * Enable DDOS protection. Possible values are: "qrator"
     */
    ddosProtectionProvider: string;
    /**
     * Wanted outgoing smtp capability.
     */
    outgoingSmtpCapability: string;
    /**
     * - Zone for allocating address.
     */
    zoneId: string;
}

export interface VpcDefaultSecurityGroupEgress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the security group.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcDefaultSecurityGroupIngress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the security group.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcRouteTableStaticRoute {
    /**
     * Route prefix in CIDR notation.
     */
    destinationPrefix?: string;
    /**
     * Address of the next hop.
     */
    nextHopAddress?: string;
}

export interface VpcSecurityGroupEgress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcSecurityGroupIngress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcSubnetDhcpOptions {
    /**
     * Domain name.
     */
    domainName?: string;
    /**
     * Domain name server IP addresses.
     */
    domainNameServers?: string[];
    /**
     * NTP server IP addresses.
     */
    ntpServers?: string[];
}

export interface YdbDatabaseDedicatedLocation {
    /**
     * Region for the Yandex Database cluster.
     * The structure is documented below.
     */
    region?: outputs.YdbDatabaseDedicatedLocationRegion;
}

export interface YdbDatabaseDedicatedLocationRegion {
    /**
     * Region ID for the Yandex Database cluster.
     */
    id: string;
}

export interface YdbDatabaseDedicatedScalePolicy {
    /**
     * Fixed scaling policy for the Yandex Database cluster.
     * The structure is documented below.
     */
    fixedScale: outputs.YdbDatabaseDedicatedScalePolicyFixedScale;
}

export interface YdbDatabaseDedicatedScalePolicyFixedScale {
    /**
     * Number of instances for the Yandex Database cluster.
     */
    size: number;
}

export interface YdbDatabaseDedicatedStorageConfig {
    /**
     * Amount of storage groups of selected type for the Yandex Database cluster.
     */
    groupCount: number;
    /**
     * Storage type ID for the Yandex Database cluster.
     * Available presets can be obtained via `yc ydb storage-type list` command.
     */
    storageTypeId: string;
}
