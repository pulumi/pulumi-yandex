# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from . import _utilities
from . import outputs
from ._inputs import *

__all__ = ['MdbKafkaClusterArgs', 'MdbKafkaCluster']

@pulumi.input_type
class MdbKafkaClusterArgs:
    def __init__(__self__, *,
                 config: pulumi.Input['MdbKafkaClusterConfigArgs'],
                 network_id: pulumi.Input[str],
                 deletion_protection: Optional[pulumi.Input[bool]] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 environment: Optional[pulumi.Input[str]] = None,
                 folder_id: Optional[pulumi.Input[str]] = None,
                 host_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 subnet_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 topics: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]]] = None,
                 users: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]]] = None):
        """
        The set of arguments for constructing a MdbKafkaCluster resource.
        :param pulumi.Input['MdbKafkaClusterConfigArgs'] config: Configuration of the Kafka cluster. The structure is documented below.
        :param pulumi.Input[str] network_id: ID of the network, to which the Kafka cluster belongs.
        :param pulumi.Input[bool] deletion_protection: Inhibits deletion of the cluster.  Can be either `true` or `false`.
        :param pulumi.Input[str] description: Description of the Kafka cluster.
        :param pulumi.Input[str] environment: Deployment environment of the Kafka cluster. Can be either `PRESTABLE` or `PRODUCTION`. 
               The default is `PRODUCTION`.
        :param pulumi.Input[str] folder_id: The ID of the folder that the resource belongs to. If it is not provided, the default provider folder is used.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] host_group_ids: A list of IDs of the host groups to place VMs of the cluster on.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: A set of key/value label pairs to assign to the Kafka cluster.
        :param pulumi.Input[str] name: The name of the topic.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_group_ids: Security group ids, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] subnet_ids: IDs of the subnets, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]] topics: To manage topics, please switch to using a separate resource type `MdbKafkaTopic`.
        :param pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]] users: A user of the Kafka cluster. The structure is documented below.
        """
        pulumi.set(__self__, "config", config)
        pulumi.set(__self__, "network_id", network_id)
        if deletion_protection is not None:
            pulumi.set(__self__, "deletion_protection", deletion_protection)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if environment is not None:
            pulumi.set(__self__, "environment", environment)
        if folder_id is not None:
            pulumi.set(__self__, "folder_id", folder_id)
        if host_group_ids is not None:
            pulumi.set(__self__, "host_group_ids", host_group_ids)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if subnet_ids is not None:
            pulumi.set(__self__, "subnet_ids", subnet_ids)
        if topics is not None:
            warnings.warn("""to manage topics, please switch to using a separate resource type yandex_mdb_kafka_topic""", DeprecationWarning)
            pulumi.log.warn("""topics is deprecated: to manage topics, please switch to using a separate resource type yandex_mdb_kafka_topic""")
        if topics is not None:
            pulumi.set(__self__, "topics", topics)
        if users is not None:
            pulumi.set(__self__, "users", users)

    @property
    @pulumi.getter
    def config(self) -> pulumi.Input['MdbKafkaClusterConfigArgs']:
        """
        Configuration of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "config")

    @config.setter
    def config(self, value: pulumi.Input['MdbKafkaClusterConfigArgs']):
        pulumi.set(self, "config", value)

    @property
    @pulumi.getter(name="networkId")
    def network_id(self) -> pulumi.Input[str]:
        """
        ID of the network, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "network_id")

    @network_id.setter
    def network_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "network_id", value)

    @property
    @pulumi.getter(name="deletionProtection")
    def deletion_protection(self) -> Optional[pulumi.Input[bool]]:
        """
        Inhibits deletion of the cluster.  Can be either `true` or `false`.
        """
        return pulumi.get(self, "deletion_protection")

    @deletion_protection.setter
    def deletion_protection(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "deletion_protection", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[str]]:
        """
        Description of the Kafka cluster.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "description", value)

    @property
    @pulumi.getter
    def environment(self) -> Optional[pulumi.Input[str]]:
        """
        Deployment environment of the Kafka cluster. Can be either `PRESTABLE` or `PRODUCTION`. 
        The default is `PRODUCTION`.
        """
        return pulumi.get(self, "environment")

    @environment.setter
    def environment(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "environment", value)

    @property
    @pulumi.getter(name="folderId")
    def folder_id(self) -> Optional[pulumi.Input[str]]:
        """
        The ID of the folder that the resource belongs to. If it is not provided, the default provider folder is used.
        """
        return pulumi.get(self, "folder_id")

    @folder_id.setter
    def folder_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "folder_id", value)

    @property
    @pulumi.getter(name="hostGroupIds")
    def host_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        A list of IDs of the host groups to place VMs of the cluster on.
        """
        return pulumi.get(self, "host_group_ids")

    @host_group_ids.setter
    def host_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "host_group_ids", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        A set of key/value label pairs to assign to the Kafka cluster.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the topic.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Security group ids, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "security_group_ids")

    @security_group_ids.setter
    def security_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "security_group_ids", value)

    @property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        IDs of the subnets, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "subnet_ids")

    @subnet_ids.setter
    def subnet_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "subnet_ids", value)

    @property
    @pulumi.getter
    def topics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]]]:
        """
        To manage topics, please switch to using a separate resource type `MdbKafkaTopic`.
        """
        return pulumi.get(self, "topics")

    @topics.setter
    def topics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]]]):
        pulumi.set(self, "topics", value)

    @property
    @pulumi.getter
    def users(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]]]:
        """
        A user of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "users")

    @users.setter
    def users(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]]]):
        pulumi.set(self, "users", value)


@pulumi.input_type
class _MdbKafkaClusterState:
    def __init__(__self__, *,
                 config: Optional[pulumi.Input['MdbKafkaClusterConfigArgs']] = None,
                 created_at: Optional[pulumi.Input[str]] = None,
                 deletion_protection: Optional[pulumi.Input[bool]] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 environment: Optional[pulumi.Input[str]] = None,
                 folder_id: Optional[pulumi.Input[str]] = None,
                 health: Optional[pulumi.Input[str]] = None,
                 host_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 hosts: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterHostArgs']]]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 network_id: Optional[pulumi.Input[str]] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 status: Optional[pulumi.Input[str]] = None,
                 subnet_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 topics: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]]] = None,
                 users: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]]] = None):
        """
        Input properties used for looking up and filtering MdbKafkaCluster resources.
        :param pulumi.Input['MdbKafkaClusterConfigArgs'] config: Configuration of the Kafka cluster. The structure is documented below.
        :param pulumi.Input[str] created_at: Timestamp of cluster creation.
        :param pulumi.Input[bool] deletion_protection: Inhibits deletion of the cluster.  Can be either `true` or `false`.
        :param pulumi.Input[str] description: Description of the Kafka cluster.
        :param pulumi.Input[str] environment: Deployment environment of the Kafka cluster. Can be either `PRESTABLE` or `PRODUCTION`. 
               The default is `PRODUCTION`.
        :param pulumi.Input[str] folder_id: The ID of the folder that the resource belongs to. If it is not provided, the default provider folder is used.
        :param pulumi.Input[str] health: Health of the host.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] host_group_ids: A list of IDs of the host groups to place VMs of the cluster on.
        :param pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterHostArgs']]] hosts: A host of the Kafka cluster. The structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: A set of key/value label pairs to assign to the Kafka cluster.
        :param pulumi.Input[str] name: The name of the topic.
        :param pulumi.Input[str] network_id: ID of the network, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_group_ids: Security group ids, to which the Kafka cluster belongs.
        :param pulumi.Input[str] status: Status of the cluster. Can be either `CREATING`, `STARTING`, `RUNNING`, `UPDATING`, `STOPPING`, `STOPPED`, `ERROR` or `STATUS_UNKNOWN`.
               For more information see `status` field of JSON representation in [the official documentation](https://cloud.yandex.com/docs/managed-kafka/api-ref/Cluster/).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] subnet_ids: IDs of the subnets, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]] topics: To manage topics, please switch to using a separate resource type `MdbKafkaTopic`.
        :param pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]] users: A user of the Kafka cluster. The structure is documented below.
        """
        if config is not None:
            pulumi.set(__self__, "config", config)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if deletion_protection is not None:
            pulumi.set(__self__, "deletion_protection", deletion_protection)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if environment is not None:
            pulumi.set(__self__, "environment", environment)
        if folder_id is not None:
            pulumi.set(__self__, "folder_id", folder_id)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if host_group_ids is not None:
            pulumi.set(__self__, "host_group_ids", host_group_ids)
        if hosts is not None:
            pulumi.set(__self__, "hosts", hosts)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if network_id is not None:
            pulumi.set(__self__, "network_id", network_id)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if subnet_ids is not None:
            pulumi.set(__self__, "subnet_ids", subnet_ids)
        if topics is not None:
            warnings.warn("""to manage topics, please switch to using a separate resource type yandex_mdb_kafka_topic""", DeprecationWarning)
            pulumi.log.warn("""topics is deprecated: to manage topics, please switch to using a separate resource type yandex_mdb_kafka_topic""")
        if topics is not None:
            pulumi.set(__self__, "topics", topics)
        if users is not None:
            pulumi.set(__self__, "users", users)

    @property
    @pulumi.getter
    def config(self) -> Optional[pulumi.Input['MdbKafkaClusterConfigArgs']]:
        """
        Configuration of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "config")

    @config.setter
    def config(self, value: Optional[pulumi.Input['MdbKafkaClusterConfigArgs']]):
        pulumi.set(self, "config", value)

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[pulumi.Input[str]]:
        """
        Timestamp of cluster creation.
        """
        return pulumi.get(self, "created_at")

    @created_at.setter
    def created_at(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "created_at", value)

    @property
    @pulumi.getter(name="deletionProtection")
    def deletion_protection(self) -> Optional[pulumi.Input[bool]]:
        """
        Inhibits deletion of the cluster.  Can be either `true` or `false`.
        """
        return pulumi.get(self, "deletion_protection")

    @deletion_protection.setter
    def deletion_protection(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "deletion_protection", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[str]]:
        """
        Description of the Kafka cluster.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "description", value)

    @property
    @pulumi.getter
    def environment(self) -> Optional[pulumi.Input[str]]:
        """
        Deployment environment of the Kafka cluster. Can be either `PRESTABLE` or `PRODUCTION`. 
        The default is `PRODUCTION`.
        """
        return pulumi.get(self, "environment")

    @environment.setter
    def environment(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "environment", value)

    @property
    @pulumi.getter(name="folderId")
    def folder_id(self) -> Optional[pulumi.Input[str]]:
        """
        The ID of the folder that the resource belongs to. If it is not provided, the default provider folder is used.
        """
        return pulumi.get(self, "folder_id")

    @folder_id.setter
    def folder_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "folder_id", value)

    @property
    @pulumi.getter
    def health(self) -> Optional[pulumi.Input[str]]:
        """
        Health of the host.
        """
        return pulumi.get(self, "health")

    @health.setter
    def health(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "health", value)

    @property
    @pulumi.getter(name="hostGroupIds")
    def host_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        A list of IDs of the host groups to place VMs of the cluster on.
        """
        return pulumi.get(self, "host_group_ids")

    @host_group_ids.setter
    def host_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "host_group_ids", value)

    @property
    @pulumi.getter
    def hosts(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterHostArgs']]]]:
        """
        A host of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "hosts")

    @hosts.setter
    def hosts(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterHostArgs']]]]):
        pulumi.set(self, "hosts", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        A set of key/value label pairs to assign to the Kafka cluster.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the topic.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="networkId")
    def network_id(self) -> Optional[pulumi.Input[str]]:
        """
        ID of the network, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "network_id")

    @network_id.setter
    def network_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "network_id", value)

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Security group ids, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "security_group_ids")

    @security_group_ids.setter
    def security_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "security_group_ids", value)

    @property
    @pulumi.getter
    def status(self) -> Optional[pulumi.Input[str]]:
        """
        Status of the cluster. Can be either `CREATING`, `STARTING`, `RUNNING`, `UPDATING`, `STOPPING`, `STOPPED`, `ERROR` or `STATUS_UNKNOWN`.
        For more information see `status` field of JSON representation in [the official documentation](https://cloud.yandex.com/docs/managed-kafka/api-ref/Cluster/).
        """
        return pulumi.get(self, "status")

    @status.setter
    def status(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "status", value)

    @property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        IDs of the subnets, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "subnet_ids")

    @subnet_ids.setter
    def subnet_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "subnet_ids", value)

    @property
    @pulumi.getter
    def topics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]]]:
        """
        To manage topics, please switch to using a separate resource type `MdbKafkaTopic`.
        """
        return pulumi.get(self, "topics")

    @topics.setter
    def topics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterTopicArgs']]]]):
        pulumi.set(self, "topics", value)

    @property
    @pulumi.getter
    def users(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]]]:
        """
        A user of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "users")

    @users.setter
    def users(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['MdbKafkaClusterUserArgs']]]]):
        pulumi.set(self, "users", value)


class MdbKafkaCluster(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 config: Optional[pulumi.Input[pulumi.InputType['MdbKafkaClusterConfigArgs']]] = None,
                 deletion_protection: Optional[pulumi.Input[bool]] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 environment: Optional[pulumi.Input[str]] = None,
                 folder_id: Optional[pulumi.Input[str]] = None,
                 host_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 network_id: Optional[pulumi.Input[str]] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 subnet_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 topics: Optional[pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterTopicArgs']]]]] = None,
                 users: Optional[pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterUserArgs']]]]] = None,
                 __props__=None):
        """
        Manages a Kafka cluster within the Yandex.Cloud. For more information, see
        [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts).

        ## Example Usage

        Example of creating a Single Node Kafka.

        ```python
        import pulumi
        import pulumi_yandex as yandex

        foo_vpc_network = yandex.VpcNetwork("fooVpcNetwork")
        foo_vpc_subnet = yandex.VpcSubnet("fooVpcSubnet",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.5.0.0/24"],
            zone="ru-central1-a")
        foo_mdb_kafka_cluster = yandex.MdbKafkaCluster("fooMdbKafkaCluster",
            config=yandex.MdbKafkaClusterConfigArgs(
                assign_public_ip=False,
                brokers_count=1,
                kafka=yandex.MdbKafkaClusterConfigKafkaArgs(
                    kafka_config=yandex.MdbKafkaClusterConfigKafkaKafkaConfigArgs(
                        compression_type="COMPRESSION_TYPE_ZSTD",
                        default_replication_factor="1",
                        log_flush_interval_messages="1024",
                        log_flush_interval_ms="1000",
                        log_flush_scheduler_interval_ms="1000",
                        log_preallocate=True,
                        log_retention_bytes="1073741824",
                        log_retention_hours="168",
                        log_retention_minutes="10080",
                        log_retention_ms="86400000",
                        log_segment_bytes="134217728",
                        num_partitions="10",
                    ),
                    resources=yandex.MdbKafkaClusterConfigKafkaResourcesArgs(
                        disk_size=32,
                        disk_type_id="network-ssd",
                        resource_preset_id="s2.micro",
                    ),
                ),
                schema_registry=False,
                unmanaged_topics=False,
                version="2.6",
                zones=["ru-central1-a"],
            ),
            environment="PRESTABLE",
            network_id=foo_vpc_network.id,
            subnet_ids=[foo_vpc_subnet.id],
            users=[
                yandex.MdbKafkaClusterUserArgs(
                    name="producer-application",
                    password="password",
                    permissions=[yandex.MdbKafkaClusterUserPermissionArgs(
                        role="ACCESS_ROLE_PRODUCER",
                        topic_name="input",
                    )],
                ),
                yandex.MdbKafkaClusterUserArgs(
                    name="worker",
                    password="password",
                    permissions=[
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_CONSUMER",
                            topic_name="input",
                        ),
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_PRODUCER",
                            topic_name="output",
                        ),
                    ],
                ),
            ])
        ```

        Example of creating a HA Kafka Cluster with two brokers per AZ (6 brokers + 3 zk)

        ```python
        import pulumi
        import pulumi_yandex as yandex

        foo_vpc_network = yandex.VpcNetwork("fooVpcNetwork")
        foo_vpc_subnet = yandex.VpcSubnet("fooVpcSubnet",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.1.0.0/24"],
            zone="ru-central1-a")
        bar = yandex.VpcSubnet("bar",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.2.0.0/24"],
            zone="ru-central1-b")
        baz = yandex.VpcSubnet("baz",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.3.0.0/24"],
            zone="ru-central1-c")
        foo_mdb_kafka_cluster = yandex.MdbKafkaCluster("fooMdbKafkaCluster",
            config=yandex.MdbKafkaClusterConfigArgs(
                assign_public_ip=True,
                brokers_count=2,
                kafka=yandex.MdbKafkaClusterConfigKafkaArgs(
                    kafka_config=yandex.MdbKafkaClusterConfigKafkaKafkaConfigArgs(
                        compression_type="COMPRESSION_TYPE_ZSTD",
                        default_replication_factor="6",
                        log_flush_interval_messages="1024",
                        log_flush_interval_ms="1000",
                        log_flush_scheduler_interval_ms="1000",
                        log_preallocate=True,
                        log_retention_bytes="1073741824",
                        log_retention_hours="168",
                        log_retention_minutes="10080",
                        log_retention_ms="86400000",
                        log_segment_bytes="134217728",
                        num_partitions="10",
                    ),
                    resources=yandex.MdbKafkaClusterConfigKafkaResourcesArgs(
                        disk_size=128,
                        disk_type_id="network-ssd",
                        resource_preset_id="s2.medium",
                    ),
                ),
                schema_registry=False,
                unmanaged_topics=False,
                version="2.6",
                zones=[
                    "ru-central1-a",
                    "ru-central1-b",
                    "ru-central1-c",
                ],
                zookeeper=yandex.MdbKafkaClusterConfigZookeeperArgs(
                    resources=yandex.MdbKafkaClusterConfigZookeeperResourcesArgs(
                        disk_size=20,
                        disk_type_id="network-ssd",
                        resource_preset_id="s2.micro",
                    ),
                ),
            ),
            environment="PRESTABLE",
            network_id=foo_vpc_network.id,
            subnet_ids=[
                foo_vpc_subnet.id,
                bar.id,
                baz.id,
            ],
            users=[
                yandex.MdbKafkaClusterUserArgs(
                    name="producer-application",
                    password="password",
                    permissions=[yandex.MdbKafkaClusterUserPermissionArgs(
                        role="ACCESS_ROLE_PRODUCER",
                        topic_name="input",
                    )],
                ),
                yandex.MdbKafkaClusterUserArgs(
                    name="worker",
                    password="password",
                    permissions=[
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_CONSUMER",
                            topic_name="input",
                        ),
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_PRODUCER",
                            topic_name="output",
                        ),
                    ],
                ),
            ])
        ```

        ## Import

        A cluster can be imported using the `id` of the resource, e.g.

        ```sh
         $ pulumi import yandex:index/mdbKafkaCluster:MdbKafkaCluster foo cluster_id
        ```

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[pulumi.InputType['MdbKafkaClusterConfigArgs']] config: Configuration of the Kafka cluster. The structure is documented below.
        :param pulumi.Input[bool] deletion_protection: Inhibits deletion of the cluster.  Can be either `true` or `false`.
        :param pulumi.Input[str] description: Description of the Kafka cluster.
        :param pulumi.Input[str] environment: Deployment environment of the Kafka cluster. Can be either `PRESTABLE` or `PRODUCTION`. 
               The default is `PRODUCTION`.
        :param pulumi.Input[str] folder_id: The ID of the folder that the resource belongs to. If it is not provided, the default provider folder is used.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] host_group_ids: A list of IDs of the host groups to place VMs of the cluster on.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: A set of key/value label pairs to assign to the Kafka cluster.
        :param pulumi.Input[str] name: The name of the topic.
        :param pulumi.Input[str] network_id: ID of the network, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_group_ids: Security group ids, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] subnet_ids: IDs of the subnets, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterTopicArgs']]]] topics: To manage topics, please switch to using a separate resource type `MdbKafkaTopic`.
        :param pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterUserArgs']]]] users: A user of the Kafka cluster. The structure is documented below.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: MdbKafkaClusterArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        Manages a Kafka cluster within the Yandex.Cloud. For more information, see
        [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts).

        ## Example Usage

        Example of creating a Single Node Kafka.

        ```python
        import pulumi
        import pulumi_yandex as yandex

        foo_vpc_network = yandex.VpcNetwork("fooVpcNetwork")
        foo_vpc_subnet = yandex.VpcSubnet("fooVpcSubnet",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.5.0.0/24"],
            zone="ru-central1-a")
        foo_mdb_kafka_cluster = yandex.MdbKafkaCluster("fooMdbKafkaCluster",
            config=yandex.MdbKafkaClusterConfigArgs(
                assign_public_ip=False,
                brokers_count=1,
                kafka=yandex.MdbKafkaClusterConfigKafkaArgs(
                    kafka_config=yandex.MdbKafkaClusterConfigKafkaKafkaConfigArgs(
                        compression_type="COMPRESSION_TYPE_ZSTD",
                        default_replication_factor="1",
                        log_flush_interval_messages="1024",
                        log_flush_interval_ms="1000",
                        log_flush_scheduler_interval_ms="1000",
                        log_preallocate=True,
                        log_retention_bytes="1073741824",
                        log_retention_hours="168",
                        log_retention_minutes="10080",
                        log_retention_ms="86400000",
                        log_segment_bytes="134217728",
                        num_partitions="10",
                    ),
                    resources=yandex.MdbKafkaClusterConfigKafkaResourcesArgs(
                        disk_size=32,
                        disk_type_id="network-ssd",
                        resource_preset_id="s2.micro",
                    ),
                ),
                schema_registry=False,
                unmanaged_topics=False,
                version="2.6",
                zones=["ru-central1-a"],
            ),
            environment="PRESTABLE",
            network_id=foo_vpc_network.id,
            subnet_ids=[foo_vpc_subnet.id],
            users=[
                yandex.MdbKafkaClusterUserArgs(
                    name="producer-application",
                    password="password",
                    permissions=[yandex.MdbKafkaClusterUserPermissionArgs(
                        role="ACCESS_ROLE_PRODUCER",
                        topic_name="input",
                    )],
                ),
                yandex.MdbKafkaClusterUserArgs(
                    name="worker",
                    password="password",
                    permissions=[
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_CONSUMER",
                            topic_name="input",
                        ),
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_PRODUCER",
                            topic_name="output",
                        ),
                    ],
                ),
            ])
        ```

        Example of creating a HA Kafka Cluster with two brokers per AZ (6 brokers + 3 zk)

        ```python
        import pulumi
        import pulumi_yandex as yandex

        foo_vpc_network = yandex.VpcNetwork("fooVpcNetwork")
        foo_vpc_subnet = yandex.VpcSubnet("fooVpcSubnet",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.1.0.0/24"],
            zone="ru-central1-a")
        bar = yandex.VpcSubnet("bar",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.2.0.0/24"],
            zone="ru-central1-b")
        baz = yandex.VpcSubnet("baz",
            network_id=foo_vpc_network.id,
            v4_cidr_blocks=["10.3.0.0/24"],
            zone="ru-central1-c")
        foo_mdb_kafka_cluster = yandex.MdbKafkaCluster("fooMdbKafkaCluster",
            config=yandex.MdbKafkaClusterConfigArgs(
                assign_public_ip=True,
                brokers_count=2,
                kafka=yandex.MdbKafkaClusterConfigKafkaArgs(
                    kafka_config=yandex.MdbKafkaClusterConfigKafkaKafkaConfigArgs(
                        compression_type="COMPRESSION_TYPE_ZSTD",
                        default_replication_factor="6",
                        log_flush_interval_messages="1024",
                        log_flush_interval_ms="1000",
                        log_flush_scheduler_interval_ms="1000",
                        log_preallocate=True,
                        log_retention_bytes="1073741824",
                        log_retention_hours="168",
                        log_retention_minutes="10080",
                        log_retention_ms="86400000",
                        log_segment_bytes="134217728",
                        num_partitions="10",
                    ),
                    resources=yandex.MdbKafkaClusterConfigKafkaResourcesArgs(
                        disk_size=128,
                        disk_type_id="network-ssd",
                        resource_preset_id="s2.medium",
                    ),
                ),
                schema_registry=False,
                unmanaged_topics=False,
                version="2.6",
                zones=[
                    "ru-central1-a",
                    "ru-central1-b",
                    "ru-central1-c",
                ],
                zookeeper=yandex.MdbKafkaClusterConfigZookeeperArgs(
                    resources=yandex.MdbKafkaClusterConfigZookeeperResourcesArgs(
                        disk_size=20,
                        disk_type_id="network-ssd",
                        resource_preset_id="s2.micro",
                    ),
                ),
            ),
            environment="PRESTABLE",
            network_id=foo_vpc_network.id,
            subnet_ids=[
                foo_vpc_subnet.id,
                bar.id,
                baz.id,
            ],
            users=[
                yandex.MdbKafkaClusterUserArgs(
                    name="producer-application",
                    password="password",
                    permissions=[yandex.MdbKafkaClusterUserPermissionArgs(
                        role="ACCESS_ROLE_PRODUCER",
                        topic_name="input",
                    )],
                ),
                yandex.MdbKafkaClusterUserArgs(
                    name="worker",
                    password="password",
                    permissions=[
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_CONSUMER",
                            topic_name="input",
                        ),
                        yandex.MdbKafkaClusterUserPermissionArgs(
                            role="ACCESS_ROLE_PRODUCER",
                            topic_name="output",
                        ),
                    ],
                ),
            ])
        ```

        ## Import

        A cluster can be imported using the `id` of the resource, e.g.

        ```sh
         $ pulumi import yandex:index/mdbKafkaCluster:MdbKafkaCluster foo cluster_id
        ```

        :param str resource_name: The name of the resource.
        :param MdbKafkaClusterArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(MdbKafkaClusterArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 config: Optional[pulumi.Input[pulumi.InputType['MdbKafkaClusterConfigArgs']]] = None,
                 deletion_protection: Optional[pulumi.Input[bool]] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 environment: Optional[pulumi.Input[str]] = None,
                 folder_id: Optional[pulumi.Input[str]] = None,
                 host_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 network_id: Optional[pulumi.Input[str]] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 subnet_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 topics: Optional[pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterTopicArgs']]]]] = None,
                 users: Optional[pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterUserArgs']]]]] = None,
                 __props__=None):
        if opts is None:
            opts = pulumi.ResourceOptions()
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.version is None:
            opts.version = _utilities.get_version()
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = MdbKafkaClusterArgs.__new__(MdbKafkaClusterArgs)

            if config is None and not opts.urn:
                raise TypeError("Missing required property 'config'")
            __props__.__dict__["config"] = config
            __props__.__dict__["deletion_protection"] = deletion_protection
            __props__.__dict__["description"] = description
            __props__.__dict__["environment"] = environment
            __props__.__dict__["folder_id"] = folder_id
            __props__.__dict__["host_group_ids"] = host_group_ids
            __props__.__dict__["labels"] = labels
            __props__.__dict__["name"] = name
            if network_id is None and not opts.urn:
                raise TypeError("Missing required property 'network_id'")
            __props__.__dict__["network_id"] = network_id
            __props__.__dict__["security_group_ids"] = security_group_ids
            __props__.__dict__["subnet_ids"] = subnet_ids
            if topics is not None and not opts.urn:
                warnings.warn("""to manage topics, please switch to using a separate resource type yandex_mdb_kafka_topic""", DeprecationWarning)
                pulumi.log.warn("""topics is deprecated: to manage topics, please switch to using a separate resource type yandex_mdb_kafka_topic""")
            __props__.__dict__["topics"] = topics
            __props__.__dict__["users"] = users
            __props__.__dict__["created_at"] = None
            __props__.__dict__["health"] = None
            __props__.__dict__["hosts"] = None
            __props__.__dict__["status"] = None
        super(MdbKafkaCluster, __self__).__init__(
            'yandex:index/mdbKafkaCluster:MdbKafkaCluster',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            config: Optional[pulumi.Input[pulumi.InputType['MdbKafkaClusterConfigArgs']]] = None,
            created_at: Optional[pulumi.Input[str]] = None,
            deletion_protection: Optional[pulumi.Input[bool]] = None,
            description: Optional[pulumi.Input[str]] = None,
            environment: Optional[pulumi.Input[str]] = None,
            folder_id: Optional[pulumi.Input[str]] = None,
            health: Optional[pulumi.Input[str]] = None,
            host_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
            hosts: Optional[pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterHostArgs']]]]] = None,
            labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
            name: Optional[pulumi.Input[str]] = None,
            network_id: Optional[pulumi.Input[str]] = None,
            security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
            status: Optional[pulumi.Input[str]] = None,
            subnet_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
            topics: Optional[pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterTopicArgs']]]]] = None,
            users: Optional[pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterUserArgs']]]]] = None) -> 'MdbKafkaCluster':
        """
        Get an existing MdbKafkaCluster resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[pulumi.InputType['MdbKafkaClusterConfigArgs']] config: Configuration of the Kafka cluster. The structure is documented below.
        :param pulumi.Input[str] created_at: Timestamp of cluster creation.
        :param pulumi.Input[bool] deletion_protection: Inhibits deletion of the cluster.  Can be either `true` or `false`.
        :param pulumi.Input[str] description: Description of the Kafka cluster.
        :param pulumi.Input[str] environment: Deployment environment of the Kafka cluster. Can be either `PRESTABLE` or `PRODUCTION`. 
               The default is `PRODUCTION`.
        :param pulumi.Input[str] folder_id: The ID of the folder that the resource belongs to. If it is not provided, the default provider folder is used.
        :param pulumi.Input[str] health: Health of the host.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] host_group_ids: A list of IDs of the host groups to place VMs of the cluster on.
        :param pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterHostArgs']]]] hosts: A host of the Kafka cluster. The structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: A set of key/value label pairs to assign to the Kafka cluster.
        :param pulumi.Input[str] name: The name of the topic.
        :param pulumi.Input[str] network_id: ID of the network, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_group_ids: Security group ids, to which the Kafka cluster belongs.
        :param pulumi.Input[str] status: Status of the cluster. Can be either `CREATING`, `STARTING`, `RUNNING`, `UPDATING`, `STOPPING`, `STOPPED`, `ERROR` or `STATUS_UNKNOWN`.
               For more information see `status` field of JSON representation in [the official documentation](https://cloud.yandex.com/docs/managed-kafka/api-ref/Cluster/).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] subnet_ids: IDs of the subnets, to which the Kafka cluster belongs.
        :param pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterTopicArgs']]]] topics: To manage topics, please switch to using a separate resource type `MdbKafkaTopic`.
        :param pulumi.Input[Sequence[pulumi.Input[pulumi.InputType['MdbKafkaClusterUserArgs']]]] users: A user of the Kafka cluster. The structure is documented below.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _MdbKafkaClusterState.__new__(_MdbKafkaClusterState)

        __props__.__dict__["config"] = config
        __props__.__dict__["created_at"] = created_at
        __props__.__dict__["deletion_protection"] = deletion_protection
        __props__.__dict__["description"] = description
        __props__.__dict__["environment"] = environment
        __props__.__dict__["folder_id"] = folder_id
        __props__.__dict__["health"] = health
        __props__.__dict__["host_group_ids"] = host_group_ids
        __props__.__dict__["hosts"] = hosts
        __props__.__dict__["labels"] = labels
        __props__.__dict__["name"] = name
        __props__.__dict__["network_id"] = network_id
        __props__.__dict__["security_group_ids"] = security_group_ids
        __props__.__dict__["status"] = status
        __props__.__dict__["subnet_ids"] = subnet_ids
        __props__.__dict__["topics"] = topics
        __props__.__dict__["users"] = users
        return MdbKafkaCluster(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter
    def config(self) -> pulumi.Output['outputs.MdbKafkaClusterConfig']:
        """
        Configuration of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "config")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> pulumi.Output[str]:
        """
        Timestamp of cluster creation.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="deletionProtection")
    def deletion_protection(self) -> pulumi.Output[bool]:
        """
        Inhibits deletion of the cluster.  Can be either `true` or `false`.
        """
        return pulumi.get(self, "deletion_protection")

    @property
    @pulumi.getter
    def description(self) -> pulumi.Output[Optional[str]]:
        """
        Description of the Kafka cluster.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter
    def environment(self) -> pulumi.Output[Optional[str]]:
        """
        Deployment environment of the Kafka cluster. Can be either `PRESTABLE` or `PRODUCTION`. 
        The default is `PRODUCTION`.
        """
        return pulumi.get(self, "environment")

    @property
    @pulumi.getter(name="folderId")
    def folder_id(self) -> pulumi.Output[str]:
        """
        The ID of the folder that the resource belongs to. If it is not provided, the default provider folder is used.
        """
        return pulumi.get(self, "folder_id")

    @property
    @pulumi.getter
    def health(self) -> pulumi.Output[str]:
        """
        Health of the host.
        """
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="hostGroupIds")
    def host_group_ids(self) -> pulumi.Output[Sequence[str]]:
        """
        A list of IDs of the host groups to place VMs of the cluster on.
        """
        return pulumi.get(self, "host_group_ids")

    @property
    @pulumi.getter
    def hosts(self) -> pulumi.Output[Sequence['outputs.MdbKafkaClusterHost']]:
        """
        A host of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "hosts")

    @property
    @pulumi.getter
    def labels(self) -> pulumi.Output[Mapping[str, str]]:
        """
        A set of key/value label pairs to assign to the Kafka cluster.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter
    def name(self) -> pulumi.Output[str]:
        """
        The name of the topic.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="networkId")
    def network_id(self) -> pulumi.Output[str]:
        """
        ID of the network, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "network_id")

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> pulumi.Output[Sequence[str]]:
        """
        Security group ids, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "security_group_ids")

    @property
    @pulumi.getter
    def status(self) -> pulumi.Output[str]:
        """
        Status of the cluster. Can be either `CREATING`, `STARTING`, `RUNNING`, `UPDATING`, `STOPPING`, `STOPPED`, `ERROR` or `STATUS_UNKNOWN`.
        For more information see `status` field of JSON representation in [the official documentation](https://cloud.yandex.com/docs/managed-kafka/api-ref/Cluster/).
        """
        return pulumi.get(self, "status")

    @property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> pulumi.Output[Optional[Sequence[str]]]:
        """
        IDs of the subnets, to which the Kafka cluster belongs.
        """
        return pulumi.get(self, "subnet_ids")

    @property
    @pulumi.getter
    def topics(self) -> pulumi.Output[Optional[Sequence['outputs.MdbKafkaClusterTopic']]]:
        """
        To manage topics, please switch to using a separate resource type `MdbKafkaTopic`.
        """
        return pulumi.get(self, "topics")

    @property
    @pulumi.getter
    def users(self) -> pulumi.Output[Optional[Sequence['outputs.MdbKafkaClusterUser']]]:
        """
        A user of the Kafka cluster. The structure is documented below.
        """
        return pulumi.get(self, "users")

